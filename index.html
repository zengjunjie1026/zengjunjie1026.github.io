<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"zengjunjie1026.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.18.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="做自己爱做的事，爱自己在做的事！">
<meta property="og:type" content="website">
<meta property="og:title" content="分子美食家的博客">
<meta property="og:url" content="https://zengjunjie1026.github.io/index.html">
<meta property="og:site_name" content="分子美食家的博客">
<meta property="og:description" content="做自己爱做的事，爱自己在做的事！">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="andrew">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://zengjunjie1026.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>分子美食家的博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">分子美食家的博客</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">记录学习的技能和遇到的问题</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">andrew</p>
  <div class="site-description" itemprop="description">做自己爱做的事，爱自己在做的事！</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">22</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zengjunjie1026.github.io/2023/08/16/hive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="andrew">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="分子美食家的博客">
      <meta itemprop="description" content="做自己爱做的事，爱自己在做的事！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 分子美食家的博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/16/hive/" class="post-title-link" itemprop="url">hive</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-08-16 21:17:46" itemprop="dateCreated datePublished" datetime="2023-08-16T21:17:46+08:00">2023-08-16</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zengjunjie1026.github.io/2023/08/16/hbase%E5%AE%89%E8%A3%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="andrew">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="分子美食家的博客">
      <meta itemprop="description" content="做自己爱做的事，爱自己在做的事！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 分子美食家的博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/16/hbase%E5%AE%89%E8%A3%85/" class="post-title-link" itemprop="url">hbase安装</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-08-16 21:16:42 / 修改时间：21:17:10" itemprop="dateCreated datePublished" datetime="2023-08-16T21:16:42+08:00">2023-08-16</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="2-1-HBase-安装部署"><a href="#2-1-HBase-安装部署" class="headerlink" title="2.1 HBase 安装部署"></a>2.1 HBase 安装部署</h3><h5 id="2-1-1-Zookeeper-正常部署"><a href="#2-1-1-Zookeeper-正常部署" class="headerlink" title="2.1.1 Zookeeper 正常部署"></a>2.1.1 Zookeeper 正常部署</h5><p>首先保证 Zookeeper 集群的正常部署，并启动之:</p>
<p>[andrew@hadoop101 zookeeper-3.4.10]$ bin&#x2F;zkServer.sh start<br>[andrew@hadoop101 zookeeper-3.4.10]$ bin&#x2F;zkServer.sh start<br>[andrew@hadoop101 zookeeper-3.4.10]$ bin&#x2F;zkServer.sh start</p>
<h5 id="2-1-2-Hadoop-正常部署-Hadoop-集群的正常部署并启动"><a href="#2-1-2-Hadoop-正常部署-Hadoop-集群的正常部署并启动" class="headerlink" title="2.1.2 Hadoop 正常部署 Hadoop 集群的正常部署并启动:"></a>2.1.2 Hadoop 正常部署 Hadoop 集群的正常部署并启动:</h5><p>[andrew@hadoop101 hadoop-2.7.2]$ sbin&#x2F;start-dfs.sh<br>[andrew@hadoop103 hadoop-2.7.2]$ sbin&#x2F;start-yarn.sh</p>
<h5 id="2-1-3-HBase-的解压-解压-Hbase-到指定目录"><a href="#2-1-3-HBase-的解压-解压-Hbase-到指定目录" class="headerlink" title="2.1.3 HBase 的解压 解压 Hbase 到指定目录:"></a>2.1.3 HBase 的解压 解压 Hbase 到指定目录:</h5><p>[andrew@hadoop101 software]$ tar -zxvf hbase-1.3.1-bin.tar.gz -C &#x2F;opt&#x2F;module</p>
<p>2.1.4 HBase 的配置文件<br>修改 HBase 对应的配置文件。</p>
<p> 1)hbase-env.sh 修改内容: 2)hbase-site.xml 修改内容:<br>vim ~&#x2F;.bashrc<br>export JAVA_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;jdk1.8.0_144<br>export HBASE_MANAGES_ZK&#x3D;false </p>
<p>hbase-site.xml 修改内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:8020/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 0.98 后的新变动，之前版本没有.port,默认端口为 60000 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>16000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/zookeeper-3.5.7/zkData<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.unsafe.stream.capability.enforce<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="comment">&lt;!-- &lt;property&gt;</span></span><br><span class="line"><span class="comment">      &lt;name&gt;phoenix.schema.isNamespaceMappingEnabled&lt;/name&gt;</span></span><br><span class="line"><span class="comment">      &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="comment">    &lt;/property&gt;</span></span><br><span class="line"><span class="comment">    &lt;property&gt;</span></span><br><span class="line"><span class="comment">    &lt;name&gt;phoenix.schema.mapSystemTablesToNamespace&lt;/name&gt;</span></span><br><span class="line"><span class="comment">      &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="comment">   &lt;/property&gt; --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>vim regionservers</p>
<p>localhost</p>
<p>启动hbase</p>
<p>bin&#x2F;hbase-daemon.sh start </p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zengjunjie1026.github.io/2023/08/16/hbase/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="andrew">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="分子美食家的博客">
      <meta itemprop="description" content="做自己爱做的事，爱自己在做的事！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 分子美食家的博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/16/hbase/" class="post-title-link" itemprop="url">hbase</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-08-16 21:16:22 / 修改时间：21:16:28" itemprop="dateCreated datePublished" datetime="2023-08-16T21:16:22+08:00">2023-08-16</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="HBase简介"><a href="#HBase简介" class="headerlink" title="HBase简介"></a>HBase简介</h2><h3 id="什么是HBase"><a href="#什么是HBase" class="headerlink" title="什么是HBase"></a>什么是HBase</h3><p>HBASE是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBASE技术可在廉价PC Server上搭建起大规模结构化存储集群。<br>HBASE的目标是存储并处理大型的数据，更具体来说是仅需使用普通的硬件配置，就能够处理由成千上万的行和列所组成的大型数据。HBASE是<br>Google Bigtable的开源实现，但是也有很多不同之处。比如：Google Bigtable利用GFS作为其文件存储系统，HBASE利用Hadoop<br>HDFS作为其文件存储系统；Google运行MAPREDUCE来处理Bigtable中的海量数据，HBASE同样利用Hadoop MapReduce来处理HBASE<br>中的海量数据；Google Bigtable利用Chubby作为协同服务，HBASE利用Zookeeper作为对应。</p>
<h3 id="HBase中的角色"><a href="#HBase中的角色" class="headerlink" title="HBase中的角色"></a>HBase中的角色</h3><h4 id="HMaster"><a href="#HMaster" class="headerlink" title="HMaster"></a>HMaster</h4><p>功能：</p>
<ul>
<li>监控RegionServer</li>
<li>处理RegionServer故障转移</li>
<li>处理元数据的变更</li>
<li>处理region的分配或移除</li>
<li>在空闲时间进行数据的负载均衡</li>
<li>通过Zookeeper发布自己的位置给客户端</li>
</ul>
<h4 id="RegionServer"><a href="#RegionServer" class="headerlink" title="RegionServer"></a>RegionServer</h4><p>功能：</p>
<ul>
<li>负责存储HBase的实际数据</li>
<li>处理分配给它的Region</li>
<li>刷新缓存到HDFS</li>
<li>维护HLog</li>
<li>执行压缩</li>
<li>负责处理Region分片</li>
</ul>
<h5 id="其他组件"><a href="#其他组件" class="headerlink" title="其他组件"></a>其他组件</h5><ul>
<li>Write-Ahead logs<br>HBase的修改记录，当对HBase读写数据的时候，数据不是直接写进磁盘，它会在内存中保留一段时间（时间以及数据量阈值可以设定）。<br>但把数据保存在内存中可能有更高的概率引起数据丢失，为了解决这个问题，数据会先写在一个叫做Write-Ahead logfile的文件中，<br>然后再写入内存中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。</li>
<li>HFile<br>这是在磁盘上保存原始数据的实际的物理文件，是实际的存储文件。</li>
<li>Store<br>HFile存储在Store中，一个Store对应HBase表中的一个列族。</li>
<li>MemStore<br>顾名思义，就是内存存储，位于内存中，用来保存当前的数据操作，所以当数据保存在WAL中之后，RegsionServer会在内存中存储键值对。</li>
<li>Region<br>Hbase表的分片，HBase表会根据RowKey值被切分成不同的region存储在RegionServer中，在一个RegionServer中可以有多个不同的region。</li>
</ul>
<h3 id="HBase架构"><a href="#HBase架构" class="headerlink" title="HBase架构"></a>HBase架构</h3><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bfa9b3afd8f844d0b938825b77e085d2~tplv-k3u1fbpfcp-watermark.image"></p>
<h2 id="HBase安装"><a href="#HBase安装" class="headerlink" title="HBase安装"></a>HBase安装</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/qingyunzong/p/8668880.html">HBase学习之路 （二）HBase集群安装</a></li>
</ul>
<h2 id="HBase数据结构"><a href="#HBase数据结构" class="headerlink" title="HBase数据结构"></a>HBase数据结构</h2><h3 id="Row-Key"><a href="#Row-Key" class="headerlink" title="Row Key"></a>Row Key</h3><p>与nosql数据库们一样,row key是用来检索记录的主键。访问HBASE table中的行，只有三种方式：</p>
<ul>
<li>通过单个row key访问</li>
<li>通过row key的range（正则）</li>
<li>全表扫描Row key行键(Row key)可以是任意字符串(最大长度是64KB，实际应用中长度一般为10-100bytes)，在HBASE内部，<br>row key保存为字节数组。存储时，数据按照Row key的字典序(byte order)排序存储。设计key时，要充分排序存储这个特性，将经常一起读取的行存储放到一起。(位置相关性)</li>
</ul>
<h3 id="Columns-Family"><a href="#Columns-Family" class="headerlink" title="Columns Family"></a>Columns Family</h3><p>列族：HBASE表中的每个列，都归属于某个列族。列族是表的schema的一部分(而列不是)，必须在使用表之前定义。列名都以列族作为前缀。例如courses:history，courses:math都属于courses 这个列族。</p>
<h3 id="Cell"><a href="#Cell" class="headerlink" title="Cell"></a>Cell</h3><p>由{row key, columnFamily, version} 唯一确定的单元。cell中的数据是没有类型的，全部是字节码形式存贮。关键字：无类型、字节码</p>
<h3 id="Time-Stamp"><a href="#Time-Stamp" class="headerlink" title="Time Stamp"></a>Time Stamp</h3><p>HBASE 中通过rowkey和columns确定的为一个存贮单元称为cell。每个cell都保存着同一份数据的多个版本。版本通过时间戳来索引。时间戳的类型是64位整型。时间戳可以由HBASE(在数据写入时自动)赋值，此时时间戳是精确到毫秒的当前系统时间。时间戳也可以由客户显式赋值。如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。每个cell中，不同版本的数据按照时间倒序排序，即最新的数据排在最前面。为了避免数据存在过多版本造成的的管理(包括存贮和索引)负担，HBASE提供了两种数据版本回收方式。一是保存数据的最后n个版本，二是保存最近一段时间内的版本（比如最近七天）。用户可以针对每个列族进行设置。</p>
<h2 id="HBase原理"><a href="#HBase原理" class="headerlink" title="HBase原理"></a>HBase原理</h2><h3 id="写流程"><a href="#写流程" class="headerlink" title="写流程"></a>写流程</h3><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bf7e99f7965d4f3b9b4e54961088cc1a~tplv-k3u1fbpfcp-watermark.image"></p>
<ul>
<li>Client向HregionServer发送写请求；</li>
<li>HregionServer将数据写到HLog（write ahead log）。为了数据的持久化和恢复；</li>
<li>HregionServer将数据写到内存（MemStore）；</li>
<li>反馈Client写成功。</li>
</ul>
<h3 id="数据flush过程"><a href="#数据flush过程" class="headerlink" title="数据flush过程"></a>数据flush过程</h3><ul>
<li>当MemStore数据达到阈值（默认是128M，老版本是64M），将数据刷到硬盘，将内存中的数据删除，同时删除HLog中的历史数据；</li>
<li>并将数据存储到HDFS中；</li>
<li>在HLog中做标记点。</li>
</ul>
<h3 id="数据合并过程"><a href="#数据合并过程" class="headerlink" title="数据合并过程"></a>数据合并过程</h3><ul>
<li>当数据块达到4块，Hmaster将数据块加载到本地，进行合并；</li>
<li>当合并的数据超过256M，进行拆分，将拆分后的Region分配给不同的HregionServer管理；</li>
<li>当HregionServer宕机后，将HregionServer上的hlog拆分，然后分配给不同的HregionServer加载，修改.META；</li>
<li>注意：HLog会同步到HDFS。</li>
</ul>
<h3 id="读流程"><a href="#读流程" class="headerlink" title="读流程"></a>读流程</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5e781efc3fd947d48e1d07bf17ee8426~tplv-k3u1fbpfcp-watermark.image"></p>
<ul>
<li>Client先访问zookeeper，从meta表读取region的位置，然后读取meta表中的数据。meta中又存储了用户表的region信息；</li>
<li>根据namespace、表名和rowkey在meta表中找到对应的region信息；</li>
<li>找到这个region对应的regionserver；</li>
<li>查找对应的region；</li>
<li>先从MemStore找数据，如果没有，再到StoreFile上读(为了读取的效率)。</li>
</ul>
<h3 id="Hmaster的职责"><a href="#Hmaster的职责" class="headerlink" title="Hmaster的职责"></a>Hmaster的职责</h3><ul>
<li>管理用户对Table的增、删、改、查操作；</li>
<li>记录region在哪台Hregion server上；</li>
<li>在Region Split后，负责新Region的分配；</li>
<li>新机器加入时，管理HRegion Server的负载均衡，调整Region分布；</li>
<li>在HRegion Server宕机后，负责失效HRegion Server 上的Regions迁移。</li>
</ul>
<h3 id="Hregionserver的职责"><a href="#Hregionserver的职责" class="headerlink" title="Hregionserver的职责"></a>Hregionserver的职责</h3><ul>
<li>HRegion Server主要负责响应用户I&#x2F;O请求，向HDFS文件系统中读写数据，是HBASE中最核心的模块。</li>
<li>HRegion Server管理了很多table的分区，也就是region。</li>
</ul>
<h3 id="Client职责"><a href="#Client职责" class="headerlink" title="Client职责"></a>Client职责</h3><ul>
<li>HBASE Client使用HBASE的RPC机制与HMaster和RegionServer进行通信</li>
<li>管理类操作：Client与HMaster进行RPC；</li>
<li>数据读写类操作：Client与HRegionServer进行RPC。</li>
</ul>
<h2 id="Phoenix-SQL-On-HBase"><a href="#Phoenix-SQL-On-HBase" class="headerlink" title="Phoenix(SQL On HBase)"></a>Phoenix(SQL On HBase)</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><ul>
<li>Phoenix是一个HBase框架，可以通过SQL的方式来操作HBase。</li>
<li>Phoenix是构建在HBase上的一个SQL层，是内嵌在HBase中的JDBC驱动，能够让用户使用标准的JDBC来操作HBase。</li>
<li>Phoenix使用JAVA语言进行编写，其查询引擎会将SQL查询语句转换成一个或多个HBase Scanner，且并行执行生成标准的JDBC结果集。</li>
<li>如果需要对HBase进行复杂的操作，那么应该使用Phoenix，其会将SQL语句转换成HBase相应的API。</li>
<li>Phoenix只能用在HBase上，其查询性能要远高于Hive。</li>
</ul>
<h3 id="Phoenix与HBase的关系"><a href="#Phoenix与HBase的关系" class="headerlink" title="Phoenix与HBase的关系"></a>Phoenix与HBase的关系</h3><p>Phoenix与HBase中的表是独立的，两者之间没有必然的关系。</p>
<p>Phoenix与HBase集成后会创建六张系统表：SYSTEM.CATALOG、SYSTEM.FUNCTION、SYSTEM.LOG、SYSTEM.SEQUENCE、SYSTEM.STATS，其中SYSTEM.CATALOG表用于存放Phoenix创建表时的元数据。</p>
<p>Phoenix创建表时会自动调用HBase客户端创建相应的表，并且在SYSTEM.CATALOG系统表中记录Phoenix创建表时的元数据，其主键的值对应HBase的RowKey，非主键的列对应HBase的Column（列族不指定时为0，且列会进行编码）</p>
<p>如果是通过Phoenix创建的表，那么必须通过Phoenix客户端来对表进行操作，因为通过Phoenix创建的表其非主键的列会进行编码。</p>
<h3 id="Phoenix语法"><a href="#Phoenix语法" class="headerlink" title="Phoenix语法"></a>Phoenix语法</h3><p>Phoenix的SQL中如果表名、字段名不使用双引号标注那么默认转换成大写。</p>
<p>Phoenix中的字符串使用单引号进行标注。 </p>
<p>创建表</p>
<figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS us_population (</span><br><span class="line">      <span class="keyword">state</span> CHAR(<span class="number">2</span>) NOT NULL,</span><br><span class="line">      city VARCHAR NOT NULL,</span><br><span class="line">      population BIGINT</span><br><span class="line">      CONSTRAINT my_pk PRIMARY KEY (<span class="keyword">state</span>, city)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<blockquote>
<p>主键的值对应HBase中的RowKey，列族不指定时默认是0，非主键的列对应HBase的列。</p>
</blockquote>
<p>删除表</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> us_population;</span><br></pre></td></tr></table></figure>

<p>查询数据</p>
<figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> us_population <span class="keyword">WHERE</span> state = <span class="string">&#x27;NA&#x27;</span> <span class="keyword">AND</span> population &gt; <span class="number">10000</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> population <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在进行查询时，支持ORDER BY、GROUP BY、LIMIT、JOIN等操作，同时Phoenix提供了一系列的函数，其中包括COUNT()、MAX()、MIN()、SUM()等，具体的函数列表可以查看：<a target="_blank" rel="noopener" href="http://phoenix.apache.org/language/functions.html%E4%B8%8D%E7%AE%A1%E6%9D%A1%E4%BB%B6%E4%B8%AD%E7%9A%84%E5%88%97%E6%98%AF%E5%90%A6%E6%98%AF%E8%81%94%E5%90%88%E4%B8%BB%E9%94%AE%E4%B8%AD%E7%9A%84%EF%BC%8CPhoenix%E4%B8%80%E6%A0%B7%E5%8F%AF%E4%BB%A5%E6%94%AF%E6%8C%81%E3%80%82">http://phoenix.apache.org/language/functions.html不管条件中的列是否是联合主键中的，Phoenix一样可以支持。</a></p>
</blockquote>
<p> 删除数据</p>
<figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DELETE FROM us_population WHERE <span class="keyword">state</span> = &#x27;NA&#x27;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>Phoenix映射HBase </p>
<p>只要直接通过HBase客户端创建的表，若想用Phoenix来进行操作，那么必须要进行表的映射，因为SYSTEM.CATALOG表中并没有维护Phoenix创建表的元数据。</p>
<p>创建表来进行表的映射</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> 表名(</span><br><span class="line">  列名 类型 主键,</span><br><span class="line">  列簇.列名,</span><br><span class="line">  列簇.列名</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>HBase中的RowKey映射Phoenix的主键，HBase中的Column映射Phoenix的列，且使用列簇名.列名进行映射。<br>相当于在SYSTEM.CATALOG表中录入相关的元数据，使Phoenix能够进行操作它。</p>
<h3 id="使用二级索引"><a href="#使用二级索引" class="headerlink" title="使用二级索引"></a>使用二级索引</h3><p>在HBase中会自动为RowKey添加索引，因此在通过RowKey查询数据时效率会很高，但是如果要根据其他列来进行组合查询，那么查询的性能就很低下，此时可以使用Phoenix提供的二级索引，能够极大的提高查询数据的性能。</p>
<p> 我们其实已经知道了我们的主键 是和我们的rowkey进行映射的，所以查询性能高</p>
<ul>
<li>创建普通索引<blockquote>
<p>CREATE INDEX 索引名称 ON 表名(列名)</p>
</blockquote>
</li>
<li>创建二级索引<blockquote>
<p>CREATE INDEX 索引名称 ON 表名(列名) INCLUDE(列名)</p>
</blockquote>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zengjunjie1026.github.io/2023/08/16/hadoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="andrew">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="分子美食家的博客">
      <meta itemprop="description" content="做自己爱做的事，爱自己在做的事！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 分子美食家的博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/16/hadoop/" class="post-title-link" itemprop="url">hadoop</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-08-16 21:14:23 / 修改时间：21:14:30" itemprop="dateCreated datePublished" datetime="2023-08-16T21:14:23+08:00">2023-08-16</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="大数据概念"><a href="#大数据概念" class="headerlink" title="大数据概念"></a>大数据概念</h2><p>大数据（big data）：指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、<br>洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。</p>
<blockquote>
<p>主要解决，海量数据的存储和海量数据的分析计算问题。</p>
</blockquote>
<h2 id="大数据技术生态体系"><a href="#大数据技术生态体系" class="headerlink" title="大数据技术生态体系"></a>大数据技术生态体系</h2><p>当然，目前这个生态是越来越大了，但是它的本质还是在二个方面 计算 和 存储</p>
<h3 id="开源生态"><a href="#开源生态" class="headerlink" title="开源生态"></a>开源生态</h3><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5f63ebfc9e784f7690d0ed92f290e7bb~tplv-k3u1fbpfcp-watermark.image"></p>
<ul>
<li><p>Sqoop：sqoop是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql)间进行数据的传递，可以将一个关系型数据库（例如：MySQL ,<br>Oracle 等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。</p>
</li>
<li><p>Flume：Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，<br>用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。</p>
</li>
<li><p>Kafka：Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性：</p>
<ul>
<li>通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。</li>
<li>高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。</li>
<li>支持通过Kafka服务器和消费机集群来分区消息。</li>
<li>支持Hadoop并行数据加载。</li>
</ul>
</li>
<li><p>Storm：Storm为分布式实时计算提供了一组通用原语，可被用于“流处理”之中，实时处理消息并更新数据库。这是管理队列及工作者集群的另一种方式。<br>Storm也可被用于“连续计算”（continuous computation），对数据流做连续查询，在计算时就将结果以流的形式输出给用户。</p>
</li>
<li><p>Spark：Spark是当前最流行的开源大数据内存计算框架。可以基于Hadoop上存储的大数据进行计算。</p>
</li>
<li><p>Oozie：Oozie是一个管理Hdoop作业（job）的工作流程调度管理系统。Oozie协调作业就是通过时间（频率）和有效数据触发当前的Oozie工作流程。</p>
</li>
<li><p>Hbase：HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。</p>
</li>
<li><p>Hive：hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce<br>任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p>
</li>
<li><p>Mahout:Apache Mahout是个可扩展的机器学习和数据挖掘库，当前Mahout支持主要的4个用例：推荐挖掘：搜集用户动作并以此给用户推荐可能喜欢的事物。<br>聚集：收集文件并进行相关文件分组。分类：从现有的分类文档中学习，寻找文档中的相似特征，并为无标签的文档进行正确的归类。频繁项集挖掘：将一组项分组，<br>并识别哪些个别项会经常一起出现。</p>
</li>
<li><p>ZooKeeper：Zookeeper是Google的Chubby一个开源的实现。它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、<br>组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p>
</li>
</ul>
<h3 id="阿里云MaxCompute"><a href="#阿里云MaxCompute" class="headerlink" title="阿里云MaxCompute"></a>阿里云MaxCompute</h3><p>MaxCompute（大数据计算服务）是是一种快速、完全托管的TB&#x2F;PB级数据仓库解决方案。MaxCompute主要用于实时性要求不高的、批量结构化数据的存储和计算。<br>并可提供大数据分析建模服务。其特点如下： </p>
<ul>
<li>采用分布式架构高效处理海量数据</li>
<li>基于表的数据存储</li>
<li>于SQL的数据处理</li>
<li>支持多用户协同分析数据，多种权限管理方式，具有灵活的数据访问控制策略</li>
<li>兼容Hive</li>
</ul>
<p>MaxCompute架构<br><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/521857b4c5af453e8967446f719eee2c~tplv-k3u1fbpfcp-watermark.image"></p>
<p>MaxCompute功能</p>
<ul>
<li>数据存储</li>
</ul>
<p>适用于TB以上规模的存储及计算需求，最大可达EB级别。数据分布式存储，多副本冗余，数据存储对外仅开放表的操作接口，不提供文件系统访问接口。表数据列式存储，<br>默认高度压缩，后续将提供兼容ORC的Ali-ORC存储格式。<br>支持外表，将存储在OSS对象存储、OTS表格存储的数据映射为二维表。<br>支持Partition、Bucket的分区、分桶存储。<br>底层是盘古文件系统（不是HDFS）。<br>使用时，存储与计算解耦，不需要仅仅为了存储而扩大不必要的计算资源。</p>
<ul>
<li>数据通道<br>TUNNEL：提供高并发的离线数据上传下载服务。支持每天TB&#x2F;PB级别的数据导入导出。适合于全量数据或历史数据的批量导入。</li>
</ul>
<p>DataHub：针对实时数据上传的场景，具有延迟低、使用方便的特点，适用于增量数据的导入。Datahub还支持多种数据传输插件，包括Logstash、Flume、Fluentd、<br>Sqoop等。同时支持日志服务Log Service中的日志数据的一键投递至MaxCompute，进而利用大数据开发套件进行日志分析和挖掘。</p>
<ul>
<li>多种计算模型<br>SQL：以二维表的形式存储数据，支持多种数据类型，MaxCompute以二维表的形式存储数据，对外提供了SQL查询功能。不支持事务、索引及Update&#x2F;Delete等操作，<br>SQL语法与Oracle，MySQL等有一定差别。无法在毫秒级别返回结果。</li>
</ul>
<p>MapReduce：支持MapReduce java编程接口（提供优化增强的MaxCompute MapReduce，也提供高度兼容Hadoop的MapReduce版本）。不暴露文件系统，<br>输入输出都是表。通过MaxCompute客户端工具、Dataworks提交作业。</p>
<p>Graph：是一套面向迭代的图计算处理框架。图计算作业使用图进行建模，图由点（Vertex）和边（Edge）组成，点和边包含权值（Value）。通过迭代对图进行编辑、<br>演化，最终求解出结果，典型应用：PageRank、单源最短距离算法 、K-均值聚类算法等。</p>
<ul>
<li>Spark</li>
</ul>
<p>MaxCompute提供了Spark on MaxCompute的解决方案，在统一的计算资源和数据集权限体系之上，提供Spark计算框架，支持用户以熟悉的开发使用方式提交运行<br>Spark作业。</p>
<ul>
<li>交互式分析(Lightning)<br>MaxCompute产品的交互式查询服务。兼容PostgreSQL协议的JDBC&#x2F;ODBC接口。支持主流BI及SQL客户端工具的连接访问，如Tableau、帆软BI、Navicat、SQL<br>Workbench&#x2F;J等。</li>
</ul>
<h2 id="Hadoop是什么"><a href="#Hadoop是什么" class="headerlink" title="Hadoop是什么"></a>Hadoop是什么</h2><ul>
<li>Hadoop是一个由Apache基金会所开发的分布式系统基础架构。</li>
<li>主要解决，海量数据的存储和海量数据的分析计算问题。</li>
<li>广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈。</li>
</ul>
<h2 id="Hadoop的组成"><a href="#Hadoop的组成" class="headerlink" title="Hadoop的组成"></a>Hadoop的组成</h2><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/94def613dbab4f819ff61a0802b4a5d2~tplv-k3u1fbpfcp-watermark.image"></p>
<h3 id="HDFS架构概述"><a href="#HDFS架构概述" class="headerlink" title="HDFS架构概述"></a>HDFS架构概述</h3><ul>
<li>NameNode（nn）：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。</li>
<li>DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。</li>
<li>Secondary NameNode(2nn)：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</li>
</ul>
<h3 id="YARN架构概述"><a href="#YARN架构概述" class="headerlink" title="YARN架构概述"></a>YARN架构概述</h3><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0e22495656df4cb1b6bbf187dac7b733~tplv-k3u1fbpfcp-watermark.image"></p>
<h3 id="MapReduce架构概述"><a href="#MapReduce架构概述" class="headerlink" title="MapReduce架构概述"></a>MapReduce架构概述</h3><p>MapReduce将计算过程分为两个阶段：Map和Reduce</p>
<ul>
<li>Map阶段并行处理输入数据</li>
<li>Reduce阶段对Map结果进行汇总</li>
</ul>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2fe4c16a0a4b4ea3b04b80c2318513cb~tplv-k3u1fbpfcp-watermark.image"></p>
<h2 id="Hadoop分布式搭建"><a href="#Hadoop分布式搭建" class="headerlink" title="Hadoop分布式搭建"></a>Hadoop分布式搭建</h2>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zengjunjie1026.github.io/2023/08/16/hdfs/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="andrew">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="分子美食家的博客">
      <meta itemprop="description" content="做自己爱做的事，爱自己在做的事！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 分子美食家的博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/16/hdfs/" class="post-title-link" itemprop="url">hdfs</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-08-16 21:13:45 / 修改时间：21:13:50" itemprop="dateCreated datePublished" datetime="2023-08-16T21:13:45+08:00">2023-08-16</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="HDFS概述"><a href="#HDFS概述" class="headerlink" title="HDFS概述"></a>HDFS概述</h2><h3 id="HDFS产生背景"><a href="#HDFS产生背景" class="headerlink" title="HDFS产生背景"></a>HDFS产生背景</h3><p>随着数据量越来越大，在一个操作系统管辖的范围内存不下了，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种<br>系统来管理多台机器上的文件，这就是分布式文件管理系统。HDFS只是分布式文件管理系统中的一种。</p>
<h3 id="HDFS概念"><a href="#HDFS概念" class="headerlink" title="HDFS概念"></a>HDFS概念</h3><p>HDFS，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有<br>各自的角色。HDFS的设计适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用</p>
<h3 id="HDFS优缺点"><a href="#HDFS优缺点" class="headerlink" title="HDFS优缺点"></a>HDFS优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li><p>高容错性</p>
<ul>
<li>数据自动保存多个副本。它通过增加副本的形式，提高容错性；</li>
<li>某一个副本丢失以后，它可以自动恢复</li>
</ul>
</li>
<li><p>适合大数据处理</p>
<ul>
<li>数据规模：能够处理数据规模达到GB、TB、甚至PB级别的数据；</li>
<li>文件规模：能够处理百万规模以上的文件数量，数量相当之大。</li>
</ul>
</li>
<li><p>流式数据访问，它能保证数据的一致性。</p>
</li>
<li><p>可构建在廉价机器上，通过多副本机制，提高可靠性。</p>
</li>
</ul>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>不适合低延时数据访问，比如毫秒级的存储数据，是做不到的。</li>
<li>无法高效的对大量小文件进行存储。<ul>
<li>存储大量小文件的话，它会占用NameNode大量的内存来存储文件、目录和块信息。这样是不可取的，因为NameNode的内存总是有限的；</li>
<li>小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标。</li>
</ul>
</li>
<li>并发写入、文件随机修改。<ul>
<li>一个文件只能有一个写，不允许多个线程同时写；</li>
<li>仅支持数据append（追加），不支持文件的随机修改。</li>
</ul>
</li>
</ul>
<h3 id="HDFS组成架构"><a href="#HDFS组成架构" class="headerlink" title="HDFS组成架构"></a>HDFS组成架构</h3><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9fb5b498df7b444087880236c63cdc3d~tplv-k3u1fbpfcp-watermark.image"></p>
<p>这种架构主要由四个部分组成，分别为HDFS Client、NameNode、DataNode和Secondary NameNode。下面我们分别介绍这四个组成部分。</p>
<ul>
<li><p>Client：就是客户端。</p>
<ul>
<li>文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行存储；</li>
<li>与NameNode交互，获取文件的位置信息；</li>
<li>与DataNode交互，读取或者写入数据；</li>
<li>Client提供一些命令来管理HDFS，比如启动或者关闭HDFS；</li>
<li>Client可以通过一些命令来访问HDFS；</li>
</ul>
</li>
<li><p>NameNode：就是Master，它是一个主管、管理者。</p>
<ul>
<li>管理HDFS的名称空间；</li>
<li>管理数据块（Block）映射信息；</li>
<li>配置副本策略；<br>- 处理客户端读写请求。</li>
</ul>
</li>
<li><p>DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。</p>
<ul>
<li>存储实际的数据块</li>
<li>执行数据块的读&#x2F;写操作。</li>
</ul>
</li>
<li><p>Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。</p>
<ul>
<li>辅助NameNode，分担其工作量；</li>
<li>定期合并Fsimage和Edits，并推送给NameNode；</li>
<li>在紧急情况下，可辅助恢复NameNode。</li>
</ul>
</li>
</ul>
<h3 id="HDFS文件块大小"><a href="#HDFS文件块大小" class="headerlink" title="HDFS文件块大小"></a>HDFS文件块大小</h3><p>HDFS中的文件在物理上是分块存储（block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x<br>版本中是128M，老版本中是64M。HDFS的块比磁盘的块大，其目的是为了最小化寻址开销。如果块设置得足够大，从磁盘传输数据的<br>时间会明显大于定位这个块开始位置所需的时间。因而，传输一个由多个块组成的文件的时间取决于磁盘传输速率。如果寻址时间约为<br>10ms，而传输速率为100MB&#x2F;s，为了使寻址时间仅占传输时间的1%，我们要将块大小设置约为100MB。默认的块大小128MB。块的大小：<br>10ms<em>100</em>100M&#x2F;s &#x3D; 100M</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/32ad8b86eab94a68b65c10857a3c31eb~tplv-k3u1fbpfcp-watermark.image"></p>
<h3 id="HDFS写数据流程"><a href="#HDFS写数据流程" class="headerlink" title="HDFS写数据流程"></a>HDFS写数据流程</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c6014ed71d4c4d57ae45c7c958e02e7c~tplv-k3u1fbpfcp-watermark.image"></p>
<ul>
<li>客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。</li>
<li>NameNode返回是否可以上传。</li>
<li>客户端请求第一个block上传到哪几个datanode服务器上。</li>
<li>NameNode返回3个datanode节点，分别为dn1、dn2、dn3。</li>
<li>客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</li>
<li>dn1、dn2、dn3逐级应答客户端。</li>
<li>客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1收到一个packet就会传给dn2，<br>dn传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</li>
<li>当一个block传输完成之后，客户端再次请求NameNode上传第二个block的服务器。（重复执行3-7步）。</li>
</ul>
<h3 id="网络拓扑概念"><a href="#网络拓扑概念" class="headerlink" title="网络拓扑概念"></a>网络拓扑概念</h3><p>在本地网络中，两个节点被称为“彼此近邻”是什么意思？在海量数据处理中，其主要限制因素是节点之间数据的传输速率——带宽很稀缺。<br>这里的想法是将两个节点间的带宽作为距离的衡量标准。</p>
<p>节点距离：两个节点到达最近的共同祖先的距离总和。<br><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c5daea537fea42d7bc72fca6edc765c6~tplv-k3u1fbpfcp-watermark.image"></p>
<h3 id="HDFS读数据流程"><a href="#HDFS读数据流程" class="headerlink" title="HDFS读数据流程"></a>HDFS读数据流程</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b7689706f7194aafa32acdd07b9df0da~tplv-k3u1fbpfcp-watermark.image"></p>
<ul>
<li>客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</li>
<li>挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。</li>
<li>DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以packet为单位来做校验）。</li>
<li>客户端以packet为单位接收，先在本地缓存，然后写入目标文件。</li>
</ul>
<h2 id="MapReduce入门"><a href="#MapReduce入门" class="headerlink" title="MapReduce入门"></a>MapReduce入门</h2><h3 id="MapReduce定义"><a href="#MapReduce定义" class="headerlink" title="MapReduce定义"></a>MapReduce定义</h3><p>Mapreduce是一个分布式运算程序的编程框架，是用户开发“基于hadoop的数据分析应用”的核心框架。Mapreduce核心功能是将用户编写的<br>业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个hadoop集群上。</p>
<h3 id="MapReduce优缺点"><a href="#MapReduce优缺点" class="headerlink" title="MapReduce优缺点"></a>MapReduce优缺点</h3><ul>
<li><p>优点</p>
<ul>
<li>MapReduce易于编程。它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的PC机器上运行。<br>也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得MapReduce编程变得非常流行。</li>
<li>良好的扩展性。当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。</li>
<li>高容错性。MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，<br>它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由Hadoop内部完成的。</li>
<li>适合PB级以上海量数据的离线处理。这里加红字体离线处理，说明它适合离线处理而不适合在线处理。比如像毫秒级别的返回一个结果，<br>MapReduce很难做到。</li>
</ul>
</li>
<li><p>缺点 MapReduce不擅长做实时计算、流式计算、DAG（有向图）计算。</p>
<ul>
<li>实时计算。MapReduce无法像Mysql一样，在毫秒或者秒级内返回结果。</li>
<li>流式计算。流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定-<br>据源必须是静态的。</li>
<li>DAG（有向图）计算。多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，<br>而是使用后，每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。</li>
</ul>
<h3 id="MapReduce核心思想"><a href="#MapReduce核心思想" class="headerlink" title="MapReduce核心思想"></a>MapReduce核心思想</h3><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/591d6d1a27e243f7bf5be80ff9904e1b~tplv-k3u1fbpfcp-watermark.image"></p>
</li>
<li><p>分布式的运算程序往往需要分成至少2个阶段。</p>
</li>
<li><p>第一个阶段的maptask并发实例，完全并行运行，互不相干。</p>
</li>
<li><p>第二个阶段的reduce task并发实例互不相干，但是他们的数据依赖于上一个阶段的所有maptask并发实例的输出。</p>
</li>
<li><p>MapReduce编程模型只能包含一个map阶段和一个reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个mapreduce程序，串行运行。</p>
</li>
</ul>
<h3 id="MapReduce进程"><a href="#MapReduce进程" class="headerlink" title="MapReduce进程"></a>MapReduce进程</h3><p>一个完整的mapreduce程序在分布式运行时有三类实例进程：</p>
<ul>
<li>MrAppMaster：负责整个程序的过程调度及状态协调。</li>
<li>MapTask：负责map阶段的整个数据处理流程。</li>
<li>ReduceTask：负责reduce阶段的整个数据处理流程。</li>
</ul>
<h3 id="MapReduce编程规范"><a href="#MapReduce编程规范" class="headerlink" title="MapReduce编程规范"></a>MapReduce编程规范</h3><p>用户编写的程序分成三个部分：Mapper、Reducer和Driver。</p>
<ul>
<li><p>Mapper阶段</p>
<ul>
<li>用户自定义的Mapper要继承自己的父类</li>
<li>Mapper的输入数据是KV对的形式（KV的类型可自定义）</li>
<li>Mapper中的业务逻辑写在map()方法中</li>
<li>Mapper的输出数据是KV对的形式（KV的类型可自定义）</li>
</ul>
</li>
<li><p>Reducer阶段</p>
<ul>
<li>用户自定义的Reducer要继承自己的父类</li>
<li>Reducer的输入数据类型对应Mapper的输出数据类型，也是KV</li>
<li>Reducer的业务逻辑写在reduce()方法中</li>
<li>Reducetask进程对每一组相同k的&lt;k,v&gt;组调用一次reduce()方法</li>
</ul>
</li>
<li><p>Driver阶段</p>
</li>
</ul>
<p>整个程序需要一个Drvier来进行提交，提交的是一个描述了各种必要信息的job对象</p>
<blockquote>
<p>其实吧我们真实开发也不会说去写mr 但是还是建议大家把最简单的wordcount做了。</p>
</blockquote>
<h2 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h2><h3 id="Yarn-概述"><a href="#Yarn-概述" class="headerlink" title="Yarn 概述"></a>Yarn 概述</h3><p>Yarn 是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式<br>的操作系统平台，而 MapReduce 等运算程序则相当于运行于操作系统之上的应用程序。</p>
<h3 id="Yarn-基本架构"><a href="#Yarn-基本架构" class="headerlink" title="Yarn 基本架构"></a>Yarn 基本架构</h3><p>YARN 主要由 ResourceManager、NodeManager、ApplicationMaster 和 Container 等组件<br>构成<br><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6c85d606218e477bbfa8cdcdb7022af4~tplv-k3u1fbpfcp-watermark.image"></p>
<h3 id="Yarn-工作机制"><a href="#Yarn-工作机制" class="headerlink" title="Yarn 工作机制"></a>Yarn 工作机制</h3><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ac47a79a89a142e3b7fe9a09df062d77~tplv-k3u1fbpfcp-watermark.image"></p>
<ul>
<li>Mr 程序提交到客户端所在的节点。</li>
<li>Yarnrunner 向 Resourcemanager 申请一个 Application。 </li>
<li>rm 将该应用程序的资源路径返回给 yarnrunner。 </li>
<li>该程序将运行所需资源提交到 HDFS 上。 </li>
<li>程序资源提交完毕后，申请运行 mrAppMaster。 </li>
<li>RM 将用户的请求初始化成一个 task。 </li>
<li>其中一个 NodeManager 领取到 task 任务。</li>
<li>该 NodeManager 创建容器 Container，并产生 MRAppmaster。 </li>
<li>Container 从 HDFS 上拷贝资源到本地。 </li>
<li>MRAppmaster 向 RM 申请运行 maptask 资源。</li>
<li>RM 将运行 maptask 任务分配给另外两个 NodeManager，另两个 NodeManager 分别领取任务并创建容器。</li>
<li>MR 向两个接收到任务的 NodeManager 发送程序启动脚本，这两个 NodeManager分别启动 maptask，maptask 对数据分区排序。</li>
<li>MrAppMaster 等待所有 maptask 运行完毕后，向 RM 申请容器，运行 reduce task。 </li>
<li>reduce task 向 maptask 获取相应分区的数据。</li>
<li>程序运行完毕后，MR 会向 RM 申请注销自己。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">andrew</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
