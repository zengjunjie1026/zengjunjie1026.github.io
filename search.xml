<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>vim 技巧</title>
      <link href="/2023/08/21/vim-%E6%8A%80%E5%B7%A7/"/>
      <url>/2023/08/21/vim-%E6%8A%80%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="vim"><a href="#vim" class="headerlink" title="vim"></a>vim</h2><p>vim是一个常用的文本编辑工具，在远程服务器中更改系统配置中经常使用。</p><p>基础<br>vim的模式<br>Vim一般分为三种不同的模式，普通模式( normal mode )、编辑模式和命令模式.</p><h3 id="普通模式-normal-mode"><a href="#普通模式-normal-mode" class="headerlink" title="普通模式( normal mode )"></a>普通模式( normal mode )</h3><p>使用vim打开文件则进入普通模式。在普通模式下可通过按键 h、j、k、l来控制光标的移动，通过 x、d(delete) 、 y(yank) 、p(put)等按键可对文本进行操作，在该模式下，键盘按键被视为类似 Word下的快捷键的功能，而不是被视为简单的文本输入。</p><h3 id="编辑模式"><a href="#编辑模式" class="headerlink" title="编辑模式"></a>编辑模式</h3><p>在编辑模式下可对文件内容进行编辑。编辑模式下按键输入均被视为文本输入，而不再具备普通模式下的各种功能。用户可以通过按键ESC从编辑模式返回普通模式。</p><h3 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h3><p>在普通模式下，键盘输入 ‘ : ‘、 ‘ &#x2F; ‘、 ‘ ? ‘则光标移动至界面最下行，并等待进一步输入。之后Vim会根据用户输入执行相应的动作，如保存和退出、查找和替换、执行外部命令等。命令模式下同样通过ESC键返回普通模式。</p><p>普通模式下的操作文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim filename　　　//打开名为filename的文件</span><br><span class="line">    :w               //保存修改至源文件</span><br><span class="line">    :wq              //保存修改并退出</span><br><span class="line">    :q!              //不保存修改，直接退出</span><br><span class="line">    :w filename      //保存修改(选中的部分)至filename(其中filename为不存在重名的新文件)</span><br></pre></td></tr></table></figure><h2 id="进入编辑模式"><a href="#进入编辑模式" class="headerlink" title="进入编辑模式"></a>进入编辑模式</h2><p>常用小写的i和o即可，i代表当行这个光标位插入，o代表下一行插入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">i    //insert即插入模式，从光标所在位置开始插入，即插入的内容位于原光标所在位置字符之前</span><br><span class="line">I    //从光标所在行的行首开始插入</span><br><span class="line">a    //append即附加模式，从光标所在位置之后附加，即新增内容位于原光标所在位置字符之后</span><br><span class="line">A    //从光标所在行的行末开始附加</span><br><span class="line">o    //在光标所在行的下一行加入新一行</span><br><span class="line">O    //在光标所在行的上一行加入新一行</span><br><span class="line">R    //进入替换模式，屏幕下方会出现Replace提示，此时的输入会直接替换光标所在位置的字符，与Windows下的 <span class="number">0</span> 作用类似，同样通过ESC键返回</span><br></pre></td></tr></table></figure><h2 id="删除操作"><a href="#删除操作" class="headerlink" title="删除操作"></a>删除操作</h2><p>在普通模式下使用dd命令即可删除当行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x        //删除光标所在处的字符(其大写形式X为将光标之前的字符删除，相当于Backspace)</span><br><span class="line">dd     　//删除光标所在行的操作(常用)</span><br><span class="line">dw         //删除一个单词</span><br><span class="line">d3w      　//删除三个单词</span><br><span class="line">d$         //删除光标所在处至行尾的字符</span><br><span class="line">d4l        //删除光标所在处起的四个字符</span><br><span class="line">d2j        //删除两行</span><br></pre></td></tr></table></figure><p>同样的，如 2dd 指令则表示将dd指令重复两次，即为删除两行操作，2d2w 则表示将 d2w 操作执行两次，即删除四个单词。</p><h2 id="复制与粘贴"><a href="#复制与粘贴" class="headerlink" title="复制与粘贴"></a>复制与粘贴</h2><p>复制即通过 v 指令选定文本段，通过 y 指令复制内容，再通过 p 指令将文本放置在指定位置；剪切即通过 v 指令选定文本段，通过 d (或 x )指令删除内容，再通过 p 指令将文本放置在指定的位置； p 指令除了用于复制内容的粘贴外，还可以将上一次删除的内容粘贴在指定的位置，故而可以达到类似剪切的效果。对于 v 指令选中的文本，可以进行多种操作，包括复制(y)、删除(x&#x2F;d)、另存(:w filename)等，读者完全可以自行进行组合尝试。指令y和d的指令形式有许多相同之处，除了均有yy和dd这种针对一行内容的处理指令外，指令y可以与光标移动指令相结合，得到更好的使用效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">p                    //put命令，将剪贴的内容(注意，既可以是复制的内容，也可以为之前删除的内容)放置在光标后的位置，其大小字母P则表示放置在光标之前的位置</span><br><span class="line">v                    //进入虚拟选择模式(visual selection)，被选择的文本段被高亮显示(v的选择对象为字符，对应的大写字母V则是以行为单位选择)</span><br><span class="line">　　Ctrl + v　　　　　　　 //以矩形框的形式进行内容选择</span><br><span class="line">y                    //复制通过 v 操作选择的文本，或则其本身也可以与光标移动指令一同使用</span><br><span class="line">y5w                     //如y5w，则复制<span class="number">5</span>个单词(注意复制是从光标所在处开始的)</span><br><span class="line">yy    //复制光标所在行的内容</span><br><span class="line">y0    //复制光标所在位置至行首的内容</span><br><span class="line">y$    //复制光标所在位置至行尾的内容</span><br><span class="line">yG    //复制光标所在位置至文本结束的内容</span><br><span class="line">ynG   //复制指令与nG指令的结合</span><br><span class="line">　　　　　　//以及诸如y3w、y3j等指令</span><br></pre></td></tr></table></figure><h2 id="行跳转"><a href="#行跳转" class="headerlink" title="行跳转"></a>行跳转</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gg        //跳转至文件第一行</span><br><span class="line">G         //跳转至文件最后行</span><br><span class="line">nG        //跳转至文件第 n 行  </span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="撤销"><a href="#撤销" class="headerlink" title="撤销"></a>撤销</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">u            //撤销上一次操作</span><br><span class="line">U            //撤销对光标所在行的所有操作</span><br><span class="line">Ctrl+r    　 //重做上一操作</span><br></pre></td></tr></table></figure><h2 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/keyword         //按默认方向查找关键字</span><br><span class="line">?keyword         //按与默认方向相反的方向查找关键字</span><br><span class="line">n                //按与之前相同的查找顺序匹配下一个出现相同关键字的位置</span><br><span class="line">N                //按与之前相反的查找顺序匹配下一个出现相同关键字的位置</span><br><span class="line">　　　　　　　　　 //用户也可以通过Ctrl + o 和 Ctrl + i 进行位置的切换</span><br><span class="line"> </span><br></pre></td></tr></table></figure><h2 id="替换"><a href="#替换" class="headerlink" title="替换"></a>替换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">:s/old/new           //将光标所在行出现的第一个old替换为new(仅对该行的第一个old)             </span><br><span class="line">:s/old/new/g      　 // 将光标所在行出现的所有old替换为new            </span><br><span class="line">:s/old/new/gc     　 //同上，替换之前提示用户确认是否替换      </span><br><span class="line">:n,ms/old/new/g　　　//在n和m指定的行之间进行检查和替换    </span><br><span class="line">:%s/old/new/g　　　　//针对整个文本进行替换</span><br></pre></td></tr></table></figure><h2 id="修改编辑选项"><a href="#修改编辑选项" class="headerlink" title="修改编辑选项"></a>修改编辑选项</h2><p>修改 ～&#x2F;.vimrc 文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">:<span class="built_in">set</span> nu        　//显示行号，相应的<span class="built_in">set</span> nonu则为不显示行号</span><br><span class="line">:<span class="built_in">set</span> ic        　//搜索忽略大小写(ignore <span class="keyword">case</span>),取消即为 <span class="built_in">set</span> noic</span><br><span class="line">:<span class="built_in">set</span> hlsearch    //搜索时匹配的结果高亮显示</span><br><span class="line">:<span class="built_in">set</span> incserch    //设置搜索时的搜索顺序</span><br><span class="line">                //可以看到，在对应的选项前面加入前缀no即表示取消取消对应的选项</span><br><span class="line">:<span class="built_in">set</span> ruler　　　　//右下角展示状态栏</span><br><span class="line">:<span class="built_in">set</span>             //显示与系统默认设置不同的参数情况，即被修改过的参数情况</span><br><span class="line">:<span class="built_in">set</span> syntax on　 //设置Vim会根据语法以不同颜色显示不同的内容</span><br><span class="line">:<span class="built_in">set</span> syntax off</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pyspark mongodb</title>
      <link href="/2023/08/21/pyspark-mongodb/"/>
      <url>/2023/08/21/pyspark-mongodb/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>干净的百度</title>
      <link href="/2023/08/21/%E5%B9%B2%E5%87%80%E7%9A%84%E7%99%BE%E5%BA%A6/"/>
      <url>/2023/08/21/%E5%B9%B2%E5%87%80%E7%9A%84%E7%99%BE%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<p>在日常使用baidu的过程中，各种垃圾广告玷污眼睛，如何去除让人恶心的广告呢，方法很简单。</p><h2 id="下载chrome浏览器"><a href="#下载chrome浏览器" class="headerlink" title="#下载chrome浏览器"></a>#下载chrome浏览器</h2><h3 id="使用google扩展程序"><a href="#使用google扩展程序" class="headerlink" title="使用google扩展程序"></a>使用google扩展程序</h3><p>需要Google账号，这时你需要google访问助手，登入同步之后，打开扩展程序，点击开发人员选项。<br>加载已解压的扩展程序包，选择解压好的google访问助手</p><p><img src="https://img-blog.csdnimg.cn/20191130222515829.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDA4MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191130222528145.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDA4MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191130222648183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDA4MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><a href="http://chromecj.com/accessibility/2017-11/853/download.html">google访问助手下载地址</a><br>下载完后将后缀改为.rar,使用解压工具解压，可以显示包内容。<br>然后登入Google账号，打开刚刚的扩展程序，有google应用商店，搜索stylish，然后就可以下载各种各种的百度主题了。<br><img src="https://img-blog.csdnimg.cn/20191130223105303.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDA4MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>点击右下角的stye install就可以体验干净的百度了。</p><p>我的 百度。<br><img src="https://img-blog.csdnimg.cn/20191130223244882.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDA4MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>换用任何一台电脑，登入google account也可以同步所有安装过的插件，是不是很酷。</p>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mongodb hive</title>
      <link href="/2023/08/21/mongodb-hive/"/>
      <url>/2023/08/21/mongodb-hive/</url>
      
        <content type="html"><![CDATA[<p>.背景<br>公司希望使用MongoDB作为后端业务数据库，使用Hadoop平台作为数据平台。最开始是先把数据从MongoDB导出来，然后传到HDFS，然后用Hive&#x2F;MR处理。我感觉这也太麻烦了，现在不可能没有人想到这个问题，于是就搜了一下，结果真找到一个MongoDB Connector for Hadoop</p><p>1.版本一定要按它要求的来，jar包去<a href="http://mvnrepository.com/%E4%B8%8B%E8%BD%BD%E5%B0%B1%E5%8F%AF%E4%BB%A5%E4%BA%86%EF%BC%8C%E4%BD%BF%E7%94%A8Hive%E5%8F%AA%E9%9C%80%E8%A6%81%E4%B8%89%E4%B8%AA%EF%BC%9A">http://mvnrepository.com/下载就可以了，使用Hive只需要三个：</a><br>mongo-hadoop-core-1.5.1.jar<br>mongo-hadoop-hive-1.5.1.jar<br>mongo-java-driver-3.2.1.jar<br>2.将jar包拷到 &lt;{HADOOP_HOME}&#x2F;lib与</script>{HIVE_HOME}&#x2F;lib下，然后启动Hive，加入jar包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ hive</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/home/hadoop/opt/apache-hive-1.2.1-bin/lib/hive-common-1.2.1.jar!/hive-log4j.properties</span><br><span class="line">hive&gt; add jar /opt/module/hadoop/opt/hive/lib/mongo-hadoop-hive-1.5.1.jarr;</span><br><span class="line">hive&gt; add jar /opt/module/hadoop/opt/hive/lib/mongo-java-driver-3.2.1.jarr;</span><br></pre></td></tr></table></figure><p>Hive Usage有两种连接方式:</p><p>其一MongoDB-based 直接连接hidden节点，使用 com.mongodb.hadoop.hive.MongoStorageHandler做数据Serde<br>其二BSON-based 将数据dump成bson文件，上传到HDFS系统，使用 com.mongodb.hadoop.hive.BSONSerDe</p><p>MongoDB-based方式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; CREATE TABLE eventlog</span><br><span class="line">    &gt; ( </span><br><span class="line">    &gt;   <span class="built_in">id</span> string,</span><br><span class="line">    &gt;   userid string,</span><br><span class="line">    &gt;   <span class="built_in">type</span> string,</span><br><span class="line">    &gt;   objid string,</span><br><span class="line">    &gt;   time string,</span><br><span class="line">    &gt;   <span class="built_in">source</span> string</span><br><span class="line">    &gt; )</span><br><span class="line">    &gt; STORED BY <span class="string">&#x27;com.mongodb.hadoop.hive.MongoStorageHandler&#x27;</span> </span><br><span class="line">    &gt; WITH SERDEPROPERTIES(<span class="string">&#x27;mongo.columns.mapping&#x27;</span>=<span class="string">&#x27;&#123;&quot;id&quot;:&quot;_id&quot;&#125;&#x27;</span>) </span><br><span class="line">    &gt; TBLPROPERTIES(<span class="string">&#x27;mongo.uri&#x27;</span>=<span class="string">&#x27;mongodb://username:password@ip:port/xxx.xxxxxx&#x27;</span>);</span><br><span class="line">hive&gt; <span class="keyword">select</span> * from eventlog <span class="built_in">limit</span> 10;</span><br><span class="line">OK</span><br><span class="line">5757c2783d6b243330ec6b25    NULL    shb NULL    2016-06-08 15:00:07 NULL</span><br><span class="line">5757c27a3d6b243330ec6b26    NULL    shb NULL    2016-06-08 15:00:10 NULL</span><br><span class="line">5757c27e3d6b243330ec6b27    NULL    shb NULL    2016-06-08 15:00:14 NULL</span><br><span class="line">5757c2813d6b243330ec6b28    NULL    shb NULL    2016-06-08 15:00:17 NULL</span><br><span class="line">5757ee443d6b242900aead78    NULL    shb NULL    2016-06-08 18:06:59 NULL</span><br><span class="line">5757ee543d6b242900aead79    NULL    smb NULL    2016-06-08 18:07:16 NULL</span><br><span class="line">5757ee553d6b242900aead7a    NULL    cmcs    NULL    2016-06-08 18:07:17 NULL</span><br><span class="line">5757ee593d6b242900aead7b    NULL    vspd    NULL    2016-06-08 18:07:21 NULL</span><br><span class="line">575b73b2de64cc26942c965c    NULL    shb NULL    2016-06-11 10:13:06 NULL</span><br><span class="line">575b73b5de64cc26942c965d    NULL    shb NULL    2016-06-11 10:13:09 NULL</span><br><span class="line">Time taken: 0.101 seconds, Fetched: 10 row(s)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这时HDFS里是没有存任何数据的，只有与表名一样的文件夹</p><p>当你处理的时候，它是直接处理mongo里最新的数据。当然，如果你想存到HDFS里也可以，用CTAS语句就可以。<br>hive&gt; create table qsstest as select * from eventlog limit 10;</p><p>还可以下载下来呢<br>PS：mongo的用户要有读写权限，jar包别忘了拷进去！<br>另一种方式我感觉有点没必要，没试，但我找到一篇博客详细写了。<br>下面转自：MongoDB与Hadoop技术栈的整合应用<br>BSON-based方式</p><p>BSON-based需要先将数据dump出来，但这个时候的dump与export不一样，不需要关心具体的数据内容,不需要指定fields list.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mongodump --host=datatask01:29017 --db=<span class="built_in">test</span> --collection=ldc_test --out=/tmp</span><br><span class="line">hdfs dfs -<span class="built_in">mkdir</span> /dev_test/dli/bson_demo/</span><br><span class="line">hdfs dfs -put /tmp/test/ldc_test.bson /dev_test/dli/bson_demo/</span><br><span class="line">- 创建映射表</span><br><span class="line">create external table temp.ldc_test_bson</span><br><span class="line">(</span><br><span class="line">  <span class="built_in">id</span> string,</span><br><span class="line">  fav_id array&lt;int&gt;,</span><br><span class="line">  info struct&lt;github:string, location:string&gt;</span><br><span class="line">)</span><br><span class="line">ROW FORMAT SERDE <span class="string">&quot;com.mongodb.hadoop.hive.BSONSerDe&quot;</span></span><br><span class="line">WITH SERDEPROPERTIES(<span class="string">&#x27;mongo.columns.mapping&#x27;</span>=<span class="string">&#x27;&#123;&quot;id&quot;:&quot;id&quot;,&quot;fav_id&quot;:&quot;fav_id&quot;,&quot;info.github&quot;:&quot;info.github&quot;,&quot;info.location&quot;:&quot;info.location&quot;&#125;&#x27;</span>)</span><br><span class="line">STORED AS INPUTFORMAT <span class="string">&quot;com.mongodb.hadoop.mapred.BSONFileInputFormat&quot;</span></span><br><span class="line">OUTPUTFORMAT <span class="string">&quot;com.mongodb.hadoop.hive.output.HiveBSONFileOutputFormat&quot;</span></span><br><span class="line">location <span class="string">&#x27;/dev_test/dli/bson_demo/&#x27;</span>;</span><br></pre></td></tr></table></figure><p>查询一下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://hd-cosmos-01:10000/default&gt; <span class="keyword">select</span> * from temp.ldc_test_mongo;</span><br><span class="line">+--------------------+------------------------+-----------------------------------------------------------------+--+</span><br><span class="line">| ldc_test_mongo.id  | ldc_test_mongo.fav_id  |                       ldc_test_mongo.info                       |</span><br><span class="line">+--------------------+------------------------+-----------------------------------------------------------------+--+</span><br><span class="line">| @Tony_老七           | [3,33,333,3333,33333]  | &#123;<span class="string">&quot;github&quot;</span>:<span class="string">&quot;https://github.com/tonylee0329&quot;</span>,<span class="string">&quot;location&quot;</span>:<span class="string">&quot;SH/CN&quot;</span>&#125;  |</span><br><span class="line">+--------------------+------------------------+-----------------------------------------------------------------+--+</span><br><span class="line">1 row selected (0.345 seconds)</span><br></pre></td></tr></table></figure><p>打开数组可以这样</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">SELECT <span class="built_in">id</span>, fid</span><br><span class="line">FROM temp.ldc_test_mongo LATERAL VIEW explode(fav_id) favids AS fid;</span><br><span class="line">-- 访问struct结构数据 </span><br><span class="line"><span class="keyword">select</span> <span class="built_in">id</span>, info.github from temp.ldc_test_mongo</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python mail</title>
      <link href="/2023/08/21/python-mail/"/>
      <url>/2023/08/21/python-mail/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> smtplib</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> email.mime.multipart <span class="keyword">import</span> MIMEMultipart</span><br><span class="line"><span class="keyword">from</span> email.mime.text <span class="keyword">import</span> MIMEText</span><br><span class="line"><span class="keyword">from</span> loguru <span class="keyword">import</span> logger</span><br><span class="line"></span><br><span class="line">mail_host = <span class="string">&#x27;smtp.163.com&#x27;</span></span><br><span class="line"><span class="comment"># 163用户名</span></span><br><span class="line">mail_user = <span class="string">&#x27;username&#x27;</span></span><br><span class="line"><span class="comment"># 密码(部分邮箱为授权码)</span></span><br><span class="line">mail_pass = <span class="string">&#x27;--------------&#x27;</span></span><br><span class="line"><span class="comment"># 邮件发送方邮箱地址</span></span><br><span class="line">sender = <span class="string">&#x27;sender@163.com&#x27;</span></span><br><span class="line"><span class="comment"># ff</span></span><br><span class="line"><span class="comment"># 邮件接受方邮箱地址，注意需要[]包裹，这意味着你可以写多个邮件地址群发</span></span><br><span class="line">receivers = [<span class="string">&quot;xxx@email.com&quot;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send</span>(<span class="params">title, messages</span>):</span><br><span class="line">    <span class="comment"># 设置email信息</span></span><br><span class="line">    <span class="comment"># 邮件内容设置</span></span><br><span class="line">    message = MIMEText(messages, <span class="string">&#x27;plain&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="comment"># message= MIMEMultipart(&#x27;mixed&#x27;)</span></span><br><span class="line">    <span class="comment"># 邮件主题</span></span><br><span class="line">    message[<span class="string">&#x27;Subject&#x27;</span>] = title</span><br><span class="line">    <span class="comment"># 发送方信息</span></span><br><span class="line">    message[<span class="string">&#x27;From&#x27;</span>] = sender</span><br><span class="line">    <span class="comment"># 接受方信息</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 登录并发送邮件</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        smtpObj = smtplib.SMTP(mail_host)</span><br><span class="line">        <span class="comment"># smtpObj = smtplib.SMTP_SSL(mail_host)</span></span><br><span class="line">        <span class="comment"># 连接到服务器</span></span><br><span class="line">        smtpObj.connect(mail_host, <span class="number">25</span>)</span><br><span class="line">        smtpObj.starttls()</span><br><span class="line">        <span class="comment"># 登录到服务器</span></span><br><span class="line">        smtpObj.login(mail_user, mail_pass)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 发送</span></span><br><span class="line">        <span class="keyword">for</span> receiver <span class="keyword">in</span> receivers:</span><br><span class="line">            message[<span class="string">&quot;To&quot;</span>] = <span class="string">&quot;, &quot;</span>.join(message)</span><br><span class="line">            <span class="comment"># message[&#x27;To&#x27;] = receiver</span></span><br><span class="line">            smtpObj.sendmail(</span><br><span class="line">                sender, receiver, message.as_string())</span><br><span class="line">        <span class="comment"># 退出</span></span><br><span class="line">        smtpObj.quit()</span><br><span class="line">        logger.info(<span class="string">&#x27;success&#x27;</span>)</span><br><span class="line">    <span class="keyword">except</span> smtplib.SMTPException <span class="keyword">as</span> e:</span><br><span class="line">        logger.error(<span class="string">f&#x27;error <span class="subst">&#123;e&#125;</span>&#x27;</span>)  <span class="comment"># 打印错误</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        send(<span class="string">&quot;test&quot;</span>,<span class="string">f&quot;hello_<span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br><span class="line">        time.sleep(<span class="number">3</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>supervisor</title>
      <link href="/2023/08/20/supervisor/"/>
      <url>/2023/08/20/supervisor/</url>
      
        <content type="html"><![CDATA[<p>ubuntu supervisor进程管理<br>Supervisor 是一个用 Python 写的进程管理工具，可以很方便的对进程进行启动、停止、重启等操作。</p><p>安装命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install supervisor</span><br></pre></td></tr></table></figure><p>安装成功后，会在&#x2F;etc&#x2F;supervisor目录下，生成supervisord.conf配置文件。</p><p>你也可以使用echo_supervisord_conf &gt; supervisord.conf命令，生成默认的配置文件（不建议，内容比较多）。</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[unix_http_server]</span><br><span class="line"><span class="attribute">file</span><span class="operator">=/</span>var/supervisor/supervisor.sock   <span class="comment">;UNIX socket 文件，supervisorctl 会使用</span></span><br><span class="line"><span class="comment">;chmod=0700                 ;socket文件的mode，默认是0700</span></span><br><span class="line"><span class="comment">;chown=nobody:nogroup       ;socket文件的owner，格式：uid:gid</span></span><br><span class="line"></span><br><span class="line"><span class="comment">;[inet_http_server]         ;HTTP服务器，提供web管理界面</span></span><br><span class="line"><span class="comment">;port=127.0.0.1:9001        ;Web管理后台运行的IP和端口，如果开放到公网，需要注意</span></span><br><span class="line">安全性</span><br><span class="line"><span class="comment">;username=andrew             ;登录管理后台的用户名</span></span><br><span class="line"><span class="comment">;password=python             ;登录管理后台的密码</span></span><br><span class="line"></span><br><span class="line">[supervisord]</span><br><span class="line"><span class="attribute">logfile</span><span class="operator">=/</span>Users/andrew/logs/supervisord.log <span class="comment">;日志文件，默认是 $CWD/supervisord.log</span></span><br><span class="line">logfile_maxbytes<span class="operator">=</span><span class="number">50</span>MB        <span class="comment">;日志文件大小，超出会rotate，默认 50MB，如果设成0，</span></span><br><span class="line">表示不限制大小</span><br><span class="line">logfile_backups<span class="operator">=</span><span class="number">10</span>           <span class="comment">;日志文件保留备份数量默认10，设为0表示不备份</span></span><br><span class="line"><span class="attribute">loglevel</span><span class="operator">=</span>info                <span class="comment">;日志级别，默认info，其它: debug,warn,trace</span></span><br><span class="line"><span class="attribute">pidfile</span><span class="operator">=/</span>var/supervisor/supervisord.pid <span class="comment">;pid 文件</span></span><br><span class="line"><span class="attribute">nodaemon</span><span class="operator">=</span>false               <span class="comment">;是否在前台启动，默认是false，即以 daemon 的方式启&gt;动</span></span><br><span class="line"><span class="attribute">minfds</span><span class="operator">=</span><span class="number">1024</span>                  <span class="comment">;可以打开的文件描述符的最小值，默认 1024</span></span><br><span class="line"><span class="attribute">minprocs</span><span class="operator">=</span><span class="number">200</span>                 <span class="comment">;可以打开的进程数的最小值，默认 200</span></span><br></pre></td></tr></table></figure><p>进程配置会读取&#x2F;etc&#x2F;supervisor&#x2F;conf.d目录下的*.conf配置文件，我们在此目录下创建一个hwapp.conf进程配置文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[program:frpc-proxys]</span><br><span class="line">directory = /Users/andrew/frp_0.30.0_darwin_amd64</span><br><span class="line"><span class="built_in">command</span> = /Users/andrew/frp_0.30.0_darwin_amd64/frpc -c /Users/andrew/frp_0.30.0_darwin_amd64/frpc-aliyun-5900.ini</span><br><span class="line">autostart = True</span><br><span class="line">autorestart = True</span><br><span class="line">user = andrew</span><br><span class="line">startsecs=3</span><br><span class="line">stderr_logfile=/Users/andrew/logs/frpc-err.log</span><br><span class="line">stdout_logfile=/Users/andrew/logs/frpc.log</span><br><span class="line">stdout_logfile_maxbytes=200MB</span><br></pre></td></tr></table></figure><p>设置开机自启和启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl <span class="built_in">enable</span> supervisord</span><br><span class="line">sudo systemctl start supervisord</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>hive cheatsheet</title>
      <link href="/2023/08/20/hive-cheatsheet/"/>
      <url>/2023/08/20/hive-cheatsheet/</url>
      
        <content type="html"><![CDATA[<h3 id="1-Hive导出到-csv文件"><a href="#1-Hive导出到-csv文件" class="headerlink" title="1. Hive导出到.csv文件"></a>1. Hive导出到.csv文件</h3><p>由于Hive中导出的文件不是以逗号，而是以Tab（或者说’\t’）为分隔符的，因此，下面的命令自己试过可以转换为逗号分隔的文件，也就是真正的csv文件。</p><p>当然，有时候可能还需要跟转码的工具进行组合，转换编码格式。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sed -i ‘s/\t/,/g’ xxx.csv</span><br><span class="line">``````</span><br><span class="line">当然，第一步是</span><br><span class="line">```bash</span><br><span class="line">hive -e “SQL语句” &gt; xxx.csv</span><br></pre></td></tr></table></figure><p>所以完整的流程代码是</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive -e <span class="string">&quot;SQL query&quot;</span> &gt; xxx.csv</span><br><span class="line">sed -i <span class="string">&#x27;s/\t/,/g&#x27;</span> xxx.csv</span><br></pre></td></tr></table></figure><h3 id="2-Hive导入-csv文件建表"><a href="#2-Hive导入-csv文件建表" class="headerlink" title="2. Hive导入.csv文件建表"></a>2. Hive导入.csv文件建表</h3><p>注意：</p><p>为了配合csv文件，建表的时候，最后一行的row format delimited fields terminated by ‘,’;必须要有，否则列会出问题</p><p>（这牵涉到csv和tsv等问题）</p><p>所以，在Hive下完整的删表建表导数据的流程如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">drop table <span class="keyword">if</span> exists table_name;</span><br><span class="line">CREATE EXTERNAL TABLE beike.beike_ershoufang (</span><br><span class="line">    details_name string,</span><br><span class="line">    postition_url string ,</span><br><span class="line">    house_url string,</span><br><span class="line">    house_id string,</span><br><span class="line">    house_info string,</span><br><span class="line">    follew_info string,</span><br><span class="line">    subway string,</span><br><span class="line">    total_price <span class="built_in">float</span>,</span><br><span class="line">    total_price_danwei string,</span><br><span class="line">    unit_price <span class="built_in">float</span>,</span><br><span class="line">    district string,</span><br><span class="line">    city_name string,</span><br><span class="line">    fetchtime timestamp</span><br><span class="line">)COMMENT <span class="string">&#x27;贝壳二手房&#x27;</span></span><br><span class="line">PARTITIONED BY (dt STRING, cd3 STRING)</span><br><span class="line">row format delimited fields terminated by <span class="string">&#x27;,&#x27;</span>;</span><br><span class="line"></span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">&#x27;/home/andrew/output.csv&#x27;</span> </span><br><span class="line">into table  beike.beike_ershoufang PARTITION(dt=<span class="string">&#x27;2017-03-31&#x27;</span> ,cd3=<span class="string">&#x27;1389&#x27;</span>);;</span><br></pre></td></tr></table></figure><h3 id="3-Hive看包括行数在内的信息"><a href="#3-Hive看包括行数在内的信息" class="headerlink" title="3. Hive看包括行数在内的信息"></a>3. Hive看包括行数在内的信息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">show tblproperties table_name;</span><br><span class="line">desc formatted table_name;</span><br></pre></td></tr></table></figure><h3 id="4-Hive一次写入一个表的多个分区的数据"><a href="#4-Hive一次写入一个表的多个分区的数据" class="headerlink" title="4. Hive一次写入一个表的多个分区的数据"></a>4. Hive一次写入一个表的多个分区的数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> hive.exec.dynamic.partition=<span class="literal">true</span>;</span><br><span class="line"><span class="built_in">set</span> hive.exec.dynamic.partition.mode=nonstrict;</span><br><span class="line">insert overwrite table table1 partition(partition_column)</span><br><span class="line"><span class="keyword">select</span> col1, col2,..., partition_column from table1;</span><br></pre></td></tr></table></figure><h3 id="5-Hive一次写入大量分区"><a href="#5-Hive一次写入大量分区" class="headerlink" title="5. Hive一次写入大量分区"></a>5. Hive一次写入大量分区</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> hive.exec.max.dynamic.<span class="attribute">partitions</span>=100000;</span><br><span class="line">--每一个mapreduce job允许创建的分区的最大数量，如果超过了这个数量就会报错</span><br><span class="line"><span class="built_in">set</span> hive.exec.max.dynamic.partitions.<span class="attribute">pernode</span>=100000;</span><br><span class="line">--hive.exec.max.created.files ：所有的mapreduce job允许创建的文件的最大数量</span><br><span class="line"><span class="built_in">set</span> hive.exec.max.created.<span class="attribute">files</span>=10000;</span><br></pre></td></tr></table></figure><h3 id="6避免产生小文件"><a href="#6避免产生小文件" class="headerlink" title="6避免产生小文件"></a>6避免产生小文件</h3><p>–在MapReduce的任务结束时合并小文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> hive.merge.mapredfiles=<span class="literal">true</span>;</span><br></pre></td></tr></table></figure><h3 id="7Hive开启本地模式"><a href="#7Hive开启本地模式" class="headerlink" title="7Hive开启本地模式"></a>7Hive开启本地模式</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> hive.exec.mode.local.auto=<span class="literal">true</span>;</span><br></pre></td></tr></table></figure><h3 id="8查询打印表头"><a href="#8查询打印表头" class="headerlink" title="8查询打印表头"></a>8查询打印表头</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> hive.cli.print.header=<span class="literal">true</span>;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hive elasticsearch</title>
      <link href="/2023/08/20/hive-elasticsearch/"/>
      <url>/2023/08/20/hive-elasticsearch/</url>
      
        <content type="html"><![CDATA[<h2 id="需要同步的elastic表"><a href="#需要同步的elastic表" class="headerlink" title="需要同步的elastic表"></a>需要同步的elastic表</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><span class="line">add jar hdfs:///elasticsearch-jars/elasticsearch-hadoop-hive-8.1.1.jar;</span><br><span class="line">-- create database ods_beike;</span><br><span class="line">CREATE EXTERNAL TABLE ods_beike.ershoufang_detail_from_es(</span><br><span class="line"></span><br><span class="line">house_url string comment &#x27;house url&#x27;,</span><br><span class="line">house_id string comment &#x27;house id&#x27;,</span><br><span class="line">title string comment &#x27;标题&#x27;,</span><br><span class="line">unit string comment &#x27;&#x27;,</span><br><span class="line">main_info string comment &#x27;厅房&#x27;,</span><br><span class="line">type_main string comment &#x27;direction&#x27;,</span><br><span class="line">type_sub string comment  &#x27;&#x27;,</span><br><span class="line">district_detail string comment  &#x27;&#x27;,</span><br><span class="line">districr_url  string comment  &#x27;小区url&#x27;,</span><br><span class="line">district_detail_url string comment  &#x27;&#x27;,</span><br><span class="line">communityname string comment  &#x27;小区信息&#x27;,</span><br><span class="line">communityurl string  comment &#x27;小区url&#x27;,</span><br><span class="line">district string comment &#x27;区或者县&#x27;,</span><br><span class="line">area string comment &#x27;房子面积&#x27;,</span><br><span class="line">year string comment &#x27;建成年份&#x27;,</span><br><span class="line">fetch_time timestamp,</span><br><span class="line">fundamental_values</span><br><span class="line">    struct&lt;</span><br><span class="line">  house_con : string,</span><br><span class="line">       house_floor:string,</span><br><span class="line">     house_area:string,</span><br><span class="line">        house_struct:string,</span><br><span class="line">       house_contruct_type:string,</span><br><span class="line">       house_direction:string,</span><br><span class="line">       house_construction:string,</span><br><span class="line">        house_detraction:string,</span><br><span class="line">       elevtor_percent:string,</span><br><span class="line">      warn_type:string,</span><br><span class="line">       has_elevtor:string,</span><br><span class="line">       gas_price:string,</span><br><span class="line">        bighouse_type:string,</span><br><span class="line">    userful_area:string,</span><br><span class="line">        water_type:string,</span><br><span class="line">        power_type:string,</span><br><span class="line">        rent_area:string</span><br><span class="line"></span><br><span class="line">    &gt;,</span><br><span class="line"></span><br><span class="line">sells_values  struct&lt;</span><br><span class="line">up_time: string ,--comment &#x27;挂牌时间&#x27;,</span><br><span class="line">sell_type: string, --comment  --&quot;交易权属&quot;,</span><br><span class="line"> last_sell: string, --comment --&quot;上次交易&quot;,</span><br><span class="line"> house_type :string, --comment -- &quot;房屋用途&quot;,</span><br><span class="line">house_age :string, --comment  --&quot;房屋年限&quot;: ,</span><br><span class="line"> property_type: string ,--comment  ,--&quot;产权所属&quot;,</span><br><span class="line"> mostage_type: string ,--comment  ,--&quot;抵押信息&quot;,</span><br><span class="line"> house_paper: string ,--comment ,-- &quot;房本备件&quot; ,</span><br><span class="line"> house_validation_code :string ,--comment  &quot;房源核验码&quot;,</span><br><span class="line">house_validation_code2: string ,-- comment  &#x27;房源核验统一编码&#x27; ,</span><br><span class="line">house_validation_code3 :string ,--comment  &#x27;房管局核验码&#x27; ,</span><br><span class="line"> house_code: string, --comment  &#x27;房源编码&#x27;,</span><br><span class="line"> code4: string,-- comment , --&quot;房源核验编码&quot;,</span><br><span class="line">code5: string --comment --comment &#x27;房协编码&#x27;</span><br><span class="line">&gt;</span><br><span class="line">)</span><br><span class="line">STORED BY &#x27;org.elasticsearch.hadoop.hive.EsStorageHandler&#x27;</span><br><span class="line">TBLPROPERTIES(</span><br><span class="line">    &#x27;es.resource&#x27; = &#x27;beike_ershoufang_details_english/doc&#x27;,</span><br><span class="line">    &#x27;es.nodes&#x27; = &#x27;http://10.147.20.10&#x27;,</span><br><span class="line">    &#x27;es.port&#x27;=&#x27;9200&#x27;,</span><br><span class="line">    &#x27;es.index.auto.create&#x27;=&#x27;false&#x27;,</span><br><span class="line">    &#x27;es.read.metadata&#x27;=&#x27;true&#x27;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">## 目的表</span><br><span class="line">add jar hdfs:///elasticsearch-jars/elasticsearch-hadoop-hive-8.1.1.jar;</span><br><span class="line">-- create database ods_beike;</span><br><span class="line">CREATE EXTERNAL TABLE ods_beike.ershoufang_detail_from_es2(</span><br><span class="line"></span><br><span class="line">house_url string comment &#x27;house url&#x27;,</span><br><span class="line">house_id string comment &#x27;house id&#x27;,</span><br><span class="line">title string comment &#x27;标题&#x27;,</span><br><span class="line">unit string comment &#x27;&#x27;,</span><br><span class="line">main_info string comment &#x27;厅房&#x27;,</span><br><span class="line">type_main string comment &#x27;direction&#x27;,</span><br><span class="line">type_sub string comment  &#x27;&#x27;,</span><br><span class="line">district_detail string comment  &#x27;&#x27;,</span><br><span class="line">districr_url  string comment  &#x27;小区url&#x27;,</span><br><span class="line">district_detail_url string comment  &#x27;&#x27;,</span><br><span class="line">communityname string comment  &#x27;小区信息&#x27;,</span><br><span class="line">communityurl string  comment &#x27;小区url&#x27;,</span><br><span class="line">district string comment &#x27;区或者县&#x27;,</span><br><span class="line">area string comment &#x27;房子面积&#x27;,</span><br><span class="line">year string comment &#x27;建成年份&#x27;,</span><br><span class="line">fetch_time timestamp,</span><br><span class="line">fundamental_values</span><br><span class="line">    struct&lt;</span><br><span class="line">  house_con : string,</span><br><span class="line">       house_floor:string,</span><br><span class="line">     house_area:string,</span><br><span class="line">        house_struct:string,</span><br><span class="line">       house_contruct_type:string,</span><br><span class="line">       house_direction:string,</span><br><span class="line">       house_construction:string,</span><br><span class="line">        house_detraction:string,</span><br><span class="line">       elevtor_percent:string,</span><br><span class="line">      warn_type:string,</span><br><span class="line">       has_elevtor:string,</span><br><span class="line">       gas_price:string,</span><br><span class="line">        bighouse_type:string,</span><br><span class="line">    userful_area:string,</span><br><span class="line">        water_type:string,</span><br><span class="line">        power_type:string,</span><br><span class="line">        rent_area:string</span><br><span class="line"></span><br><span class="line">    &gt;,</span><br><span class="line"></span><br><span class="line">sells_values  struct&lt;</span><br><span class="line">up_time: string ,--comment &#x27;挂牌时间&#x27;,</span><br><span class="line">sell_type: string, --comment  --&quot;交易权属&quot;,</span><br><span class="line"> last_sell: string, --comment --&quot;上次交易&quot;,</span><br><span class="line"> house_type :string, --comment -- &quot;房屋用途&quot;,</span><br><span class="line">house_age :string, --comment  --&quot;房屋年限&quot;: ,</span><br><span class="line"> property_type: string ,--comment  ,--&quot;产权所属&quot;,</span><br><span class="line"> mostage_type: string ,--comment  ,--&quot;抵押信息&quot;,</span><br><span class="line"> house_paper: string ,--comment ,-- &quot;房本备件&quot; ,</span><br><span class="line"> house_validation_code :string ,--comment  &quot;房源核验码&quot;,</span><br><span class="line">house_validation_code2: string ,-- comment  &#x27;房源核验统一编码&#x27; ,</span><br><span class="line">house_validation_code3 :string ,--comment  &#x27;房管局核验码&#x27; ,</span><br><span class="line"> house_code: string, --comment  &#x27;房源编码&#x27;,</span><br><span class="line"> code4: string,-- comment , --&quot;房源核验编码&quot;,</span><br><span class="line">code5: string --comment --comment &#x27;房协编码&#x27;</span><br><span class="line">&gt;</span><br><span class="line">)</span><br><span class="line">STORED BY &#x27;org.elasticsearch.hadoop.hive.EsStorageHandler&#x27;</span><br><span class="line">TBLPROPERTIES(</span><br><span class="line">    &#x27;es.resource&#x27; = &#x27;beike_ershoufang_details_english/doc&#x27;,</span><br><span class="line">    &#x27;es.nodes&#x27; = &#x27;http://10.147.20.96&#x27;,</span><br><span class="line">    &#x27;es.port&#x27;=&#x27;9200&#x27;,</span><br><span class="line">    &#x27;es.index.auto.create&#x27;=&#x27;false&#x27;,</span><br><span class="line">    &#x27;es.read.metadata&#x27;=&#x27;true&#x27;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">## 同步</span><br><span class="line"></span><br><span class="line">select count(*) from  ods_beike.ershoufang_detail_from_es2;</span><br><span class="line">desc ods_beike.ershoufang_detail_from_es2;</span><br><span class="line"></span><br><span class="line">insert into table ods_beike.ershoufang_detail_from_es2</span><br><span class="line">select * from ods_beike.ershoufang_detail_from_es;</span><br><span class="line"></span><br><span class="line">select count(*) from  ods_beike.ershoufang_detail_from_es2;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>deeplearning/sklearn</title>
      <link href="/2023/08/18/deeplearning-sklearn/"/>
      <url>/2023/08/18/deeplearning-sklearn/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>pykafka</title>
      <link href="/2023/08/18/pykafka/"/>
      <url>/2023/08/18/pykafka/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pykafka <span class="keyword">import</span> KafkaClient</span><br><span class="line"></span><br><span class="line">client = KafkaClient(hosts=<span class="string">&quot;localhost:9092&quot;</span>)</span><br><span class="line"></span><br><span class="line">topic = client.topics[<span class="string">&#x27;maoyan_wish&#x27;</span>]</span><br><span class="line">consumer = topic.get_simple_consumer(consumer_group=<span class="string">&#x27;test&#x27;</span>, auto_commit_enable=<span class="literal">True</span>, consumer_id=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> message <span class="keyword">in</span> consumer:</span><br><span class="line">  <span class="keyword">if</span> message <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(message.offset, message.value)</span><br></pre></td></tr></table></figure><p>这个程序貌似是不会停止的</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>pymongo分片</title>
      <link href="/2023/08/18/pymongo%E5%88%86%E7%89%87/"/>
      <url>/2023/08/18/pymongo%E5%88%86%E7%89%87/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>普通用户docker执行问题</title>
      <link href="/2023/08/18/%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7docker%E6%89%A7%E8%A1%8C%E9%97%AE%E9%A2%98/"/>
      <url>/2023/08/18/%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7docker%E6%89%A7%E8%A1%8C%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>通过将用户添加到docker用户组可以将sudo去掉，命令如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo groupadd docker <span class="comment">#添加docker用户组</span></span><br><span class="line"></span><br><span class="line">sudo gpasswd -a <span class="variable">$USER</span> docker <span class="comment">#将登陆用户加入到docker用户组中</span></span><br><span class="line"></span><br><span class="line">newgrp docker <span class="comment">#更新用户组</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>hive中文乱码</title>
      <link href="/2023/08/18/hive%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81/"/>
      <url>/2023/08/18/hive%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<p>在metastroe</p><p>（1）修改表字段注解和表注解</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alter table COLUMNS_V2 modify column COMMENT varchar(256) character <span class="built_in">set</span> utf8;</span><br><span class="line">alter table TABLE_PARAMS modify column PARAM_VALUE varchar(4000) character <span class="built_in">set</span> utf8;</span><br></pre></td></tr></table></figure><p>（2）修改分区字段注解</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alter table PARTITION_PARAMS modify column PARAM_VALUE varchar(4000) character <span class="built_in">set</span> utf8 ;</span><br><span class="line">alter table PARTITION_KEYS modify column PKEY_COMMENT varchar(4000) character <span class="built_in">set</span> utf8;</span><br></pre></td></tr></table></figure><p>（3）修改索引注解</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table INDEX_PARAMS modify column PARAM_VALUE varchar(4000) character <span class="built_in">set</span> utf8;</span><br></pre></td></tr></table></figure><p>修改hive-site.xml配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;jdbc:mysql://IP:3306/db_name?createDatabaseIfNotExist=<span class="literal">true</span>&amp;amp;useUnicode=<span class="literal">true</span>&amp;characterEncoding=UTF-8&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;JDBC connect string <span class="keyword">for</span> a JDBC metastore&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>hive窗口函数</title>
      <link href="/2023/08/18/hive%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0/"/>
      <url>/2023/08/18/hive%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<p>CREATE TABLE tmp.COSTITEM<br>( NAME STRING,<br>ORDERDATE DATE,<br>COST STRING);</p><p>– 数据加<br>INSERT INTO  tmp.COSTITEM  VALUES (‘jack’,’2020-01-01’,’10’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘tony’,’2020-01-02’,’15’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘jack’,’2020-02-03’,’23’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘tony’,’2020-01-04’,’29’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘jack’,’2020-01-05’,’46’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘jack’,’2020-04-06’,’42’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘tony’,’2020-01-07’,’50’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘jack’,’2020-01-08’,’55’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘mart’,’2020-04-08’,’62’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘mart’,’2020-04-09’,’68’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘neil’,’2020-05-10’,’12’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘mart’,’2020-04-11’,’75’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘neil’,’2020-06-12’,’80’);<br>INSERT INTO  tmp.COSTITEM  VALUES (‘mart’,’2020-04-13’,’94’);</p><p>SELECT<br>    name,<br>    orderdate,<br>    cost,<br>    sum(cost) OVER() as sample1,   – 所有行相加 ok<br>    sum(cost) over(PARTITION BY name) as sample2,  – 按name分组，组内数据求和 ok<br>    sum(cost) OVER(PARTITION BY name ORDER BY orderdate) as sample3,   – 按name分组，时间排序，组内数据逐个相加 ok<br>    sum(cost) OVER(PARTITION BY name ORDER BY orderdate ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sample4,   – 组内由起点到当前行的聚合<br>    sum(cost) OVER(PARTITION BY name ORDER BY orderdate ROWS BETWEEN 1 PRECEDING and CURRENT ROW) as sample5,   – 组内当前行和前面一行做聚合</p><pre><code>sum(cost) over(PARTITION BY name ORDER BY orderdate ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) as sample6,   -- 组内当前行和前一行和后一行聚合sum(cost) over(PARTITION BY name ORDER BY orderdate ROWS BETWEEN CURRENT ROW and UNBOUNDED FOLLOWING) as sample7    -- 组内当前行和后面所有行</code></pre><p>FROM<br>    TEST.COSTITEM </p><p>jack    2020-01-01      10      661.0   176.0   10.0    10.0    10.0    56.0    176.0<br>jack    2020-01-05      46      661.0   176.0   56.0    56.0    56.0    111.0   166.0<br>jack    2020-01-08      55      661.0   176.0   111.0   111.0   101.0   124.0   120.0<br>jack    2020-02-03      23      661.0   176.0   134.0   134.0   78.0    120.0   65.0<br>jack    2020-04-06      42      661.0   176.0   176.0   176.0   65.0    65.0    42.0<br>mart    2020-04-08      62      661.0   299.0   62.0    62.0    62.0    130.0   299.0<br>mart    2020-04-09      68      661.0   299.0   130.0   130.0   130.0   205.0   237.0<br>mart    2020-04-11      75      661.0   299.0   205.0   205.0   143.0   237.0   169.0<br>mart    2020-04-13      94      661.0   299.0   299.0   299.0   169.0   169.0   94.0<br>neil    2020-05-10      12      661.0   92.0    12.0    12.0    12.0    92.0    92.0<br>neil    2020-06-12      80      661.0   92.0    92.0    92.0    92.0    92.0    80.0<br>tony    2020-01-02      15      661.0   94.0    15.0    15.0    15.0    44.0    94.0<br>tony    2020-01-04      29      661.0   94.0    44.0    44.0    44.0    94.0    79.0<br>tony    2020-01-07      50      661.0   94.0    94.0    94.0    79.0    79.0    50.0<br>Time taken: 91.905 seconds, Fetched: 14 row(s) </p><p>SELECT name,<br>       orderdate,<br>       cost, –当前window内，当前行的前一行到后一行 金额总和<br> sum(cast(cost AS INT)) over(PARTITION BY name<br>                             ORDER BY orderdate DESC ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS precedingFollow, –当前window内，当前行到最后行的金额总和<br> sum(cast(cost AS INT)) over(PARTITION BY name<br>                             ORDER BY orderdate DESC ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS currentFollow, –当前window内，按照时间进行排序<br> row_number() OVER(PARTITION BY name<br>                   ORDER BY orderdate DESC) AS rank,–用户上次购买的时间<br> lag(orderdate,1,’查无结果’) over(PARTITION BY name<br>                              ORDER BY orderdate) AS lastTime,–用户下一次购买的时间<br> lead(orderdate,1,’查无结果’) over(PARTITION BY name<br>                               ORDER BY orderdate)AS nextTime,–用户上次购物金额<br> lag(cost,1,’查无结果’)over(PARTITION BY name<br>                        ORDER BY orderdate) AS lastCost,–用户下次购物金额<br> lead(cost,1,’查无结果’) OVER (PARTITION BY name<br>                           ORDER BY orderdate) AS nextCost,–用户上一次+这次的购物金额<br> sum(cast(cost AS INT)) over(PARTITION BY name<br>                             ORDER BY orderdate ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS lastCurrentCost,–用户每月购物金额<br> sum(cast(cost AS INT)) over(PARTITION BY name,month(orderdate)<br>                             ORDER BY month(orderdate)) AS monthCost,–用户当月单词消费最大值<br> max(cast(cost AS INT)) over(PARTITION BY name,month(orderdate)<br>                             ORDER BY orderdate) AS monthMaxCost,–用户当月单词消费最小值<br> min(cast(cost AS INT)) over(PARTITION BY name,month(orderdate)<br>                             ORDER BY orderdate) as monthMinCost<br>FROM TEST.COSTITEM</p>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop 八股文</title>
      <link href="/2023/08/18/hadoop-%E5%85%AB%E8%82%A1%E6%96%87/"/>
      <url>/2023/08/18/hadoop-%E5%85%AB%E8%82%A1%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h2 id="1-请说下HDFS读写流程"><a href="#1-请说下HDFS读写流程" class="headerlink" title="1. 请说下HDFS读写流程"></a>1. 请说下HDFS读写流程</h2><p>HDFS写流程<br>1）client客户端发送上传请求，通过RPC与namenode建立通信，namenode检查该用户是否有上传权限，以及上传的文件是否在hdfs对应的目录下重名，如果这两者有任意一个不满足，则直接报错，如果两者都满足，则返回给客户端一个可以上传的信息<br>2）client根据文件的大小进行切分，默认128M一块，切分完成之后给namenode发送请求第一个block块上传到哪些服务器上<br>3）namenode收到请求之后，根据网络拓扑和机架感知以及副本机制进行文件分配，返回可用的DataNode的地址 </p><ul><li>注：Hadoop 在设计时考虑到数据的安全与高效, 数据文件默认在 HDFS 上存放三份, 存储策略为本地一份，同机架内其它某一节点上一份, 不同机架的某一节点上一份<br>4）客户端收到地址之后与服务器地址列表中的一个节点如A进行通信，本质上就是RPC调用，建立pipeline，A收到请求后会继续调用B，B在调用C，将整个pipeline建立完成，逐级返回client<br>5）client开始向A上发送第一个block（先从磁盘读取数据然后放到本地内存缓存），以packet（数据包，64kb）为单位，A收到一个packet就会发送给B，然后B发送给C，A每传完一个packet就会放入一个应答队列等待应答<br>6）数据被分割成一个个的packet数据包在pipeline上依次传输，在pipeline反向传输中，逐个发送ack（命令正确应答），最终由pipeline 中第一个 DataNode 节点 A 将 pipelineack 发送给 Client<br>7）当一个 block 传输完成之后, Client 再次请求 NameNode 上传第二个 block ，namenode重新选择三台DataNode给client<br>HDFS读流程<br>1）client向namenode发送RPC请求。请求文件block的位置<br>2）namenode收到请求之后会检查用户权限以及是否有这个文件，如果都符合，则会视情况返回部分或全部的block列表，对于每个block，NameNode 都会返回含有该 block 副本的 DataNode 地址； 这些返回的 DN 地址，会按照集群拓扑结构得出 DataNode 与客户端的距离，然后进行排序，排序两个规则：网络拓扑结构中距离 Client 近的排靠前；心跳机制中超时汇报的 DN 状态为 STALE，这样的排靠后<br>3）Client 选取排序靠前的 DataNode 来读取 block，如果客户端本身就是DataNode,那么将从本地直接获取数据(短路读取特性)<br>4）底层上本质是建立 Socket Stream（FSDataInputStream），重复的调用父类 DataInputStream 的 read 方法，直到这个块上的数据读取完毕<br>5）当读完列表的 block 后，若文件读取还没有结束，客户端会继续向NameNode 获取下一批的 block 列表<br>6）读取完一个 block 都会进行 checksum 验证，如果读取 DataNode 时出现错误，客户端会通知 NameNode，然后再从下一个拥有该 block 副本的DataNode 继续读<br>7）read 方法是并行的读取 block 信息，不是一块一块的读取；NameNode 只是返回Client请求包含块的DataNode地址，并不是返回请求块的数据<br>8） 最终读取来所有的 block 会合并成一个完整的最终文件</li></ul><h2 id="2-HDFS在读取文件的时候-如果其中一个块突然损坏了怎么办"><a href="#2-HDFS在读取文件的时候-如果其中一个块突然损坏了怎么办" class="headerlink" title="2. HDFS在读取文件的时候,如果其中一个块突然损坏了怎么办"></a>2. HDFS在读取文件的时候,如果其中一个块突然损坏了怎么办</h2><p>客户端读取完DataNode上的块之后会进行checksum 验证，也就是把客户端读取到本地的块与HDFS上的原始块进行校验，如果发现校验结果不一致，客户端会通知 NameNode，然后再从下一个拥有该 block 副本的DataNode 继续读</p><h2 id="3-HDFS在上传文件的时候-如果其中一个DataNode突然挂掉了怎么办"><a href="#3-HDFS在上传文件的时候-如果其中一个DataNode突然挂掉了怎么办" class="headerlink" title="3. HDFS在上传文件的时候,如果其中一个DataNode突然挂掉了怎么办"></a>3. HDFS在上传文件的时候,如果其中一个DataNode突然挂掉了怎么办</h2><p>客户端上传文件时与DataNode建立pipeline管道，管道正向是客户端向DataNode发送的数据包，管道反向是DataNode向客户端发送ack确认，也就是正确接收到数据包之后发送一个已确认接收到的应答，当DataNode突然挂掉了，客户端接收不到这个DataNode发送的ack确认<br>，客户端会通知 NameNode，NameNode检查该块的副本与规定的不符，NameNode会通知DataNode去复制副本，并将挂掉的DataNode作下线处理，不再让它参与文件上传与下载。</p><h2 id="4-NameNode在启动的时候会做哪些操作"><a href="#4-NameNode在启动的时候会做哪些操作" class="headerlink" title="4. NameNode在启动的时候会做哪些操作"></a>4. NameNode在启动的时候会做哪些操作</h2><p>NameNode数据存储在内存和本地磁盘，本地磁盘数据存储在fsimage镜像文件和edits编辑日志文件 </p><ul><li>首次启动NameNode<br>1、格式化文件系统，为了生成fsimage镜像文件<br>2、启动NameNode<br>（1）读取fsimage文件，将文件内容加载进内存<br>（2）等待DataNade注册与发送block report<br>3、启动DataNode<br>（1）向NameNode注册<br>（2）发送block report<br>（3）检查fsimage中记录的块的数量和block report中的块的总数是否相同<br>4、对文件系统进行操作（创建目录，上传文件，删除文件等）<br>（1）此时内存中已经有文件系统改变的信息，但是磁盘中没有文件系统改变的信息，此时会将这些改变信息写入edits文件中，edits文件中存储的是文件系统元数据改变的信息。 </li><li>第二次启动NameNode<br>1、读取fsimage和edits文件<br>2、将fsimage和edits文件合并成新的fsimage文件<br>3、创建新的edits文件，内容为空<br>4、启动DataNode</li></ul><h2 id="5-Secondary-NameNode了解吗，它的工作机制是怎样的"><a href="#5-Secondary-NameNode了解吗，它的工作机制是怎样的" class="headerlink" title="5. Secondary NameNode了解吗，它的工作机制是怎样的"></a>5. Secondary NameNode了解吗，它的工作机制是怎样的</h2><p>Secondary NameNode 是合并NameNode的edit logs到fsimage文件中；<br>它的具体工作机制：<br>（1）Secondary NameNode询问NameNode是否需要checkpoint。直接带回NameNode是否检查结果<br>（2）Secondary NameNode请求执行checkpoint<br>（3）NameNode滚动正在写的edits日志<br>（4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode<br>（5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并<br>（6）生成新的镜像文件fsimage.chkpoint<br>（7）拷贝fsimage.chkpoint到NameNode<br>（8）NameNode将fsimage.chkpoint重新命名成fsimage<br>所以如果NameNode中的元数据丢失，是可以从Secondary NameNode恢复一部分元数据信息的，但不是全部，因为NameNode正在写的edits日志还没有拷贝到Secondary NameNode，这部分恢复不了</p><h2 id="6-Secondary-NameNode不能恢复NameNode的全部数据，那如何保证NameNode数据存储安全"><a href="#6-Secondary-NameNode不能恢复NameNode的全部数据，那如何保证NameNode数据存储安全" class="headerlink" title="6. Secondary NameNode不能恢复NameNode的全部数据，那如何保证NameNode数据存储安全"></a>6. Secondary NameNode不能恢复NameNode的全部数据，那如何保证NameNode数据存储安全</h2><h2 id="8-在NameNode-HA中，会出现脑裂问题吗？怎么解决脑裂"><a href="#8-在NameNode-HA中，会出现脑裂问题吗？怎么解决脑裂" class="headerlink" title="8. 在NameNode HA中，会出现脑裂问题吗？怎么解决脑裂"></a>8. 在NameNode HA中，会出现脑裂问题吗？怎么解决脑裂</h2><h2 id="9-小文件过多会有什么危害-如何避免"><a href="#9-小文件过多会有什么危害-如何避免" class="headerlink" title="9. 小文件过多会有什么危害,如何避免"></a>9. 小文件过多会有什么危害,如何避免</h2><h2 id="10-请说下HDFS的组织架构"><a href="#10-请说下HDFS的组织架构" class="headerlink" title="10. 请说下HDFS的组织架构"></a>10. 请说下HDFS的组织架构</h2><h2 id="11-请说下MR中Map-Task的工作机制"><a href="#11-请说下MR中Map-Task的工作机制" class="headerlink" title="11. 请说下MR中Map Task的工作机制"></a>11. 请说下MR中Map Task的工作机制</h2><h2 id="12-请说下MR中Reduce-Task的工作机制"><a href="#12-请说下MR中Reduce-Task的工作机制" class="headerlink" title="12. 请说下MR中Reduce Task的工作机制"></a>12. 请说下MR中Reduce Task的工作机制</h2><p>##13. 请说下MR中shuffle阶段 </p><h2 id="14-shuffle阶段的数据压缩机制了解吗-15-在写MR时，什么情况下可以使用规约-16-yarn-集群的架构和工作原理知道多少-17-yarn-的任务提交流程是怎样的-18-yarn-的资源调度三种模型了解吗"><a href="#14-shuffle阶段的数据压缩机制了解吗-15-在写MR时，什么情况下可以使用规约-16-yarn-集群的架构和工作原理知道多少-17-yarn-的任务提交流程是怎样的-18-yarn-的资源调度三种模型了解吗" class="headerlink" title="14. shuffle阶段的数据压缩机制了解吗 15. 在写MR时，什么情况下可以使用规约 16. yarn 集群的架构和工作原理知道多少 17. yarn 的任务提交流程是怎样的 18. yarn 的资源调度三种模型了解吗"></a>14. shuffle阶段的数据压缩机制了解吗 15. 在写MR时，什么情况下可以使用规约 16. yarn 集群的架构和工作原理知道多少 17. yarn 的任务提交流程是怎样的 18. yarn 的资源调度三种模型了解吗</h2>]]></content>
      
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>centos设置static ip</title>
      <link href="/2023/08/18/centos%E8%AE%BE%E7%BD%AEstatic-ip/"/>
      <url>/2023/08/18/centos%E8%AE%BE%E7%BD%AEstatic-ip/</url>
      
        <content type="html"><![CDATA[<p>archlinux设置固定ip</p><p>cd   &#x2F;etc&#x2F;netctl&#x2F;</p><p>Ip adds 查看网卡id</p><p>vim 网卡id</p><p>TYPE&#x3D;Ethernet<br>PROXY_METHOD&#x3D;none<br>BROWSER_ONLY&#x3D;no<br>BOOTPROTO&#x3D;”static”         # 使用静态IP地址，默认为dhcp<br>IPADDR&#x3D;”192.168.28.5”   # 设置的静态IP地址<br>NETMASK&#x3D;”255.255.255.0”    # 子网掩码<br>GATEWAY&#x3D;”192.168.28.1”    # 网关地址<br>DNS1&#x3D;”192.168.28.1”       # DNS服务器<br>DEFROUTE&#x3D;yes<br>IPV4_FAILURE_FATAL&#x3D;no<br>IPV6INIT&#x3D;yes<br>IPV6_AUTOCONF&#x3D;yes<br>IPV6_DEFROUTE&#x3D;yes<br>IPV6_FAILURE_FATAL&#x3D;no<br>IPV6_ADDR_GEN_MODE&#x3D;stable-privacy<br>NAME&#x3D;enp0s8<br>UUID&#x3D;fb16fac1-9eca-4962-9e2f-a0587174b47c<br>DEVICE&#x3D;enp0s8<br>ONBOOT&#x3D;yes</p><p>如果是centos7设置固定ip<br>cd &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts</p><p>查看网卡id</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">2: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    <span class="built_in">link</span>/ether 08:00:27:59:05:17 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.28.5/24 brd 192.168.28.255 scope global noprefixroute enp0s8</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::750c:27c1:a8c4:bcc8/64 scope <span class="built_in">link</span> noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>   enp0s8<br>vim ifcfg-enp0s8<br>添加上诉配置文件，修改相应的NAME IPADDR</p><p>保存后重启电脑</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>linux 查找trick</title>
      <link href="/2023/08/18/linux-%E6%9F%A5%E6%89%BEtrick/"/>
      <url>/2023/08/18/linux-%E6%9F%A5%E6%89%BEtrick/</url>
      
        <content type="html"><![CDATA[<h3 id="查找大文件"><a href="#查找大文件" class="headerlink" title="查找大文件"></a>查找大文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find / -<span class="built_in">type</span> f -print0 | xargs -0 <span class="built_in">du</span> -h | <span class="built_in">sort</span> -rh | <span class="built_in">head</span> -n 10</span><br></pre></td></tr></table></figure><h3 id="精确查找"><a href="#精确查找" class="headerlink" title="精确查找"></a>精确查找</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find / -<span class="built_in">type</span> f -name <span class="string">&quot;*.conf&quot;</span> | xargs grep -ri <span class="string">&quot;10.0.0.74&quot;</span> -i</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>airtag</title>
      <link href="/2023/08/18/airtag/"/>
      <url>/2023/08/18/airtag/</url>
      
        <content type="html"><![CDATA[<p><img src="/../img/airtag.png" alt="airtag"></p><p>淘宝廉价airtag，28一个，给自行车🚴贴上</p>]]></content>
      
      
      
        <tags>
            
            <tag> 日常 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>conda</title>
      <link href="/2023/08/17/conda/"/>
      <url>/2023/08/17/conda/</url>
      
        <content type="html"><![CDATA[<p><span class="post-count">&lt;%&#x3D; wordcount(post.content) %&gt;</span><br><span class="post-count">&lt;%&#x3D; min2read(post.content) %&gt;</span><br><span class="post-count">&lt;%&#x3D; totalcount(site) %&gt;</span></p><p><img src="/../img/IMG_20180806_121455.jpg" alt="image"></p><h2 id="Miniconda"><a href="#Miniconda" class="headerlink" title="Miniconda"></a>Miniconda</h2><p>Miniconda is a free minimal installer for conda. It is a small, bootstrap version of Anaconda that includes only conda, Python, the packages they depend on, and a small number of other useful packages, including pip, zlib and a few others. Use the conda install command to install 720+ additional conda packages from the Anaconda repository.</p><p>See if Miniconda is right for you.</p><h2 id="System-requirements"><a href="#System-requirements" class="headerlink" title="System requirements"></a>System requirements</h2><p>License: Free use and redistribution under the terms of the EULA for Miniconda.<br>Operating system: Windows 10 or newer, 64-bit macOS 10.13+, or Linux, including Ubuntu, RedHat, CentOS 7+, and others.<br>If your operating system is older than what is currently supported, you can find older versions of the Miniconda installers in our archive that might work for you.<br>System architecture: Windows- 64-bit x86, 32-bit x86; macOS- 64-bit x86 &amp; Apple M1 (ARM64); Linux- 64-bit x86, 64-bit aarch64 (AWS Graviton2), 64-bit IBM Power8&#x2F;Power9, s390x (Linux on IBM Z &amp; LinuxONE).<br>The linux-aarch64 Miniconda installer requires glibc &gt;&#x3D;2.26 and thus will not work with CentOS 7, Ubuntu 16.04, or Debian 9 (“stretch”).<br>Minimum 400 MB disk space to download and install.<br>On Windows, macOS, and Linux, it is best to install Miniconda for the local user, which does not require administrator permissions and is the most robust type of installation. However, if you need to, you can install Miniconda system wide, which does require administrator permissions.</p><h2 id="Installing"><a href="#Installing" class="headerlink" title="Installing"></a>Installing</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https://repo.anaconda.com/miniconda/Miniconda3-py310_23.5.2-0-Linux-x86_64.sh</span><br><span class="line"><span class="built_in">mkdir</span> -p /opt/module</span><br><span class="line">bash Miniconda3-py310_23.5.2-0-Linux-x86_64.sh -b -p /opt/module/miniconda3/</span><br><span class="line">/opt/module/miniconda3/bin/conda init</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ conda install numpy</span><br></pre></td></tr></table></figure><p>…</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ conda create -n py3k anaconda python=3</span><br></pre></td></tr></table></figure><p>…<br>There are two variants of the installer: Miniconda is Python 2 based and Miniconda3 is Python 3 based. Note that the choice of which Miniconda is installed only affects the root environment. Regardless of which version of Miniconda you install, you can still install both Python 2.x and Python 3.x environments.</p><p>The other difference is that the Python 3 version of Miniconda will default to Python 3 when creating new environments and building packages. So for instance, the behavior of:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ conda create -n myenv python</span><br></pre></td></tr></table></figure><p>will be to install Python 2.7 with the Python 2 Miniconda and to install Python 3.10 with the Python 3 Miniconda. You can override the default by explicitly setting python&#x3D;2 or python&#x3D;3. It also determines the default value of CONDA_PY when using conda build.</p><p>Note</p><p>If you already have Miniconda or Anaconda installed, and you just want to upgrade, you should not use the installer. Just use conda update.</p><p>For instance:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ conda update conda</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nfs centos</title>
      <link href="/2023/08/17/nfs-centos/"/>
      <url>/2023/08/17/nfs-centos/</url>
      
        <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@frps.cn ~]<span class="comment"># yum install -y nfs-utils rpcbind</span></span><br><span class="line"></span><br><span class="line">[root@frps.cn ~]<span class="comment"># systemctl start rpcbind</span></span><br><span class="line">[root@frps.cn ~]<span class="comment"># systemctl enable rpcbind</span></span><br><span class="line">[root@frps.cn ~]<span class="comment"># systemctl start nfs</span></span><br><span class="line">[root@frps.cn ~]<span class="comment"># systemctl enable nfs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#首先检查nfs挂载目录是否正常</span></span><br><span class="line">[root@nfs ~]<span class="comment"># showmount -e localhost</span></span><br><span class="line">Export list <span class="keyword">for</span> localhost:</span><br><span class="line">/volume1/nfs01 *</span><br><span class="line"></span><br><span class="line"><span class="comment">#先在客户端创建数据目录（挂载点位置）</span></span><br><span class="line">[root@所有节点 ~]<span class="comment"># mkdir -p /data1/k8s/</span></span><br><span class="line">[root@所有节点 ~]<span class="comment"># mount -t nfs 10.4.82.118:/volume1/nfs01 /data1/k8s</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#现在进行挂载 分别是ip:nfs目录  节点存储目录</span></span><br><span class="line"></span><br><span class="line">挂在完成后我们使用<span class="built_in">df</span> -h 就可以看到挂载点</span><br><span class="line">[root@所有节点 ~]<span class="comment"># df -h|grep 10.4.82.135</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql</title>
      <link href="/2023/08/16/mysql/"/>
      <url>/2023/08/16/mysql/</url>
      
        <content type="html"><![CDATA[<h3 id="Archlinux-安装mysql；"><a href="#Archlinux-安装mysql；" class="headerlink" title="Archlinux  安装mysql；"></a>Archlinux  安装mysql；</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Paceman -S mariadb</span><br><span class="line">sudo mariadb-install-db --user=mysql --basedir=/usr --datadir=/var/lib/mysql</span><br><span class="line"></span><br><span class="line">Two all-privilege accounts were created.</span><br><span class="line">One is root@localhost, it has no password, but you need to</span><br><span class="line">be system <span class="string">&#x27;root&#x27;</span> user to connect. Use, <span class="keyword">for</span> example, sudo mysql</span><br><span class="line">The second is mysql@localhost, it has no password either, but</span><br><span class="line">you need to be the system <span class="string">&#x27;mysql&#x27;</span> user to connect.</span><br><span class="line">After connecting you can <span class="built_in">set</span> the password, <span class="keyword">if</span> you would need to be</span><br><span class="line">able to connect as any of these <span class="built_in">users</span> with a password and without sudo</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Sudo systemctl stop mariadb;</span><br><span class="line">mysqld_safe --skip-grant-tables &amp;</span><br><span class="line"></span><br><span class="line">Mysql;</span><br><span class="line">Use mysql;</span><br><span class="line">Delete from user <span class="built_in">where</span> user=<span class="string">&#x27;&#x27;</span>;</span><br><span class="line">flush privileges;</span><br><span class="line"><span class="built_in">set</span> password <span class="keyword">for</span> root@<span class="string">&#x27;localhost&#x27;</span>=password(<span class="string">&#x27;redhat&#x27;</span>);</span><br><span class="line"><span class="built_in">set</span> password <span class="keyword">for</span> mysql@‘ocalhost<span class="string">&#x27;=password(&#x27;</span>redhat<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">grant all privileges on *.* to username@&#x27;</span>%<span class="string">&#x27; identified by &#x27;</span>pass<span class="string">&#x27;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Exit</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> UPDATE mysql.user SET authentication_string = PASSWORD(&quot;pass&quot;), plugin = &#x27;</span>mysql_native_password<span class="string">&#x27; WHERE User = &#x27;</span>root<span class="string">&#x27; AND Host = &#x27;</span>localhost<span class="string">&#x27;;</span></span><br></pre></td></tr></table></figure><h2 id="centos-linux安装MySQL"><a href="#centos-linux安装MySQL" class="headerlink" title="centos linux安装MySQL"></a>centos linux安装MySQL</h2><p>优先去yum源中去找<br>&#96;&#96;&#96;bash&#96;<br>yum search mysql-community-server<br>yum search mysql-server<br>&#96;&#96;<br>去官网下载mysql:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">https://dev.mysql.com/downloads/mysql/</span><br><span class="line">Select Operating System:</span><br><span class="line">Red Hat Enterprise Linux / Oracle Linux</span><br><span class="line">Select OS Version:</span><br><span class="line">Red Hat Enterprise Linux7 /Oracle Linux7 (x86,64-bit)</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">需要下载的安装包：</span><br><span class="line">- [x] mysql-community-libs</span><br><span class="line">- [x] mysql-community-common</span><br><span class="line">- [x] mysql-community-client</span><br><span class="line">- [x] mysql-community-server</span><br></pre></td></tr></table></figure><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mariadb-libs 被 mysql-community-libs-8.0.32-1.el7.x86_64 取代</span><br><span class="line">rpm -e mariadb-libs —nodeps 卸载一个软件包</span><br><span class="line"></span><br><span class="line">rpm -ivh mysql-community-common-8.0.32-1.el7.x86_64.rpm </span><br><span class="line">rpm -ivh mysql-community-client-plugins-8.0.32-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-libs-8.0.32-1.el7.x86_64.rpm </span><br><span class="line">rpm -ivh mysql-community-client-8.0.32-1.el7.x86_64.rpm</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">yum install net-tools</span><br><span class="line">yum install -y perl-Module-Install.noarch</span><br><span class="line"></span><br><span class="line">rpm -ivh mysql-community-icu-data-files-8.0.32-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-server-8.0.32-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><h3 id="启动mysql"><a href="#启动mysql" class="headerlink" title="启动mysql:"></a>启动mysql:</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysqld --initialize初始化</span><br><span class="line"><span class="built_in">cd</span> /var/lib <span class="built_in">chown</span> mysql:mysql mysql -R  修改mysql数据文件的拥有者</span><br><span class="line">systemctl start mysqld.service 启动mysql</span><br><span class="line"> systemctl status  mysqld.service 查看mysql的启动状态.     systemctl status firewalld.service查看防火墙的启动状态</span><br><span class="line"> systemctl start  mysqld.service手动启动mysql       systemctl stop firewalld.service 关闭防火墙</span><br><span class="line">临时密码：e_z(hG9M=ZfD </span><br><span class="line">修改密码：alter user <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> identified by <span class="string">&#x27;pass&#x27;</span></span><br><span class="line">quit:退出mysql</span><br><span class="line">systemctl <span class="built_in">enable</span> mysqld.service将mysql设置为随机启动</span><br><span class="line">systemctl <span class="built_in">disable</span> mysqld.service 将mysql设置为不随机启动</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ssh反向代理</title>
      <link href="/2023/08/16/ssh%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"/>
      <url>/2023/08/16/ssh%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="SSH-命令端口转发（Port-Forward）"><a href="#SSH-命令端口转发（Port-Forward）" class="headerlink" title="SSH 命令端口转发（Port Forward）"></a>SSH 命令端口转发（Port Forward）</h3><p>远程转发到本地端口 -L （端口转发）<br>命令格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh -N -f -L lhost:lport:rhost:rport ruser@rhost</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br></pre></td></tr></table></figure><p>访问本地127.0.0.1:8443即可访问<a href="http://www.google.com:443/">www.google.com:443</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -N -f -L [lhost:]8443:www.google.com:443 root@1.1.1.1</span><br></pre></td></tr></table></figure><p>本地转发到远程端口 -R （内网穿透）<br>命令格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -N -f -R rhost:rport:lhost:lport ruser@rhost</span><br></pre></td></tr></table></figure><p>访问1.1.1.1:443即可访问本地127.0.0.1:8443</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -N -f -R [rhost:]443:localhost:8443 root@1.1.1.1</span><br></pre></td></tr></table></figure><p>Socks 转发 -D<br>命令格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -N -f -D lhost:lport ruser@rhost</span><br></pre></td></tr></table></figure><p>通过ssh建立Socks通道，本地proxychains配置127.0.0.1:8080即可转发到1.1.1.1</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -N -f -D [lhost:]8080 root@1.1.1.1</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server,内网穿透 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vscode</title>
      <link href="/2023/08/16/vscode/"/>
      <url>/2023/08/16/vscode/</url>
      
        <content type="html"><![CDATA[<h3 id="1-下载安装vscode"><a href="#1-下载安装vscode" class="headerlink" title="1.下载安装vscode"></a>1.下载安装vscode</h3><p>巨硬爸爸开源的全平台IED工匠，本身只是一个简单的文本编辑查看代码的工具，由于众多开发者贡献的免费插件，已经成为一个很有影响力的一个IDE开发工具，墙裂建议你们试试使用vscode进行远程开发，比pycharm的远程开发好用10000000倍。<br><a href="https://code.visualstudio.com/">https://code.visualstudio.com/</a>  </p><h3 id="2-安装remote-development插件"><a href="#2-安装remote-development插件" class="headerlink" title="2.安装remote development插件"></a>2.安装remote development插件</h3><p><img src="/../img/vscode_1.png" alt="图片"></p><h3 id="3-配置远程服务器"><a href="#3-配置远程服务器" class="headerlink" title="3.配置远程服务器"></a>3.配置远程服务器</h3><p><img src="/../img/vscode_2.png" alt="图片"><br>4.添加服务器<br><img src="/../img/vscode_3.png" alt="图片"></p><p><img src="/../img/vscode_4.png" alt="图片"></p><p><img src="/../img/vscode_5.png" alt="图片"></p><h3 id="5-连接输入密码"><a href="#5-连接输入密码" class="headerlink" title="5.连接输入密码"></a>5.连接输入密码</h3><p><img src="/../img/vscode_6.png" alt="图片"></p><p><img src="/../img/vscode_7.png" alt="图片"></p><h3 id="6-可选配置免密码登陆"><a href="#6-可选配置免密码登陆" class="headerlink" title="6.可选配置免密码登陆"></a>6.可选配置免密码登陆</h3><p>macos&#x2F;linux 机器<br>设置ssh key<br><img src="/../img/vscode_8.png" alt="图片"><br>ssh-copy-id上传你的ssh public key到server<br><img src="/../img/vscode_9.png" alt="图片"><br>免密设置成功</p><p>windows平台<br><img src="/../img/vscode_10.png" alt="图片"><br>type %USERPROFILE%.ssh\id_rsa.pub | ssh username@server_ip -p port “cat &gt;&gt; .ssh&#x2F;authorized_keys”</p><p><img src="/../img/vscode_11.png" alt="图片"><br>可以删除%USERPROFILE%如果你在windows的家目录下面<br>输入密码就可以达到和linux的ssh-copy-id一样的功能<br>7.安装jupyter notebook环境<br>由于服务器设置没有独立的ip地址，暂时只能用vscode的jupyter notebook，也可以使用端口转发功能映射服务器的8888端口到本地<br><img src="/../img/vscode_12.png" alt="图片"><br><img src="/../img/vscode_13.png" alt="图片"><br>直接打开notebook文件即可<br><img src="/../img/vscode_14.png" alt="图片"><br>可能需要安装python的插件<br><img src="/../img/vscode_15.png" alt="图片"><br>安装即可<br><img src="/../img/vscode_15.png" alt="图片"><br>选择python环境<br><img src="/../img/vscode_16.png" alt="图片"><br>在vscode使用jupyter notebook<br><img src="/../img/vscode_17.png" alt="图片"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>code server</title>
      <link href="/2023/08/16/code-server/"/>
      <url>/2023/08/16/code-server/</url>
      
        <content type="html"><![CDATA[<h4 id="云端vscode"><a href="#云端vscode" class="headerlink" title="云端vscode"></a>云端vscode</h4><p>云端vscode的概念就是在浏览器中有和本地一样体验的vscode环境。在以下这个网站中，官方已经有实现在浏览器中的实现。</p><h4 id="installation"><a href="#installation" class="headerlink" title="installation"></a>installation</h4><p><a href="https://github.com/coder/code-server/releases">https://github.com/coder/code-server/releases</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## https://github.com/coder/code-server/releases</span></span><br><span class="line">curl -fOL  sudo dpkg -i code-server_4.3.0_amd64.deb</span><br><span class="line">sudo systemctl <span class="built_in">enable</span> --now code-server@root</span><br><span class="line"><span class="comment"># Now visit http://127.0.0.1:8080. Your password is in ~/.config/code-server/config.yaml</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.config/code-server/config.yaml</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/../img/codeserver.png" alt="code"></p><p>启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 类似jupyter notebook</span></span><br><span class="line">code-server</span><br><span class="line"></span><br><span class="line">(base) [zengjunjie@gpu009 ~]$ </span><br><span class="line">(base) [zengjunjie@gpu009 ~]$ code-server</span><br><span class="line">[2023-08-18T02:26:50.960Z] info  code-server 4.14.1 5c199629305a0b935b4388b7db549f77eae82b5a</span><br><span class="line">[2023-08-18T02:26:50.961Z] info  Using user-data-dir ~/.local/share/code-server</span><br><span class="line">[2023-08-18T02:26:50.975Z] info  Using config file ~/.config/code-server/config.yaml</span><br><span class="line">[2023-08-18T02:26:50.975Z] info  HTTP server listening on http://0.0.0.0:8081/</span><br><span class="line">[2023-08-18T02:26:50.975Z] info    - Authentication is enabled</span><br><span class="line">[2023-08-18T02:26:50.975Z] info      - Using password from ~/.config/code-server/config.yaml</span><br><span class="line">[2023-08-18T02:26:50.975Z] info    - Not serving HTTPS</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jupyter notebook</title>
      <link href="/2023/08/16/jupyter-notebook/"/>
      <url>/2023/08/16/jupyter-notebook/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>pve</title>
      <link href="/2023/08/16/pve/"/>
      <url>/2023/08/16/pve/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>黑苹果</title>
      <link href="/2023/08/16/%E9%BB%91%E8%8B%B9%E6%9E%9C/"/>
      <url>/2023/08/16/%E9%BB%91%E8%8B%B9%E6%9E%9C/</url>
      
        <content type="html"><![CDATA[<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>intel 10600k<br>microstar Z490 unify itx主板<br>阿斯加特 32G DDR4<br>1TB 阿斯加特 ssd<br>500G 西数SN750 ssd<br>GPU 5700XT<br>机箱 乔思伯V8<br>电源 全汉ms600w sfx小电源  </p><h3 id="成品"><a href="#成品" class="headerlink" title="成品"></a>成品</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">(base) andrew@255imac:~<span class="comment">#neofetch</span></span><br><span class="line">                    <span class="string">&#x27;c.          andrew@imac </span></span><br><span class="line"><span class="string">                 ,xNMM.          ----------- </span></span><br><span class="line"><span class="string">               .OMMMMo           OS: macOS 13.5 22G5038d x86_64 </span></span><br><span class="line"><span class="string">               OMMM0,            Host: Hackintosh (SMBIOS: iMac20,2) </span></span><br><span class="line"><span class="string">     .;loddo:&#x27;</span> loolloddol;.      Kernel: 22.6.0 </span><br><span class="line">   cKMMMMMMMMMMNWMMMMMMMMMM0:    Uptime: 8 days, 28 mins </span><br><span class="line"> .KMMMMMMMMMMMMMMMMMMMMMMMWd.    Packages: 62 (brew) </span><br><span class="line"> XMMMMMMMMMMMMMMMMMMMMMMMX.      Shell: zsh 5.9 </span><br><span class="line">;MMMMMMMMMMMMMMMMMMMMMMMM:       Resolution: 1920x1200@2x </span><br><span class="line">:MMMMMMMMMMMMMMMMMMMMMMMM:       DE: Aqua </span><br><span class="line">.MMMMMMMMMMMMMMMMMMMMMMMMX.      WM: Quartz Compositor </span><br><span class="line"> kMMMMMMMMMMMMMMMMMMMMMMMMWd.    WM Theme: Blue (Light) </span><br><span class="line"> .XMMMMMMMMMMMMMMMMMMMMMMMMMMk   Terminal: Apple_Terminal </span><br><span class="line">  .XMMMMMMMMMMMMMMMMMMMMMMMMK.   Terminal Font: Monaco </span><br><span class="line">    kMMMMMMMMMMMMMMMMMMMMMMd     CPU: Intel i5-10600K (12) @ 4.10GHz </span><br><span class="line">     ;KMMMMMMMWXXWMMMMMMMk.      GPU: AMD Radeon RX 460/560 </span><br><span class="line">       .cooc,.    .,coo:.        Memory: 36909MiB / 65536MiB </span><br><span class="line"></span><br><span class="line">                                                         </span><br><span class="line">                                        </span><br></pre></td></tr></table></figure><p><img src="/../img/hackintosh.png" alt="hackintosh"></p><h2 id="参考EFI"><a href="#参考EFI" class="headerlink" title="参考EFI"></a>参考EFI</h2><p><a href="https://github.com/wjz304/Hackintosh-EFI-MSI-Z490i-Unify">https://github.com/wjz304/Hackintosh-EFI-MSI-Z490i-Unify</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 服务器折腾 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>黑群晖</title>
      <link href="/2023/08/16/%E9%BB%91%E7%BE%A4%E6%99%96/"/>
      <url>/2023/08/16/%E9%BB%91%E7%BE%A4%E6%99%96/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> 服务器折腾 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>万兆光</title>
      <link href="/2023/08/16/%E4%B8%87%E5%85%86%E5%85%89/"/>
      <url>/2023/08/16/%E4%B8%87%E5%85%86%E5%85%89/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> 服务器折腾 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.5G交换机</title>
      <link href="/2023/08/16/2-5G%E4%BA%A4%E6%8D%A2%E6%9C%BA/"/>
      <url>/2023/08/16/2-5G%E4%BA%A4%E6%8D%A2%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>组建双3090炼丹炉</title>
      <link href="/2023/08/16/%E7%BB%84%E5%BB%BA%E5%8F%8C3090%E7%82%BC%E4%B8%B9%E7%82%89/"/>
      <url>/2023/08/16/%E7%BB%84%E5%BB%BA%E5%8F%8C3090%E7%82%BC%E4%B8%B9%E7%82%89/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>stable diffusion</title>
      <link href="/2023/08/16/stable-diffusion/"/>
      <url>/2023/08/16/stable-diffusion/</url>
      
        <content type="html"><![CDATA[<p>ubuntu supervisor进程管理<br>Supervisor 是一个用 Python 写的进程管理工具，可以很方便的对进程进行启动、停止、重启等操作。</p><p>安装命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install supervisor</span><br></pre></td></tr></table></figure><p>安装成功后，会在&#x2F;etc&#x2F;supervisor目录下，生成supervisord.conf配置文件。</p><p>你也可以使用echo_supervisord_conf &gt; supervisord.conf命令，生成默认的配置文件（不建议，内容比较多）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[unix_http_server]</span><br><span class="line">file=/var/supervisor/supervisor.sock   ;UNIX socket 文件，supervisorctl 会使用</span><br><span class="line">;<span class="built_in">chmod</span>=0700                 ;socket文件的mode，默认是0700</span><br><span class="line">;<span class="built_in">chown</span>=nobody:nogroup       ;socket文件的owner，格式：uid:gid</span><br><span class="line"></span><br><span class="line">;[inet_http_server]         ;HTTP服务器，提供web管理界面</span><br><span class="line">;port=127.0.0.1:9001        ;Web管理后台运行的IP和端口，如果开放到公网，需要注意</span><br><span class="line">安全性</span><br><span class="line">;username=andrew             ;登录管理后台的用户名</span><br><span class="line">;password=python             ;登录管理后台的密码</span><br><span class="line"></span><br><span class="line">[supervisord]</span><br><span class="line">logfile=/Users/andrew/logs/supervisord.log ;日志文件，默认是 <span class="variable">$CWD</span>/supervisord.log</span><br><span class="line">logfile_maxbytes=50MB        ;日志文件大小，超出会rotate，默认 50MB，如果设成0，</span><br><span class="line">表示不限制大小</span><br><span class="line">logfile_backups=10           ;日志文件保留备份数量默认10，设为0表示不备份</span><br><span class="line">loglevel=info                ;日志级别，默认info，其它: debug,warn,trace</span><br><span class="line">pidfile=/var/supervisor/supervisord.pid ;pid 文件</span><br><span class="line">nodaemon=<span class="literal">false</span>               ;是否在前台启动，默认是<span class="literal">false</span>，即以 daemon 的方式启&gt;动</span><br><span class="line">minfds=1024                  ;可以打开的文件描述符的最小值，默认 1024</span><br><span class="line">minprocs=200                 ;可以打开的进程数的最小值，默认 200</span><br></pre></td></tr></table></figure><p>进程配置会读取&#x2F;etc&#x2F;supervisor&#x2F;conf.d目录下的*.conf配置文件，我们在此目录下创建一个hwapp.conf进程配置文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[program:frpc-proxys]</span><br><span class="line">directory = /Users/andrew/frp_0.30.0_darwin_amd64</span><br><span class="line"><span class="built_in">command</span> = /Users/andrew/frp_0.30.0_darwin_amd64/frpc -c /Users/andrew/frp_0.30.0_darwin_amd64/frpc-aliyun-5900.ini</span><br><span class="line">autostart = True</span><br><span class="line">autorestart = True</span><br><span class="line">user = andrew</span><br><span class="line">startsecs=3</span><br><span class="line">stderr_logfile=/Users/andrew/logs/frpc-err.log</span><br><span class="line">stdout_logfile=/Users/andrew/logs/frpc.log</span><br><span class="line">stdout_logfile_maxbytes=200MB</span><br></pre></td></tr></table></figure><p>设置开机自启和启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl <span class="built_in">enable</span> supervisord</span><br><span class="line">sudo systemctl start supervisord</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>chatgpt</title>
      <link href="/2023/08/16/chatgpt/"/>
      <url>/2023/08/16/chatgpt/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>aliyun</title>
      <link href="/2023/08/16/aliyun/"/>
      <url>/2023/08/16/aliyun/</url>
      
        <content type="html"><![CDATA[<p><img src="/../img/aliyun.png" alt="aliyun_dbs"></p><p>首次优惠500可以买三年的云服务器。<br>续费坑爹。  </p><p><img src="/../img/aliyun_xufei.png" alt="aliyun_xufei"></p><p>换美帝的100mbps云服务器了</p><p><img src="/../img/us_aliyun.jpg" alt="us"></p><p>美滋滋</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>frp</title>
      <link href="/2023/08/16/frp/"/>
      <url>/2023/08/16/frp/</url>
      
        <content type="html"><![CDATA[<p>内网穿透是打破没有公网ip的桎梏，让处于内网的机器也能在远程使用ssh链接，让我这个机器学习算法工程师也能处在世界任何一个地方操纵自己的电脑。话不多说，开始教程。</p><p>需要的条件是，有一台有公网ip的服务器当代理机器，使用端口映射，将内网内的主机localhost:22y映射到公网ip的主机上任意一个没有占用的端口，比如6000.</p><h2 id="复习计算机网络"><a href="#复习计算机网络" class="headerlink" title="复习计算机网络"></a>复习计算机网络</h2><p>假设我们的主机IP是192.168.0.0，路由器LAN IP为192.168.0.1，WAN IP为211.22.145.234（这是一个公网IP）,google 服务器 IP 为74.125.204.101。</p><p>主机构建HTTP请求数据包，目标IP为74.125.204.101，目标端口是80&#x2F;443，源IP为192.168.0.0，源端口随机生成，假定为5000<br>主机检查目标IP地址，发现不在一个网段，数据包丢给默认网关192.168.0.1<br>路由器LAN口收到数据包，构建NAT映射，随机生成端口，假定为5500,这样映射就是：5500-&gt;192.168.0.0:5000．WAN口收到的数据包，如果目标端口是5500,则会转发给192.168.0.0的5000端口。<br>路由器修改数据包的源端口为5500,源ＩＰ地址为211.22.145.234，使用WAN口将数据包发出去<br>google服务器收到请求，构建响应HTTP数据包，目标IP地址为211.22.145.234,目标端口是5500<br>路由器WAN口收到数据包，目标端口是5500,查询NAT表，发现对应的机器是192.168.0.0:5000，所以修改目标IP为192.168.0.0，目标端口为5000，并通过LAN口发送给主机<br>主机收到数据包，完成一次通信。</p><p>参考<br><a href="https://www.jianshu.com/p/a621556fc07b">frp穿透原理</a></p><h2 id="使用frp穿透内网"><a href="#使用frp穿透内网" class="headerlink" title="使用frp穿透内网"></a>使用frp穿透内网</h2><p>点击链接下载<a href="https://github.com/fatedier/frp/releases/download/v0.30.0/frp_0.30.0_linux_amd64.tar.gz">https://github.com/fatedier/frp/releases/download/v0.30.0/frp_0.30.0_linux_amd64.tar.gz</a><br><a href="https://github.com/fatedier/frp/releases/download/v0.30.0/frp_0.30.0_linux_amd64.tar.gz">frp_0.30_amd64_linux</a><br>目前版本为0.30，请到官网下载最新的frp内网穿透软件，我买的腾讯云的服务器，架构一般的X86_64.,上传服务器，解压。<br>或者直接使用wget或aria2下载</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##使用wget 下载</span></span><br><span class="line">wget https://github.com/fatedier/frp/releases/download/v0<span class="number">.30</span><span class="number">.0</span>/frp_0<span class="number">.30</span><span class="number">.0</span>_linux_amd64.tar.gz</span><br><span class="line"><span class="comment">##使用aria2下载</span></span><br><span class="line">aria2 https://github.com/fatedier/frp/releases/download/v0<span class="number">.30</span><span class="number">.0</span>/frp_0<span class="number">.30</span><span class="number">.0</span>_linux_amd64.tar.gz</span><br></pre></td></tr></table></figure><p>下载完毕后解压,进入路径</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##解压</span></span><br><span class="line">tar -xvzf  frp_0<span class="number">.30</span><span class="number">.0</span>_linux_amd64.tar.gz</span><br><span class="line"><span class="comment">##进入软件包</span></span><br><span class="line">cd frp_0<span class="number">.30</span><span class="number">.0</span>_linux_amd64</span><br></pre></td></tr></table></figure><h2 id="设置服务端server"><a href="#设置服务端server" class="headerlink" title="设置服务端server"></a>设置服务端server</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim frps.ini</span><br></pre></td></tr></table></figure><p>查看监听的端口号</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[common]</span><br><span class="line">bind_port = 7000        <span class="comment"># frp服务的端口</span></span><br></pre></td></tr></table></figure><p>在服务端开启frp代理服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./frps -c frps.ini      <span class="comment"># 前台直接启动，测试看日志方便</span></span><br><span class="line"><span class="built_in">nohup</span> ./frps -c ./frps.ini &gt; /dev/null 2&gt;&amp;1 &amp;   <span class="comment"># 后台运行</span></span><br></pre></td></tr></table></figure><h2 id="设置客户端client"><a href="#设置客户端client" class="headerlink" title="设置客户端client"></a>设置客户端client</h2><p>同上下载对应版本的frp软件，解压到适当的路径。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##使用wget 下载</span></span><br><span class="line">wget https://github.com/fatedier/frp/releases/download/v0<span class="number">.30</span><span class="number">.0</span>/frp_0<span class="number">.30</span><span class="number">.0</span>_linux_amd64.tar.gz</span><br><span class="line"><span class="comment">##使用aria2下载</span></span><br><span class="line">aria2 https://github.com/fatedier/frp/releases/download/v0<span class="number">.30</span><span class="number">.0</span>/frp_0<span class="number">.30</span><span class="number">.0</span>_linux_amd64.tar.gz</span><br></pre></td></tr></table></figure><p>下载完毕后解压,进入路径</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##解压</span></span><br><span class="line">tar -xvzf  frp_0<span class="number">.30</span><span class="number">.0</span>_linux_amd64.tar.gz</span><br><span class="line"><span class="comment">##进入软件包</span></span><br><span class="line">cd frp_0<span class="number">.30</span><span class="number">.0</span>_linux_amd64</span><br></pre></td></tr></table></figure><p>编辑客户端的配置，将server的公网ip写入server_addr，这里是23。12.12.12,监听端口写入server_port,这里是7000，远程连接时使用的端口remote_port改为6000。<br>&#96;</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim frpc.ini</span><br></pre></td></tr></table></figure><p>修改的端口号</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[common]</span><br><span class="line">server_addr = 23.12.12.12     <span class="comment"># 公网服务器IP</span></span><br><span class="line">server_port = 7000              <span class="comment"># 公网服务器的bind_port</span></span><br><span class="line"></span><br><span class="line">[ssh]</span><br><span class="line"><span class="built_in">type</span> = tcp                      <span class="comment"># 协议格式</span></span><br><span class="line">local_ip = 127.0.0.1</span><br><span class="line">local_port = 22                 <span class="comment"># 本地ssh服务端口</span></span><br><span class="line">remote_port = 6000             <span class="comment"># 远程连接时使用的端口</span></span><br></pre></td></tr></table></figure><p>开启客户端的frp服务。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./frpc -c ./frpc.ini    <span class="comment"># 前台直接启动，测试看日志方便</span></span><br><span class="line">nohup ./frpc -c ./frpc.ini &gt; /dev/null <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp; <span class="comment"># 后台运行</span></span><br></pre></td></tr></table></figure><p>如果有多台机器需要配置，只需要将每台客户端的的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[ssh]</span><br><span class="line"><span class="built_in">type</span> = tcp                      <span class="comment"># 协议格式</span></span><br><span class="line">local_ip = <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line">local_port = <span class="number">22</span>                 <span class="comment"># 本地ssh服务端口</span></span><br><span class="line">remote_port = <span class="number">6000</span>             <span class="comment"># 远程连接时使用的端口</span></span><br></pre></td></tr></table></figure><p>中ssh改一个其他名字，remote_port改为其他的端口比如6001.像这样。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[ssh_6001]</span><br><span class="line"><span class="built_in">type</span> = tcp                      <span class="comment"># 协议格式</span></span><br><span class="line">local_ip = <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line">local_port = <span class="number">22</span>                 <span class="comment"># 本地ssh服务端口</span></span><br><span class="line">remote_port = <span class="number">6001</span>             <span class="comment"># 远程连接时使用的端口</span></span><br></pre></td></tr></table></figure><p>之后开启服务。</p><h2 id="测试远程登陆计算机。"><a href="#测试远程登陆计算机。" class="headerlink" title="测试远程登陆计算机。"></a>测试远程登陆计算机。</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh innet_username@server_ip_address -p <span class="number">6000</span></span><br><span class="line">ssh innet_username@server_ip_address -p <span class="number">6001</span></span><br></pre></td></tr></table></figure><p>输入密码就可以登录在内网内的主机了，是不是很方便？</p><h2 id="使用scp在刚刚内网穿透的机器上进行文件传输"><a href="#使用scp在刚刚内网穿透的机器上进行文件传输" class="headerlink" title="使用scp在刚刚内网穿透的机器上进行文件传输"></a>使用scp在刚刚内网穿透的机器上进行文件传输</h2><p>scp是一个很好的文件传输工具，在局域网内可以很方便传输，或者在有公网ip的机器上也可以，那么在内网穿透后可以传输吗？答案是肯定的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -P <span class="number">6000</span> -r ./local_file inner_net_username@server_ip_address:/your/inner/net/machine/path</span><br></pre></td></tr></table></figure><p>-P 添加刚刚的port<br>-r 代表递归，传输文件夹</p><h2 id="关掉frp"><a href="#关掉frp" class="headerlink" title="关掉frp"></a>关掉frp</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps -aux|grep frp| grep -v grep</span><br><span class="line">kill process_id</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zerotier</title>
      <link href="/2023/08/16/zerotier/"/>
      <url>/2023/08/16/zerotier/</url>
      
        <content type="html"><![CDATA[<h3 id="zerotier"><a href="#zerotier" class="headerlink" title="zerotier"></a>zerotier</h3><p>zerotier是一个异地组网实现方案，个人尤其是小公司（设备数量50以下）虚拟组网的最简单实现放完，异地访问家里的nas，数据库，远程桌面等，具有简单和安全的特性。</p><p>我是在openwrt软路由上发现这个内置的组建，尝试了一下发现特别简单，按照官网给的文档，可以在5分钟之内组建自己的专属局域网，实现家里的nas当远程网盘。数据共享，不需要DDNS动态域名解析，也无需借助公网ip，活着VPS进行frp反向代理实现内网穿透。</p><p>在官网注册登入之后新建虚拟网络，一个id可以支持50台设备</p>]]></content>
      
      
      
        <tags>
            
            <tag> server,内网穿透 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hbase</title>
      <link href="/2023/08/16/hbase/"/>
      <url>/2023/08/16/hbase/</url>
      
        <content type="html"><![CDATA[<h2 id="HBase简介"><a href="#HBase简介" class="headerlink" title="HBase简介"></a>HBase简介</h2><h3 id="什么是HBase"><a href="#什么是HBase" class="headerlink" title="什么是HBase"></a>什么是HBase</h3><p>HBASE是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBASE技术可在廉价PC Server上搭建起大规模结构化存储集群。<br>HBASE的目标是存储并处理大型的数据，更具体来说是仅需使用普通的硬件配置，就能够处理由成千上万的行和列所组成的大型数据。HBASE是<br>Google Bigtable的开源实现，但是也有很多不同之处。比如：Google Bigtable利用GFS作为其文件存储系统，HBASE利用Hadoop<br>HDFS作为其文件存储系统；Google运行MAPREDUCE来处理Bigtable中的海量数据，HBASE同样利用Hadoop MapReduce来处理HBASE<br>中的海量数据；Google Bigtable利用Chubby作为协同服务，HBASE利用Zookeeper作为对应。</p><h3 id="HBase中的角色"><a href="#HBase中的角色" class="headerlink" title="HBase中的角色"></a>HBase中的角色</h3><h4 id="HMaster"><a href="#HMaster" class="headerlink" title="HMaster"></a>HMaster</h4><p>功能：</p><ul><li>监控RegionServer</li><li>处理RegionServer故障转移</li><li>处理元数据的变更</li><li>处理region的分配或移除</li><li>在空闲时间进行数据的负载均衡</li><li>通过Zookeeper发布自己的位置给客户端</li></ul><h4 id="RegionServer"><a href="#RegionServer" class="headerlink" title="RegionServer"></a>RegionServer</h4><p>功能：</p><ul><li>负责存储HBase的实际数据</li><li>处理分配给它的Region</li><li>刷新缓存到HDFS</li><li>维护HLog</li><li>执行压缩</li><li>负责处理Region分片</li></ul><h5 id="其他组件"><a href="#其他组件" class="headerlink" title="其他组件"></a>其他组件</h5><ul><li>Write-Ahead logs<br>HBase的修改记录，当对HBase读写数据的时候，数据不是直接写进磁盘，它会在内存中保留一段时间（时间以及数据量阈值可以设定）。<br>但把数据保存在内存中可能有更高的概率引起数据丢失，为了解决这个问题，数据会先写在一个叫做Write-Ahead logfile的文件中，<br>然后再写入内存中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。</li><li>HFile<br>这是在磁盘上保存原始数据的实际的物理文件，是实际的存储文件。</li><li>Store<br>HFile存储在Store中，一个Store对应HBase表中的一个列族。</li><li>MemStore<br>顾名思义，就是内存存储，位于内存中，用来保存当前的数据操作，所以当数据保存在WAL中之后，RegsionServer会在内存中存储键值对。</li><li>Region<br>Hbase表的分片，HBase表会根据RowKey值被切分成不同的region存储在RegionServer中，在一个RegionServer中可以有多个不同的region。</li></ul><h3 id="HBase架构"><a href="#HBase架构" class="headerlink" title="HBase架构"></a>HBase架构</h3><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bfa9b3afd8f844d0b938825b77e085d2~tplv-k3u1fbpfcp-watermark.image"></p><h2 id="HBase安装"><a href="#HBase安装" class="headerlink" title="HBase安装"></a>HBase安装</h2><ul><li><a href="https://www.cnblogs.com/qingyunzong/p/8668880.html">HBase学习之路 （二）HBase集群安装</a></li></ul><h2 id="HBase数据结构"><a href="#HBase数据结构" class="headerlink" title="HBase数据结构"></a>HBase数据结构</h2><h3 id="Row-Key"><a href="#Row-Key" class="headerlink" title="Row Key"></a>Row Key</h3><p>与nosql数据库们一样,row key是用来检索记录的主键。访问HBASE table中的行，只有三种方式：</p><ul><li>通过单个row key访问</li><li>通过row key的range（正则）</li><li>全表扫描Row key行键(Row key)可以是任意字符串(最大长度是64KB，实际应用中长度一般为10-100bytes)，在HBASE内部，<br>row key保存为字节数组。存储时，数据按照Row key的字典序(byte order)排序存储。设计key时，要充分排序存储这个特性，将经常一起读取的行存储放到一起。(位置相关性)</li></ul><h3 id="Columns-Family"><a href="#Columns-Family" class="headerlink" title="Columns Family"></a>Columns Family</h3><p>列族：HBASE表中的每个列，都归属于某个列族。列族是表的schema的一部分(而列不是)，必须在使用表之前定义。列名都以列族作为前缀。例如courses:history，courses:math都属于courses 这个列族。</p><h3 id="Cell"><a href="#Cell" class="headerlink" title="Cell"></a>Cell</h3><p>由{row key, columnFamily, version} 唯一确定的单元。cell中的数据是没有类型的，全部是字节码形式存贮。关键字：无类型、字节码</p><h3 id="Time-Stamp"><a href="#Time-Stamp" class="headerlink" title="Time Stamp"></a>Time Stamp</h3><p>HBASE 中通过rowkey和columns确定的为一个存贮单元称为cell。每个cell都保存着同一份数据的多个版本。版本通过时间戳来索引。时间戳的类型是64位整型。时间戳可以由HBASE(在数据写入时自动)赋值，此时时间戳是精确到毫秒的当前系统时间。时间戳也可以由客户显式赋值。如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。每个cell中，不同版本的数据按照时间倒序排序，即最新的数据排在最前面。为了避免数据存在过多版本造成的的管理(包括存贮和索引)负担，HBASE提供了两种数据版本回收方式。一是保存数据的最后n个版本，二是保存最近一段时间内的版本（比如最近七天）。用户可以针对每个列族进行设置。</p><h2 id="HBase原理"><a href="#HBase原理" class="headerlink" title="HBase原理"></a>HBase原理</h2><h3 id="写流程"><a href="#写流程" class="headerlink" title="写流程"></a>写流程</h3><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bf7e99f7965d4f3b9b4e54961088cc1a~tplv-k3u1fbpfcp-watermark.image"></p><ul><li>Client向HregionServer发送写请求；</li><li>HregionServer将数据写到HLog（write ahead log）。为了数据的持久化和恢复；</li><li>HregionServer将数据写到内存（MemStore）；</li><li>反馈Client写成功。</li></ul><h3 id="数据flush过程"><a href="#数据flush过程" class="headerlink" title="数据flush过程"></a>数据flush过程</h3><ul><li>当MemStore数据达到阈值（默认是128M，老版本是64M），将数据刷到硬盘，将内存中的数据删除，同时删除HLog中的历史数据；</li><li>并将数据存储到HDFS中；</li><li>在HLog中做标记点。</li></ul><h3 id="数据合并过程"><a href="#数据合并过程" class="headerlink" title="数据合并过程"></a>数据合并过程</h3><ul><li>当数据块达到4块，Hmaster将数据块加载到本地，进行合并；</li><li>当合并的数据超过256M，进行拆分，将拆分后的Region分配给不同的HregionServer管理；</li><li>当HregionServer宕机后，将HregionServer上的hlog拆分，然后分配给不同的HregionServer加载，修改.META；</li><li>注意：HLog会同步到HDFS。</li></ul><h3 id="读流程"><a href="#读流程" class="headerlink" title="读流程"></a>读流程</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5e781efc3fd947d48e1d07bf17ee8426~tplv-k3u1fbpfcp-watermark.image"></p><ul><li>Client先访问zookeeper，从meta表读取region的位置，然后读取meta表中的数据。meta中又存储了用户表的region信息；</li><li>根据namespace、表名和rowkey在meta表中找到对应的region信息；</li><li>找到这个region对应的regionserver；</li><li>查找对应的region；</li><li>先从MemStore找数据，如果没有，再到StoreFile上读(为了读取的效率)。</li></ul><h3 id="Hmaster的职责"><a href="#Hmaster的职责" class="headerlink" title="Hmaster的职责"></a>Hmaster的职责</h3><ul><li>管理用户对Table的增、删、改、查操作；</li><li>记录region在哪台Hregion server上；</li><li>在Region Split后，负责新Region的分配；</li><li>新机器加入时，管理HRegion Server的负载均衡，调整Region分布；</li><li>在HRegion Server宕机后，负责失效HRegion Server 上的Regions迁移。</li></ul><h3 id="Hregionserver的职责"><a href="#Hregionserver的职责" class="headerlink" title="Hregionserver的职责"></a>Hregionserver的职责</h3><ul><li>HRegion Server主要负责响应用户I&#x2F;O请求，向HDFS文件系统中读写数据，是HBASE中最核心的模块。</li><li>HRegion Server管理了很多table的分区，也就是region。</li></ul><h3 id="Client职责"><a href="#Client职责" class="headerlink" title="Client职责"></a>Client职责</h3><ul><li>HBASE Client使用HBASE的RPC机制与HMaster和RegionServer进行通信</li><li>管理类操作：Client与HMaster进行RPC；</li><li>数据读写类操作：Client与HRegionServer进行RPC。</li></ul><h2 id="Phoenix-SQL-On-HBase"><a href="#Phoenix-SQL-On-HBase" class="headerlink" title="Phoenix(SQL On HBase)"></a>Phoenix(SQL On HBase)</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><ul><li>Phoenix是一个HBase框架，可以通过SQL的方式来操作HBase。</li><li>Phoenix是构建在HBase上的一个SQL层，是内嵌在HBase中的JDBC驱动，能够让用户使用标准的JDBC来操作HBase。</li><li>Phoenix使用JAVA语言进行编写，其查询引擎会将SQL查询语句转换成一个或多个HBase Scanner，且并行执行生成标准的JDBC结果集。</li><li>如果需要对HBase进行复杂的操作，那么应该使用Phoenix，其会将SQL语句转换成HBase相应的API。</li><li>Phoenix只能用在HBase上，其查询性能要远高于Hive。</li></ul><h3 id="Phoenix与HBase的关系"><a href="#Phoenix与HBase的关系" class="headerlink" title="Phoenix与HBase的关系"></a>Phoenix与HBase的关系</h3><p>Phoenix与HBase中的表是独立的，两者之间没有必然的关系。</p><p>Phoenix与HBase集成后会创建六张系统表：SYSTEM.CATALOG、SYSTEM.FUNCTION、SYSTEM.LOG、SYSTEM.SEQUENCE、SYSTEM.STATS，其中SYSTEM.CATALOG表用于存放Phoenix创建表时的元数据。</p><p>Phoenix创建表时会自动调用HBase客户端创建相应的表，并且在SYSTEM.CATALOG系统表中记录Phoenix创建表时的元数据，其主键的值对应HBase的RowKey，非主键的列对应HBase的Column（列族不指定时为0，且列会进行编码）</p><p>如果是通过Phoenix创建的表，那么必须通过Phoenix客户端来对表进行操作，因为通过Phoenix创建的表其非主键的列会进行编码。</p><h3 id="Phoenix语法"><a href="#Phoenix语法" class="headerlink" title="Phoenix语法"></a>Phoenix语法</h3><p>Phoenix的SQL中如果表名、字段名不使用双引号标注那么默认转换成大写。</p><p>Phoenix中的字符串使用单引号进行标注。 </p><p>创建表</p><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS us_population (</span><br><span class="line">      <span class="keyword">state</span> CHAR(<span class="number">2</span>) NOT NULL,</span><br><span class="line">      city VARCHAR NOT NULL,</span><br><span class="line">      population BIGINT</span><br><span class="line">      CONSTRAINT my_pk PRIMARY KEY (<span class="keyword">state</span>, city)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><blockquote><p>主键的值对应HBase中的RowKey，列族不指定时默认是0，非主键的列对应HBase的列。</p></blockquote><p>删除表</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> us_population;</span><br></pre></td></tr></table></figure><p>查询数据</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> us_population <span class="keyword">WHERE</span> state = <span class="string">&#x27;NA&#x27;</span> <span class="keyword">AND</span> population &gt; <span class="number">10000</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> population <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure><blockquote><p>在进行查询时，支持ORDER BY、GROUP BY、LIMIT、JOIN等操作，同时Phoenix提供了一系列的函数，其中包括COUNT()、MAX()、MIN()、SUM()等，具体的函数列表可以查看：<a href="http://phoenix.apache.org/language/functions.html%E4%B8%8D%E7%AE%A1%E6%9D%A1%E4%BB%B6%E4%B8%AD%E7%9A%84%E5%88%97%E6%98%AF%E5%90%A6%E6%98%AF%E8%81%94%E5%90%88%E4%B8%BB%E9%94%AE%E4%B8%AD%E7%9A%84%EF%BC%8CPhoenix%E4%B8%80%E6%A0%B7%E5%8F%AF%E4%BB%A5%E6%94%AF%E6%8C%81%E3%80%82">http://phoenix.apache.org/language/functions.html不管条件中的列是否是联合主键中的，Phoenix一样可以支持。</a></p></blockquote><p> 删除数据</p><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DELETE FROM us_population WHERE <span class="keyword">state</span> = &#x27;NA&#x27;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Phoenix映射HBase </p><p>只要直接通过HBase客户端创建的表，若想用Phoenix来进行操作，那么必须要进行表的映射，因为SYSTEM.CATALOG表中并没有维护Phoenix创建表的元数据。</p><p>创建表来进行表的映射</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> 表名(</span><br><span class="line">  列名 类型 主键,</span><br><span class="line">  列簇.列名,</span><br><span class="line">  列簇.列名</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>HBase中的RowKey映射Phoenix的主键，HBase中的Column映射Phoenix的列，且使用列簇名.列名进行映射。<br>相当于在SYSTEM.CATALOG表中录入相关的元数据，使Phoenix能够进行操作它。</p><h3 id="使用二级索引"><a href="#使用二级索引" class="headerlink" title="使用二级索引"></a>使用二级索引</h3><p>在HBase中会自动为RowKey添加索引，因此在通过RowKey查询数据时效率会很高，但是如果要根据其他列来进行组合查询，那么查询的性能就很低下，此时可以使用Phoenix提供的二级索引，能够极大的提高查询数据的性能。</p><p> 我们其实已经知道了我们的主键 是和我们的rowkey进行映射的，所以查询性能高</p><ul><li>创建普通索引<blockquote><p>CREATE INDEX 索引名称 ON 表名(列名)</p></blockquote></li><li>创建二级索引<blockquote><p>CREATE INDEX 索引名称 ON 表名(列名) INCLUDE(列名)</p></blockquote></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RAID技术简介</title>
      <link href="/2023/08/16/RAID%E6%8A%80%E6%9C%AF%E7%AE%80%E4%BB%8B/"/>
      <url>/2023/08/16/RAID%E6%8A%80%E6%9C%AF%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<p><img src="https://pica.zhimg.com/50/3d84e446492f99c8082089313c3944ac_720w.jpg?source=1940ef5c" alt="img"><img src="https://pica.zhimg.com/80/3d84e446492f99c8082089313c3944ac_1440w.jpg?source=1940ef5c" alt="img"></p><p><strong>## 前言</strong></p><p>RAID解释我偷个小懒引用WikipediA，独立硬盘冗余阵列（RAID, Redundant Array of Independent Disks），旧称廉价磁盘冗余阵列（Redundant Array of Inexpensive Disks），简称磁盘阵列。其基本思想就是把多个相对便宜的硬盘组合起来，成为一个硬盘阵列组，使性能达到甚至超过一个价格昂贵、容量巨大的硬盘。根据选择的版本不同，RAID比单颗硬盘有以下一个或多个方面的好处：增强数据集成度，增强容错功能，增加处理量或容量。另外，磁盘阵列对于电脑来说，看起来就像一个单独的硬盘或逻辑存储单元。写这篇文章当然不是单纯的介绍概念和使用方法，更重要的是如何针对不同的业务场景做合理的RAID配置和参数优化，对于SSD固态硬盘的加入我引入小米运维团队的实验数据，同时我也相信分布式存储会逐步走向成熟，以OpenStack，VSAN，Nutanix为代表头顶软件定义和超融合概念的技术也已经开始了暗战。</p><p>&gt; RAID的本质是平衡可用性与成本  </p><p>-–</p><p><strong>## 更新历史</strong></p><p>2016年03月11日 - 初稿</p><p>阅读原文 - <a href="https://link.zhihu.com/?target=http://wsgzao.github.io/post/raid/">RAID磁盘阵列配置和调优小结</a></p><p><strong>扩展阅读</strong></p><p>RAID - <a href="https://link.zhihu.com/?target=https://zh.wikipedia.org/wiki/RAID">https://zh.wikipedia.org/wiki/RAID</a><br>RAID技术发展综述 - <a href="https://link.zhihu.com/?target=http://blog.csdn.net/liuaigui/article/details/4581970">RAID技术发展综述</a><br>SSD阵列卡方案优化：考虑使用RAID 50替代RAID 10 - <a href="https://link.zhihu.com/?target=http://noops.me/?p=1805">SSD阵列卡方案优化：考虑使用RAID 50替代RAID 10</a></p><p>-–</p><p><strong>## RAID基础知识</strong></p><p>&gt;感谢@刘爱贵，详细知识点可参考扩展阅读</p><p>### 基本原理</p><p>RAID （ Redundant Array of Independent Disks ）即独立磁盘冗余阵列，通常简称为磁盘阵列。简单地说， RAID 是由多个独立的高性能磁盘驱动器组成的磁盘子系统，从而提供比单个磁盘更高的存储性能和数据冗余的技术。 RAID 是一类多磁盘管理技术，其向主机环境提供了成本适中、数据可靠性高的高性能存储。 SNIA 对 RAID 的定义是 ：一种磁盘阵列，部分物理存储空间用来记录保存在剩余空间上的用户数据的冗余信息。当其中某一个磁盘或访问路径发生故障时，冗余信息可用来重建用户数据。磁盘条带化虽然与 RAID 定义不符，通常还是称为 RAID （即 RAID0 ）。</p><p>RAID 的初衷是为大型服务器提供高端的存储功能和冗余的数据安全。在整个系统中， RAID 被看作是由两个或更多磁盘组成的存储空间，通过并发地在多个磁盘上读写数据来提高存储系统的 I&#x2F;O 性能。大多数 RAID 等级具有完备的数据校验、纠正措施，从而提高系统的容错性，甚至镜像方式，大大增强系统的可靠性， Redundant 也由此而来。</p><p>这里要提一下 JBOD （ Just a Bunch of Disks ）。最初 JBOD 用来表示一个没有控制软件提供协调控制的磁盘集合，这是 RAID 区别与 JBOD 的主要因素。目前 JBOD 常指磁盘柜，而不论其是否提供 RAID 功能。</p><p>RAID 的两个关键目标是提高数据可靠性和 I&#x2F;O 性能。磁盘阵列中，数据分散在多个磁盘中，然而对于计算机系统来说，就像一个单独的磁盘。通过把相同数据同时写入到多块磁盘（典型地如镜像），或者将计算的校验数据写入阵列中来获得冗余能力，当单块磁盘出现故障时可以保证不会导致数据丢失。有些 RAID 等级允许更多地 磁盘同时发生故障，比如 RAID6 ，可以是两块磁盘同时损坏。在这样的冗余机制下，可以用新磁盘替换故障磁盘， RAID 会自动根据剩余磁盘中的数据和校验数据重建丢失的数据，保证数据一致性和完整性。数据分散保存在 RAID 中的多个不同磁盘上，并发数据读写要大大优于单个磁盘，因此可以获得更高的聚合 I&#x2F;O 带宽。当然，磁盘阵列会减少全体磁盘的总可用存储空间，牺牲空间换取更高的可靠性和性能。比如， RAID1 存储空间利用率仅有 50% ， RAID5 会损失其中一个磁盘的存储容量，空间利用率为 (n-1)&#x2F;n 。</p><p>磁盘阵列可以在部分磁盘（单块或多块，根据实现而论）损坏的情况下，仍能保证系统不中断地连续运行。在重建故障磁盘数据至新磁盘的过程中，系统可以继续正常运行，但是性能方面会有一定程度上的降低。一些磁盘阵列在添加或删除磁盘时必须停机，而有些则支持热交换 （ Hot Swapping ），允许不停机下替换磁盘驱动器。这种高端磁盘阵列主要用于要求高可能性的应用系统，系统不能停机或尽可能少的停机时间。一般来说， RAID 不可作为数据备份的替代方案，它对非磁盘故障等造成的数据丢失无能为力，比如病毒、人为破坏、意外删除等情形。此时的数据丢失是相对操作系统、文件系统、卷管理器或者应用系统来说的，对于 RAID 系统来身，数据都是完好的，没有发生丢失。所以，数据备份、灾 备等数据保护措施是非常必要的，与 RAID 相辅相成，保护数据在不同层次的安全性，防止发生数据丢失。</p><p>RAID 中主要有三个关键概念和技术：镜像（ Mirroring ）、数据条带（ Data Stripping ）和数据校验（ Data parity ）。镜像，将数据复制到多个磁盘，一方面可以提高可靠性，另一方面可并发从两个或多个副本读取数据来提高读性能。显而易见，镜像的写性能要稍低， 确保数据正确地写到多个磁盘需要更多的时间消耗。数据条带，将数据分片保存在多个不同的磁盘，多个数据分片共同组成一个完整数据副本，这与镜像的多个副本是不同的，它通常用于性能考虑。数据条带具有更高的并发粒度，当访问数据时，可以同时对位于不同磁盘上数据进行读写操作， 从而获得非常可观的 I&#x2F;O 性能提升 。数据校验，利用冗余数据进行数据错误检测和修复，冗余数据通常采用海明码、异或操作等算法来计算获得。利用校验功能，可以很大程度上提高磁盘阵列的可靠性、鲁棒性和容错能力。不过，数据校验需要从多处读取数据并进行计算和对比，会影响系统性能。 不同等级的 RAID 采用一个或多个以上的三种技术，来获得不同的数据可靠性、可用性和 I&#x2F;O 性能。至于设计何种 RAID （甚至新的等级或类型）或采用何种模式的 RAID ，需要在深入理解系统需求的前提下进行合理选择，综合评估可靠性、性能和成本来进行折中的选择。</p><p>RAID 思想从提出后就广泛被业界所接纳，存储工业界投入了大量的时间和财力来研究和开发相关产品。而且，随着处理器、内存、计算机接口等技术的不断发展， RAID 不断地发展和革新，在计算机存储领域得到了广泛的应用，从高端系统逐渐延伸到普通的中低端系统。 RAID 技术如此流行，源于其具有显著的特征和优势，基本可以满足大部分的数据存储需求。总体说来， RAID 主要优势有如下几点：<br>(1) 大容量<br>　　这是 RAID 的一个显然优势，它扩大了磁盘的容量，由多个磁盘组成的 RAID 系统具有海量的存储空间。现在单个磁盘的容量就可以到 1TB 以上，这样 RAID 的存储容量就可以达到 PB 级，大多数的存储需求都可以满足。一般来说， RAID 可用容量要小于所有成员磁盘的总容量。不同等级的 RAID 算法需要一定的冗余开销，具体容量开销与采用算法相关。如果已知 RAID 算法和容量，可以计算出 RAID 的可用容量。通常， RAID 容量利用率在 50% ~ 90% 之间。<br>(2) 高性能<br>　　 RAID 的高性能受益于数据条带化技术。单个磁盘的 I&#x2F;O 性能受到接口、带宽等计算机技术的限制，性能往往很有 限，容易成为系统性能的瓶颈。通过数据条带化， RAID 将数据 I&#x2F;O 分散到各个成员磁盘上，从而获得比单个磁盘成倍增长的聚合 I&#x2F;O 性能。<br>(3) 可靠性<br>　　可用性和可靠性是 RAID 的另一个重要特征。从理论上讲，由多个磁盘组成的 RAID 系统在可靠性方面应该比单个磁盘要差。这里有个隐含假定：单个磁盘故障将导致整个 RAID 不可用。 RAID 采用镜像和数据校验等数据冗余技术，打破了这个假定。 镜像是最为原始的冗余技术，把某组磁盘驱动器上的数据完全复制到另一组磁盘驱动器上，保证总有数据副本可用。 比起镜像 50% 的冗余开销 ，数据校验要小很多，它利用校验冗余信息对数据进行校验和纠错。 RAID 冗余技术大幅提升数据可用性和可靠性，保证了若干磁盘出错时，不 会导致数据的丢失，不影响系统的连续运行。<br>(4) 可管理性<br>　　实际上， RAID 是一种虚拟化技术，它对多个物理磁盘驱动器虚拟成一个大容量的逻辑驱动器。对于外部主机系统来说， RAID 是一个单一的、快速可靠的大容量磁盘驱动器。这样，用户就可以在这个虚拟驱动器上来组织和存储应用系统数据。 从用户应用角度看，可使存储系统简单易用，管理也很便利。 由于 RAID 内部完成了大量的存储管理工作，管理员只需要管理单个虚拟驱动器，可以节省大量的管理工作。 RAID 可以动态增减磁盘驱动器，可自动进行数据校验和数据重建，这些都可以 大大简化管理工作。</p><p><strong>### 关键技术</strong></p><p>&gt; 镜像</p><p>镜像是一种冗余技术，为磁盘提供保护功能，防止磁盘发生故障而造成数据丢失。对于 RAID 而言，采用镜像技术 典型地 将会同时在阵列中产生两个完全相同的数据副本，分布在两个不同的磁盘驱动器组上。镜像提供了完全的数据冗余能力，当一个数据副本失效不可用时，外部系统仍可正常访问另一副本，不会对应用系统运行和性能产生影响。而且，镜像不需要额外的计算和校验，故障修复非常快，直接复制即可。镜像技术可以从多个副本进行并发读取数据，提供更高的读 I&#x2F;O 性能，但不能并行写数据，写多个副本会会导致一定的 I&#x2F;O 性能降低。</p><p>镜像技术提供了非常高的数据安全性，其代价也是非常昂贵的，需要　　　至少双倍的存储空间。高成本限制了镜像的广泛应用，主要应用于至关重要的数据保护，这种场合下数据丢失会造成巨大的损失。另外，镜像通过 “ 拆分 ” 能获得特定时间点的上数据快照，从而可以实现一种备份窗口几乎为零的数据备份技术。</p><p>&gt; 数据条带</p><p>磁盘存储的性能瓶颈在于磁头寻道定位，它是一种慢速机械运动，无法与高速的 CPU 匹配。再者，单个磁盘驱动器性能存在物理极限， I&#x2F;O 性能非常有限。 RAID 由多块磁盘组成，数据条带技术将数据以块的方式分布存储在多个磁盘中，从而可以对数据进行并发处理。这样写入和读取数据就可以在多个磁盘上同时进行，并发产生非常高的聚合 I&#x2F;O ，有效提高了整体 I&#x2F;O 性能，而且具有良好的线性扩展性。这对大容量数据尤其显著，如果不分块，数据只能按顺序存储在磁盘阵列的磁盘上，需要时再按顺序读取。而通过条带技术，可获得数倍与顺序访问的性能提升。</p><p>数据条带技术的分块大小选择非常关键。条带粒度可以是一个字节至几 KB 大小，分块越小，并行处理能力就越强，数据存取速度就越高，但同时就会增加块存取的随机性和块寻址时间。实际应用中，要根据数据特征和需求来选择合适的分块大小，在数据存取随机性和并发处理能力之间进行平衡，以争取尽可能高的整体性能。</p><p>数据条带是基于提高 I&#x2F;O 性能而提出的，也就是说它只关注性能， 而对数据可靠性、可用性没有任何改善。实际上，其中任何一个数据条带损坏都会导致整个数据不可用，采用数据条带技术反而增加了数据发生丢失的概念率。</p><p>&gt; 数据校验</p><p>镜像具有高安全性、高读性能，但冗余开销太昂贵。数据条带通过并发性来大幅提高性能，然而对数据安全性、可靠性未作考虑。数据校验是一种冗余技术，它用校验数据来提供数据的安全，可以检测数据错误，并在能力允许的前提下进行数据重构。相对镜像，数据校验大幅缩减了冗余开销，用较小的代价换取了极佳的数据完整性和可靠性。数据条带技术提供高性能，数据校验提供数据安全性， RAID 不同等级往往同时结合使用这两种技术。</p><p>采用数据校验时， RAID 要在写入数据同时进行校验计算，并将得到的校验数据存储在 RAID 成员磁盘中。校验数据可以集中保存在某个磁盘或分散存储在多个不同磁盘中，甚至校验数据也可以分块，不同 RAID 等级实现各不相同。当其中一部分数据出错时，就可以对剩余数据和校验数据进行反校验计算重建丢失的数据。校验技术相对于镜像技术的优势在于节省大量开销，但由于每次数据读写都要进行大量的校验运算，对计算机的运算速度要求很高，必须使用硬件 RAID 控制器。在数据重建恢复方面，检验技术比镜像技术复杂得多且慢得多。</p><p>海明校验码和 异或校验是两种最为常用的 数据校验算法。海明校验码是由理查德 · 海明提出的，不仅能检测错误，还能给出错误位置并自动纠正。海明校验的基本思想是：将有效信息按照某种规律分成若干组，对每一个组作奇偶测试并安排一个校验位，从而能提供多位检错信息，以定位错误点并纠正。可见海明校验实质上是一种多重奇偶校验。异或校验通过异或逻辑运算产生，将一个有效信息与一个给定的初始值进行异或运算，会得到校验信息。如果有效信息出现错误，通过校验信息与初始值的异或运算能还原正确的有效信息。</p><p><strong>## 常见RAID类型</strong></p><p>&gt; 常见5种RAID类型对比，n位磁盘数量，详细介绍可参考扩展阅读</p><table><thead><tr><th>RAID 等级</th><th>RAID0</th><th>RAID1</th><th>RAID5</th><th>RAID6</th><th>RAID10</th></tr></thead><tbody><tr><td>别名</td><td>条带</td><td>镜像</td><td>分布奇偶校验条带</td><td>双重奇偶校验条带</td><td>镜像加条带</td></tr><tr><td>容错性</td><td>无</td><td>有</td><td>有</td><td>有</td><td>有</td></tr><tr><td>冗余类型</td><td>无</td><td>有</td><td>有</td><td>有</td><td>有</td></tr><tr><td>热备盘</td><td>无</td><td>有</td><td>有</td><td>有</td><td>有</td></tr><tr><td>读性能</td><td>高</td><td>低</td><td>高</td><td>高</td><td>高</td></tr><tr><td>随机写性能</td><td>高</td><td>低</td><td>一般</td><td>低</td><td>一般</td></tr><tr><td>连续写性能</td><td>高</td><td>低</td><td>低</td><td>低</td><td>一般</td></tr><tr><td>需要磁盘数</td><td>n≥1</td><td>2n (n≥1)</td><td>n≥3</td><td>n≥4</td><td>2n(n≥2)≥4</td></tr><tr><td>可用容量</td><td>全部</td><td>50%</td><td>(n-1)&#x2F;n</td><td>(n-2)&#x2F;n</td><td>50%</td></tr></tbody></table><p><strong>## RAID 等级</strong></p><p><strong>### 标准 RAID 等级</strong></p><p>SNIA 、 Berkeley 等组织机构把 RAID0 、 RAID1 、 RAID2 、 RAID3 、 RAID4 、 RAID5 、 RAID6 七个等级定为标准的 RAID 等级，这也被业界和学术界所公认。标准等级是最基本的 RAID 配置集合，单独或综合利用数据条带、镜像和数据校验技术。标准 RAID 可以组合，即 RAID 组合等级，满足 对性能、安全性、可靠性要求更高的存储应用需求。</p><p><strong>### JBOD</strong></p><p>JBOD （ Just a Bunch Of Disks ）不是标准的 RAID 等级，它通常用来表示一个没有控制软件提供协调控制的磁盘集合。 JBOD 将多个物理磁盘串联起来，提供一个巨大的逻辑磁盘。 JBOD 的数据存放机制是由第一块磁盘开始按顺序往后存储，当前磁盘存储空间用完后，再依次往后面的磁盘存储数据。 JBOD 存储性能完全等同于单块磁盘，而且也不提供数据安全保护。它只是简单提供一种扩展存储空间的机制， JBOD 可用存储容量等于所有成员磁盘的存储空间之和。目前 JBOD 常指磁盘柜，而不论其是否提供 RAID 功能。</p><p><img src="https://pic3.zhimg.com/50/4cfb57a1c97a239af039a04697baab27_720w.jpg?source=1940ef5c" alt="img"><img src="https://pic3.zhimg.com/80/4cfb57a1c97a239af039a04697baab27_1440w.jpg?source=1940ef5c" alt="img"></p><p><strong>### RAID0</strong></p><p>RAID0 是一种简单的、无数据校验的数据条带化技术。实际上不是一种真正的 RAID ，因为它并不提供任何形式的冗余策略。 RAID0 将所在磁盘条带化后组成大容量的存储空间，将数据分散存储在所有磁盘中，以独立访问方式实现多块磁盘的并读访问。由于可以并发执行 I&#x2F;O 操作，总线带宽得到充分利用。再加上不需要进行数据校验， RAID0 的性能在所有 RAID 等级中是最高的。理论上讲，一个由 n 块磁盘组成的 RAID0 ，它的读写性能是单个磁盘性能的 n 倍，但由于总线带宽等多种因素的限制，实际的性能提升低于理论值。</p><p>RAID0 具有低成本、高读写性能、 100% 的高存储空间利用率等优点，但是它不提供数据冗余保护，一旦数据损坏，将无法恢复。 因此， RAID0 一般适用于对性能要求严格但对数据安全性和可靠性不高的应用，如视频、音频存储、临时数据缓存空间等。</p><p><img src="https://pic3.zhimg.com/50/0ab608c6eef8e74f926f9c1e89753a99_720w.jpg?source=1940ef5c" alt="img"><img src="https://pic3.zhimg.com/80/0ab608c6eef8e74f926f9c1e89753a99_1440w.jpg?source=1940ef5c" alt="img"></p><p><strong>### RAID1</strong></p><p>RAID1 称为镜像，它将数据完全一致地分别写到工作磁盘和镜像 磁盘，它的磁盘空间利用率为 50% 。 RAID1 在数据写入时，响应时间会有所影响，但是读数据的时候没有影响。 RAID1 提供了最佳的数据保护，一旦工作磁盘发生故障，系统自动从镜像磁盘读取数据，不会影响用户工作。</p><p>RAID1 与 RAID0 刚好相反，是为了增强数据安全性使两块 磁盘数据呈现完全镜像，从而达到安全性好、技术简单、管理方便。 RAID1 拥有完全容错的能力，但实现成本高。 RAID1 应用于对顺序读写性能要求高以及对数据保护极为重视的应用，如对邮件系统的数据保护。</p><p><img src="https://pic1.zhimg.com/50/595a2d853196c5b38ceee5d98032baeb_720w.jpg?source=1940ef5c" alt="img"><img src="https://pic1.zhimg.com/80/595a2d853196c5b38ceee5d98032baeb_1440w.jpg?source=1940ef5c" alt="img"></p><p><strong>### RAID5</strong></p><p>RAID5 应该是目前最常见的 RAID 等级，它的原理与 RAID4 相似，区别在于校验数据分布在阵列中的所有磁盘上，而没有采用专门的校验磁盘。对于数据和校验数据，它们的写操作可以同时发生在完全不同的磁盘上。因此， RAID5 不存在 RAID4 中的并发写操作时的校验盘性能瓶颈问题。另外， RAID5 还具备很好的扩展性。当阵列磁盘 数量增加时，并行操作量的能力也随之增长，可比 RAID4 支持更多的磁盘，从而拥有更高的容量以及更高的性能。</p><p>RAID5 的磁盘上同时存储数据和校验数据，数据块和对应的校验信息存保存在不同的磁盘上，当一个数据盘损坏时，系统可以根据同一条带的其他数据块和对应的校验数据来重建损坏的数据。与其他 RAID 等级一样，重建数据时， RAID5 的性能会受到较大的影响。</p><p>RAID5 兼顾存储性能、数据安全和存储成本等各方面因素，它可以理解为 RAID0 和 RAID1 的折中方案，是目前综合性能最佳的数据保护解决方案。 RAID5 基本上可以满足大部分的存储应用需求，数据中心大多采用它作为应用数据的保护方案。</p><p><img src="https://pic1.zhimg.com/50/8ff9b2beeaf295dd1f41d98af50d1ebf_720w.jpg?source=1940ef5c" alt="img"><img src="https://pic1.zhimg.com/80/8ff9b2beeaf295dd1f41d98af50d1ebf_1440w.jpg?source=1940ef5c" alt="img"></p><p><strong>### RAID6</strong></p><p>前面所 述的各个 RAID 等级都只能保护因单个磁盘失效而造成的数据丢失。如果两个磁盘同时发生故障，数据将无法恢复。 RAID6 引入双重校验的概念，它可以保护阵列中同时出现两个磁盘失效时，阵列仍能够继续工作，不会发生数据丢失。 RAID6 等级是在 RAID5 的基础上为了进一步增强数据保护而设计的一种 RAID 方式，它可以看作是一种扩展的 RAID5 等级。</p><p>RAID6 不仅要支持数据的恢复，还要支持校验数据的恢复，因此实现代价很高，控制器的设计也比其他等级更复杂、更昂贵。 RAID6 思想最常见的实现方式是采用两个独立的校验算法，假设称为 P 和 Q ，校验数据可以分别存储在两个不同的校验盘上，或者分散存储在所有成员磁盘中。当两个磁盘同时失效时，即可通过求解两元方程来重建两个磁盘上的数据。</p><p>RAID6 具有快速的读取性能、更高的容错能力。但是，它的成本要高于 RAID5 许多，写性能也较差，并有设计和实施非常复杂。因此， RAID6 很少得到实际应用，主要用于对数据安全等级要求非常高的场合。它一般是替代 RAID10 方案的经济性选择</p><p><img src="https://pic2.zhimg.com/50/e3d61ad32bd894385be86e3c1fcc8ff7_720w.jpg?source=1940ef5c" alt="img"><img src="https://pic2.zhimg.com/80/e3d61ad32bd894385be86e3c1fcc8ff7_1440w.jpg?source=1940ef5c" alt="img"></p><p><strong>### RAID 组合等级</strong></p><p>标准 RAID 等级各有优势和不足。自然地，我们想到把多个 RAID 等级组合起来，实现优势互补，弥补相互的不足，从而达到在性能、数据安全性等指标上更高的 RAID 系统。目前在业界和学术研究中提到的 RAID 组合等级主要有 RAID00 、 RAID01 、 RAID10 、 RAID100 、 RAID30 、 RAID50 、 RAID53 、 RAID60 ，但实际得到较为广泛应用的只有 RAID01 和 RAID10 两个等级。当然，组合等级的实现成本一般都非常昂贵，只是在 少数特定场合应用。</p><p><strong>### RAID10 和 RAID01</strong></p><p>一些文献把这两种 RAID 等级看作是等同的，本文认为是不同的。 RAID01 是先做条带化再作镜像，本质是对物理磁盘实现镜像；而 RAID10 是先做镜像再作条带化，是对虚拟磁盘实现镜像。相同的配置下，通常 RAID01 比 RAID10 具有更好的容错能力。</p><p>RAID01 兼备了 RAID0 和 RAID1 的优点，它先用两块磁盘建立镜像，然后再在镜像内部做条带化。 RAID01 的数据将同时写入到两个磁盘阵列中，如果其中一个阵列损坏，仍可继续工作，保证数据安全性的同时又提高了性能。 RAID01 和 RAID10 内部都含有 RAID1 模式，因此整体磁盘利用率均仅为 50% 。</p><p><img src="https://pic2.zhimg.com/50/29966aef58264fa7eabd94b2baa2fe43_720w.jpg?source=1940ef5c" alt="img"><img src="https://pic2.zhimg.com/80/29966aef58264fa7eabd94b2baa2fe43_1440w.jpg?source=1940ef5c" alt="img"></p><p><img src="https://pica.zhimg.com/50/b522ccd35950243675d164bbdb36011e_720w.jpg?source=1940ef5c" alt="img"><img src="https://pica.zhimg.com/80/b522ccd35950243675d164bbdb36011e_1440w.jpg?source=1940ef5c" alt="img"></p><p><strong>### RAID 50</strong></p><p>RAID 5与RAID 0的组合，先作RAID 5，再作RAID 0，也就是对多组RAID 5彼此构成Stripe访问。由于RAID 50是以RAID 5为基础，而RAID 5至少需要3颗硬盘，因此要以多组RAID 5构成RAID 50，至少需要6颗硬盘。以RAID 50最小的6颗硬盘配置为例，先把6颗硬盘分为2组，每组3颗构成RAID 5，如此就得到两组RAID 5，然后再把两组RAID 5构成RAID 0。</p><p>RAID 50在底层的任一组或多组RAID 5中出现1颗硬盘损坏时，仍能维持运作，不过如果任一组RAID 5中出现2颗或2颗以上硬盘损毁，整组RAID 50就会失效。</p><p>RAID 50由于在上层把多组RAID 5构成Stripe，性能比起单纯的RAID 5高，容量利用率比RAID5要低。比如同样使用9颗硬盘，由各3颗RAID 5再组成RAID 0的RAID 50，每组RAID 5浪费一颗硬盘，利用率为(1-3&#x2F;9)，RAID 5则为(1-1&#x2F;9)。</p><p><img src="https://pic3.zhimg.com/50/8c26881d67c3fc5d88b2172bbed85f48_720w.jpg?source=1940ef5c" alt="img"><img src="https://pic3.zhimg.com/80/8c26881d67c3fc5d88b2172bbed85f48_1440w.jpg?source=1940ef5c" alt="img"></p><p><strong>### RAID 60</strong></p><p>RAID 6与RAID 0的组合：先作RAID 6，再作RAID 0。换句话说，就是对两组以上的RAID 6作Stripe访问。RAID 6至少需具备4颗硬盘，所以RAID 60的最小需求是8颗硬盘。</p><p>由于底层是以RAID 6组成，所以RAID 60可以容许任一组RAID 6中损毁最多2颗硬盘，而系统仍能维持运作；不过只要底层任一组RAID 6中损毁3颗硬盘，整组RAID 60就会失效，当然这种情况的概率相当低。</p><p>比起单纯的RAID 6，RAID 60的上层通过结合多组RAID 6构成Stripe访问，因此性能较高。不过使用门槛高，而且容量利用率低是较大的问题。</p><p><img src="https://pic1.zhimg.com/50/7d1922f356f6e2be74cdae8c3cc8b2ac_720w.jpg?source=1940ef5c" alt="img"><img src="https://pic1.zhimg.com/80/7d1922f356f6e2be74cdae8c3cc8b2ac_1440w.jpg?source=1940ef5c" alt="img"></p><p><strong>## 关于RAID参数调优</strong></p><p>&gt; 通常情况下建议系统(RAID1)与数据(RAID[5|10])分离，这里引用@叶金荣老师的一段话</p><p>\1. 使用SSD或者PCIe SSD设备，至少获得数百倍甚至万倍的IOPS提升<br>\2. 购置阵列卡同时配备CACHE及BBU模块，可明显提升IOPS（主要是指机械盘，SSD或PCIe SSD除外。同时需要定期检查CACHE及BBU模块的健康状况，确保意外时不至于丢失数据）<br>\3. 有阵列卡时，设置阵列写策略为WB，甚至FORCE WB（若有双电保护，或对数据安全性要求不是特别高的话），严禁使用WT策略。并且闭阵列预读策略<br>\4. 尽可能选用RAID-10，而非RAID-5(<code>这句话有待商榷</code>)<br>\5. 使用机械盘的话，尽可能选择高转速的，例如选用15KRPM，而不是7.2KRPM的盘，不差几个钱的；</p><p><strong>## SSD阵列卡方案优化</strong></p><p>&gt; 感谢@小米noops运维团队，详细实验数据请参考扩展阅读</p><p><img src="https://pic1.zhimg.com/50/c4132b7b42d2758db39d1644ee5a3963_720w.jpg?source=1940ef5c" alt="img"><img src="https://pic1.zhimg.com/80/c4132b7b42d2758db39d1644ee5a3963_1440w.jpg?source=1940ef5c" alt="img"></p><p><img src="https://pica.zhimg.com/50/c76b4b4d0d3877d242ccbc037e3c3aff_720w.jpg?source=1940ef5c" alt="img"><img src="https://pica.zhimg.com/80/c76b4b4d0d3877d242ccbc037e3c3aff_1440w.jpg?source=1940ef5c" alt="img"></p><p><strong>性能测试结论</strong></p><p>性能测试显示，相同容量的R50和R10性能接近：其中小块文件的随机读R50要全面好于R10，随机写4K虽然R50和R10差距在28%，但是块增大后R50要全面优于R10。顺序读写方面，R50和R10十分接近。</p><p>容错方面，R50接近R10：第二块盘容错率R50十分接近R10，两者相差30%。R10的优势主要是在有一定的概率提供第三、甚至第四块磁盘的容错率，但是考虑到并非100%容错，因此从容错角度来看R50虽然和R10有一些差距，但也已体现出较好的容错率，至少优于R5。而且R50搭配灵活，甚至可以指定3组R5以达到最大3块磁盘的容错；</p><p>成本方面，R50有很大优势：按这个配置计算R50只有R10的3&#x2F;4。</p><p><strong>总结</strong></p><p>RAID 50提供了接近RAID 10性能、可用性以及接近RAID 5成本的特性，具有较好的整体性价比优势，所以考虑使用RAID 50替换RAID 10吧</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>群晖变身airdrop</title>
      <link href="/2023/08/16/%E7%BE%A4%E6%99%96%E5%8F%98%E8%BA%ABairdrop/"/>
      <url>/2023/08/16/%E7%BE%A4%E6%99%96%E5%8F%98%E8%BA%ABairdrop/</url>
      
        <content type="html"><![CDATA[<p>把群晖 NAS 变成「时间返回舱」，轻松搞定 Time Machine 无线备份</p><p>2018年11月18日</p><p>相比 Windows 自带的系统还原功能，macOS 有着更加完善的备份还原机制：通过内置的 Time Machine，我们可以方便地进行整机备份，在关键时候成为系统以及重要资料一颗「后悔药」。</p><p>当然，如果需要使用 Time Machine 功能备份，苹果官方提供了两种方式，无论哪一种方式，你都需要外置的存储来解决：一种是准备一个较合适容量的移动硬盘，如果你正好有一个闲置不用的移动硬盘，拿出来做专门的 Mac 的 Time Machine 备份倒是不错，只不过就会比较麻烦——每一次备份都需要插入移动硬盘。</p><p>还有一种是使用网络存储器，比如说苹果官方的高存储容量 AirPort Time Capsule（时间返回舱），设置一次就可以轻松完成自动备份工作，但其售价高昂不说，现在也已经全面在苹果在线商店下架，显然无论是从经济角度还是便利性角度而言，以上两个方案似乎都并不合适。</p><p>其实，如果你恰好有一台群晖 NAS ，就可以将其轻松打造成一个稳定可靠的「时间返回舱」，而该功能从入门级的 J 系列就已经默认搭载，换句话说，你几乎没有什么额外成本就可以拥有和 AirPort Time Capsule 近乎一样的功能，那么如何使用 Time Machine 将 Mac 文件备份至群晖呢？</p><h2 id="如何让群晖-NAS-支持-Time-Machine-功能？"><a href="#如何让群晖-NAS-支持-Time-Machine-功能？" class="headerlink" title="如何让群晖 NAS 支持 Time Machine 功能？"></a>如何让群晖 NAS 支持 Time Machine 功能？</h2><p>要想让群晖支持 Time Machine ，还需要对群晖进行一番设置，首先我们使用管理员账号登录群晖的 DSM 系统1 ，首先来创建一个共享文件夹，专门用来存放 Time Machine 的备份数据：</p><p>登录到 DSM 之后，点击「控制面板 - 共享文件夹」，点击「创建」来添加共享文件夹。</p><p><img src="https://cdn.sspai.com/2018/11/18/ac135adbe134d0703a7acac6bbc4a04c.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>然后输入共享文件夹的名字2 ，然后选择一个所在位置（单盘 NAS 选择默认）：</p><p><img src="https://cdn.sspai.com/2018/11/18/7992d79626fd2f571cae842bde49b2c1.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>后面一步就是是否需要加密，因为我是本地家庭环境使用，为了减少一些不必要的麻烦直接跳过，如果你是在公司中来操作则建议设置加密，然后点击下一步。</p><p><img src="https://cdn.sspai.com/2018/11/18/940f3d290ab4cb4f91a7e6ee58d08d49.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>后面是为共享文件夹配置高级功能，这里我就直接跳过，然后确认设置下面选择应用。</p><p><img src="https://cdn.sspai.com/2018/11/18/57993635211b319945fe96921a7ef000.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>最后会弹出读取权限的设置，这里面默认应该只有管理员（当前你登录的账户）读写权限，这里默认不修改，点击确定生成分享文件夹。</p><p><img src="https://cdn.sspai.com/2018/11/18/a715c3349fbeca61d476e5050bb05bcf.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>现在你应该可以看到名为 Time Machine Folder 新共享文件夹了，下面进入到下一步，为这个文件夹配可访问的账号。</p><h2 id="在-NAS-中为-Time-Machine-创建管理用户"><a href="#在-NAS-中为-Time-Machine-创建管理用户" class="headerlink" title="在 NAS 中为 Time Machine 创建管理用户"></a>在 NAS 中为 Time Machine 创建管理用户</h2><p>Time Machine Folder 这个文件夹显然应该只需要有一个专门操作的账户来操作，使用管理员账号操作并不安全，因此在这里我们需要给 Time Machine 创建管理用户并为其配备的对应配额限制。</p><p><img src="https://cdn.sspai.com/2018/11/18/86234695bbbb0758f2aa1d1567eca86b.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>首先，还是通过群晖的管理员账户登录 DSM ，在「控制面板 - 用户」中，点击「创建用户」，输入用户名3 并设置一个复杂密码，然后点下一步，在群组中保持默认再点下一步。</p><p><img src="https://cdn.sspai.com/2018/11/18/9b3e81fc108b528526b47257a8c8e7a5.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>在文件夹的权限分配这个设置页中，找到之前设置的共享文件夹「Time Machine Folder」，<strong>勾选中「读写」权限（一定要做），</strong>然后点击下一步，在用户配合设置页面中，选择存储配额。</p><p>这一步需要注意的是，为了避免 Time Machine 备份占用你全部的存储空间，建议设置在一个额定的空间范围内，比如我的 MacBook Pro 是 128GB 的存储，而我的群晖 NAS 的存储「空间 1」剩余 2.0 TB ，因此从使用权衡来看，选择 200GB 完全是绰绰有余，制定好之后选择下一步。</p><p><img src="https://cdn.sspai.com/2018/11/18/85d0d591291cf483391f7ad169493d12.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>后续两个设置中都默认不选，直接点下一步，最后点击到应用后完成用户「Time Machine User」的新建，最后你在「控制面板 - 用户」中应该可以看到这个新建的用户了。</p><p><img src="https://cdn.sspai.com/2018/11/18/cf650e3ab4e93f9bb7ec52c84e61124b.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>p.s.  如果你是在企业生产环境中，可以通过生成配对的「共享文件夹」+「对应的用户」来创建多个 Time Machine 备份空间，这样可以为多台 Mac 设备开启单独的备份，管理也更方便。</p><h2 id="在-NAS-中开启相关文件服务"><a href="#在-NAS-中开启相关文件服务" class="headerlink" title="在 NAS 中开启相关文件服务"></a>在 NAS 中开启相关文件服务</h2><p>前面共享文件夹和相关的访问用户已经设置完毕，那么接下来就是对相关的文件夹进行一系列的设置。首先在群晖的「控制面板 - 文件服务」设置中，找到 <strong>SMB&#x2F;AFP&#x2F;NFS</strong> 选项卡，然后点击勾选 启用 SMB 服务以及 AFP 服务。注意下方生成的访问地址，例如我这里生成的 SMB 访问地址：<code>smb://DS215J</code>。</p><p><img src="https://cdn.sspai.com/2018/11/18/9a0808946eb2a9d0c1e4cebe4919a8bb.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>然后切换到高级设置中，在 Bonjour 中勾选「启用 Bonjour 服务发现」，以及下方的「启用通过 SMB 进行 Bonjour Time Machine 播送」和「启用通过 AFP 进行 Bonjour Time Machine 播送」，然后点击下方的设置 Time machine 文件夹，选择之前我们建立的 「Time Machine Folder」共享文件夹点击确定即可。</p><p><img src="https://cdn.sspai.com/2018/11/18/dbf8339cefcd9273213e57735e8c8d4d.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>p.s. 如果你的环境中，Mac 设备的系统版本在 10.12 以上，那么只需要启用 SMB 相关服务即可，可以不用勾选 AFP 服务。</p><p>至此，在群晖上的相关设置就全部完成了，换言之，这时候的群晖已经脱胎换骨成为一台「时间返回舱」了。</p><h2 id="让-Mac-的-Time-Machine-备份至-NAS"><a href="#让-Mac-的-Time-Machine-备份至-NAS" class="headerlink" title="让 Mac 的 Time Machine 备份至 NAS"></a>让 Mac 的 Time Machine 备份至 NAS</h2><p>接下来的步骤就是在 Mac 上设置时间机器，然后将备份目的地改成刚才设置好的群晖，首先在我们需要可以让 Mac 访问群晖中的备份文件夹。</p><p><img src="https://cdn.sspai.com/2018/11/18/c67463c703df1874de7c6318052b2430.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>打开访达，在菜单中点击「前往 - 连接服务器」，然后输入 NAS 的 smb 地址，例如我这里的 <code>smb://DS215J</code>，然后点击链接，在输入之前设置的账户名和密码之后，在弹出的文件夹中，选择时间机器的备份文件夹，之后点击好完成装载。</p><p><img src="https://cdn.sspai.com/2018/11/18/1f1c1dea15242ee5d673acbdbc7e7429.png?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt="img"></p><p>接下来从 Dock 栏中打开「系统偏好设置」，在「时间机器」中选择「备份磁盘」，然后选择之前链接的群晖对应的文件夹，然后点击使用磁盘。</p><p>这时候还有可能会要求输入之前在群晖中创建的账户和密码，然后点击链接，然后时间机器会自动绑定群晖设置到了备份目的磁盘，然后到这里你的时间机器就算是真正意义上的设置好了，如果不出意外的话就会自动开始进行备份工作。</p><p>通过一连串的操作之后，你的群晖可以轻松化身为一台「廉价版 AirPort Time Capsule」，为你的 Mac 设备保驾护航，而无论是性价比上还是便利性上都可以称作是 Mac 时间机器的最佳解决方案，如果你恰好有一台 Mac 和群晖设备，不妨试试这个方案来打造一个最廉价的时间机器备份方案。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>kubeflow基础搭建</title>
      <link href="/2023/08/16/kubeflow%E5%9F%BA%E7%A1%80%E6%90%AD%E5%BB%BA/"/>
      <url>/2023/08/16/kubeflow%E5%9F%BA%E7%A1%80%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>hadoop安装</title>
      <link href="/2023/08/16/hadoop%E5%AE%89%E8%A3%85/"/>
      <url>/2023/08/16/hadoop%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p>Hadoop 下载地址:<a href="https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/">https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/</a></p><p>cd &#x2F;opt&#x2F;software&#x2F;</p><p>解压安装文件到&#x2F;opt&#x2F;module 下面<br>[andrew@hadoop101 software]$ tar -zxvf hadoop-3.1.3.tar.gz -C &#x2F;opt&#x2F;module&#x2F;</p><p>将 Hadoop 添加到环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP_HOME  </span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-3.1.3   </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin  </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin   </span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure><p>修改以下文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim mapred-site.xml</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>vim yarn-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--MR shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 关闭yarn对物理内存和虚拟内存的限制检查 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmen-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmen-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>vim hdfs-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--nn web访问 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">     <span class="comment">&lt;!--2nn web访问 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">     <span class="comment">&lt;!-- 指定hdfs副本数量 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///opt/module/hadoop-3.1.3/data/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>vim workers<br>localhost</p><p>vim core-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--指定NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- hadoop数据存放目录 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!--HDFS网页登入使用的的静态用户为andrew --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>andrew<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 配置andrew允通过代理访问主机节点 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.andrew.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 配置andrew允通过代理访问主机节点 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.andrew.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>io.compression.codecs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">org.apache.hadoop.io.compress.GzipCodec,</span><br><span class="line">org.apache.hadoop.io.compress.DefaultCodec,</span><br><span class="line">org.apache.hadoop.io.compress.BZip2Codec,</span><br><span class="line">org.apache.hadoop.io.compress.SnappyCodec,</span><br><span class="line">com.hadoop.compression.lzo.LzoCodec,</span><br><span class="line">com.hadoop.compression.lzo.LzopCodec</span><br><span class="line"><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>io.compression.codec.lzo.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>com.hadoop.compression.lzo.LzoCodec<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>vim hadoop-env.sh</p><figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">export HDFS_NAMENODE_USER=andrew</span><br><span class="line">export HDFS_DATANODE_USER=andrew</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=andrew</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=andrew</span><br><span class="line">export YARN_NODEMANAGER_USER=andrew</span><br><span class="line">export HDFS_JOURNALNODE_USER=andrew</span><br><span class="line">export HDFS_ZKFC_USER=andrew</span><br><span class="line">export HADOOP_SHELL_EXECNAME=andrew</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elasticsearch分布式安装</title>
      <link href="/2023/08/16/elasticsearch%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/"/>
      <url>/2023/08/16/elasticsearch%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>minio分布式安装</title>
      <link href="/2023/08/16/minio%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/"/>
      <url>/2023/08/16/minio%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>redis分布式安装</title>
      <link href="/2023/08/16/redis%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/"/>
      <url>/2023/08/16/redis%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p>python 操作redis</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"></span><br><span class="line"><span class="comment">#   连接redis</span></span><br><span class="line"><span class="comment">#   几个常用默认参数：</span></span><br><span class="line"><span class="comment">#   host=&#x27;localhost&#x27;, port=6379, db=0, decode_responses=False, password=None</span></span><br><span class="line">pool = redis.ConnectionPool(host=<span class="string">&#x27;ip-address&#x27;</span>, port=<span class="number">6379</span>, decode_responses=<span class="literal">True</span>,db=<span class="number">1</span>,password=<span class="string">&#x27;password&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---redis</span></span><br></pre></td></tr></table></figure><p>字符串</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">r = redis.Redis(connection_pool=pool)</span><br><span class="line"><span class="comment">#   增加数据：set key value（如果key存在，则修改为新的value）</span></span><br><span class="line"><span class="built_in">print</span>(r.<span class="built_in">set</span>(<span class="string">&#x27;str_type&#x27;</span>, <span class="string">&#x27;str_value&#x27;</span>))  <span class="comment"># 打印True</span></span><br><span class="line"><span class="comment">#   追加数据：append key value</span></span><br><span class="line"><span class="built_in">print</span>(r.append(<span class="string">&#x27;str_type&#x27;</span>, <span class="string">&#x27;_new&#x27;</span>))  <span class="comment"># 打印13，字符长度</span></span><br><span class="line"><span class="comment">#   查看数据：get key</span></span><br><span class="line"><span class="built_in">print</span>(r.get(<span class="string">&#x27;str_type&#x27;</span>))</span><br></pre></td></tr></table></figure><p>数组</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#   在插入数据时，如果该键并不存在，Redis将为该键创建一个</span></span><br><span class="line"><span class="comment">#   在末尾添加数据（列表右边）</span></span><br><span class="line">r.rpush(<span class="string">&#x27;list_type&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;xy&#x27;</span>, <span class="string">&#x27;li_val_end&#x27;</span>)</span><br><span class="line"><span class="comment">#   在头部添加数据（列表左边）</span></span><br><span class="line">r.lpush(<span class="string">&#x27;list_type&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;xy&#x27;</span>, <span class="string">&#x27;li_val_start&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#   查看数据</span></span><br><span class="line"><span class="comment">#   数据为：[&#x27;li_val_start&#x27;, &#x27;xy&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;xy&#x27;, &#x27;li_val_end&#x27;]</span></span><br><span class="line"><span class="comment">#   下标范围：lrange key start stop</span></span><br><span class="line"><span class="built_in">print</span>(r.lrange(<span class="string">&#x27;list_type&#x27;</span>, <span class="number">0</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment">#   指定下标：lindex key index</span></span><br><span class="line"><span class="built_in">print</span>(r.lindex(<span class="string">&#x27;list_type&#x27;</span>, -<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#   删除数据</span></span><br><span class="line"><span class="comment">#   从末尾删除（列表右边）：rpop key</span></span><br><span class="line"><span class="built_in">print</span>(r.rpop(<span class="string">&#x27;list_type&#x27;</span>))  <span class="comment"># 打印删除的值</span></span><br><span class="line"><span class="comment">#   从头部删除（列表左边）：lpop key</span></span><br><span class="line"><span class="built_in">print</span>(r.lpop(<span class="string">&#x27;list_type&#x27;</span>))  <span class="comment"># 打印删除的值</span></span><br><span class="line"><span class="comment">#   指定值删除：lrem key count(可以存在多个重复的值，指定value删除的次数) value</span></span><br><span class="line"><span class="built_in">print</span>(r.lrem(<span class="string">&#x27;list_type&#x27;</span>, <span class="number">2</span>, <span class="string">&#x27;xy&#x27;</span>))  <span class="comment"># 打印成功删除的个数</span></span><br></pre></td></tr></table></figure><p>字典类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#   hash类型的值是一个键值对集合，如：h_test : &#123; field1:value1, field2:value2,...&#125;</span></span><br><span class="line"><span class="comment">#   添加数据：hset key field value</span></span><br><span class="line"><span class="built_in">print</span>(r.hset(<span class="string">&#x27;hash_type&#x27;</span>, <span class="string">&#x27;filed&#x27;</span>, <span class="string">&#x27;value&#x27;</span>))  <span class="comment"># 打印成功添加数据的条数</span></span><br><span class="line"><span class="comment">#   查看域值：hget key field</span></span><br><span class="line"><span class="built_in">print</span>(r.hget(<span class="string">&#x27;hash_type&#x27;</span>, <span class="string">&#x27;filed&#x27;</span>))</span><br><span class="line"><span class="comment">#   查看所有的field：hkeys key</span></span><br><span class="line"><span class="built_in">print</span>(r.hkeys(<span class="string">&#x27;hash_type&#x27;</span>))</span><br><span class="line"><span class="comment">#   查看所有的value：hvals key</span></span><br><span class="line"><span class="built_in">print</span>(r.hvals(<span class="string">&#x27;hash_type&#x27;</span>))</span><br><span class="line"><span class="comment">#   查看所有的键值对：hgetall key</span></span><br><span class="line"><span class="built_in">print</span>(r.hgetall(<span class="string">&#x27;hash_type&#x27;</span>))</span><br></pre></td></tr></table></figure><h1 id="python-zset"><a href="#python-zset" class="headerlink" title="python zset"></a>python zset</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">conn=redis.StrictRedis(host=<span class="string">&#x27;192.168.80.41&#x27;</span>,port=<span class="number">6379</span>,db=<span class="number">0</span>)</span><br><span class="line">conn.zadd(<span class="string">&#x27;znames&#x27;</span>,<span class="number">100</span>,<span class="string">&#x27;jiang&#x27;</span>)</span><br><span class="line">conn.zadd(<span class="string">&#x27;znames&#x27;</span>,<span class="number">20</span>,<span class="string">&#x27;wolson&#x27;</span>)</span><br><span class="line">    <span class="comment">#向有顺集合中增加一个元素jiang、它的分值为100</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(conn.zscore(<span class="string">&#x27;znames&#x27;</span>,<span class="string">&#x27;jiang&#x27;</span>))</span><br><span class="line">    <span class="comment">#获取jiang这个元素的分值</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(conn.zrange(<span class="string">&#x27;znames&#x27;</span>,<span class="number">0</span>,-<span class="number">1</span>,desc=<span class="literal">True</span>,withscores=<span class="literal">True</span>))</span><br><span class="line">    <span class="comment">#获取集合中指定序列内的元素</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(conn.zrangebyscore(<span class="string">&#x27;znames&#x27;</span>,<span class="number">80</span>,<span class="number">100</span>))</span><br><span class="line">    <span class="comment">#获取指定分数范围内的元素</span></span><br><span class="line"></span><br><span class="line">newScore=conn.zincrby(<span class="string">&#x27;znames&#x27;</span>,<span class="string">&#x27;wolson&#x27;</span>,<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(newScore)</span><br><span class="line"><span class="built_in">print</span>(conn.zscore(<span class="string">&#x27;znames&#x27;</span>,<span class="string">&#x27;wolson&#x27;</span>))</span><br><span class="line">    <span class="comment">#增加指定元素的分值</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(conn.zcard(<span class="string">&#x27;znames&#x27;</span>))</span><br><span class="line">    <span class="comment">#获取集合中的元素数</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(conn.zcount(<span class="string">&#x27;znames&#x27;</span>,<span class="number">90</span>,<span class="number">101</span>))</span><br><span class="line">    <span class="comment">#获取分数范围内的元素数量</span></span><br><span class="line"></span><br><span class="line">conn.zrem(<span class="string">&#x27;znames&#x27;</span>,<span class="string">&#x27;wolson&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(conn.zrange(<span class="string">&#x27;znames&#x27;</span>,<span class="number">0</span>,-<span class="number">1</span>))</span><br><span class="line">    <span class="comment">#删除集合中指定元素</span></span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mongodb 分布式安装</title>
      <link href="/2023/08/16/mongodb-%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/"/>
      <url>/2023/08/16/mongodb-%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p>参考搭建文档<a href="https://blog.csdn.net/msh6453/article/details/131161845">https://blog.csdn.net/msh6453/article/details/131161845</a></p><p>前言<br>官方文档：<a href="https://www.mongodb.com/docs/%EF%BC%88%E5%8F%AF%E4%BB%A5%E5%8F%82%E8%80%83%EF%BC%89">https://www.mongodb.com/docs/（可以参考）</a></p><h2 id="一，安装说明"><a href="#一，安装说明" class="headerlink" title="一，安装说明"></a>一，安装说明</h2><p>1.1环境说明<br>1、首先确定部署的环境，确定下服务器的端口，一般默认是22的端口；<br>2、操作系统Centos7.9；<br>3、 数据库mongodb-linux-x86_64-rhel70-4.4.22。<br>mongodb版本4.4.22</p><p><img src="/image-1.png" alt="Alt text"></p><p>mongos，数据库集群请求的入口，所有的请求都通过mongos进行协调，不需要在应用程序添加一个路由选择器，mongos自己就是一个请求分发中心，它负责把对应的数据请求请求转发到对应的shard服务器上。在生产环境通常有多mongos作为请求的入口，防止其中一个挂掉所有的mongodb请求都没有办法操作。</p><p>config server，顾名思义为配置服务器，存储所有数据库元信息（路由、分片）的配置。mongos本身没有物理存储分片服务器和数据路由信息，只是缓存在内存里，配置服务器则实际存储这些数据。mongos第一次启动或者关掉重启就会从 config server 加载配置信息，以后如果配置服务器信息变化会通知到所有的 mongos 更新自己的状态，这样 mongos 就能继续准确路由。在生产环境通常有多个 config server 配置服务器，因为它存储了分片路由的元数据，防止数据丢失！</p><p>shard，分片（sharding）是指将数据库拆分，将其分散在不同的机器上的过程。将数据分散到不同的机器上，不需要功能强大的服务器就可以存储更多的数据和处理更大的负载。基本思想就是将集合切成小块，这些块分散到若干片里，每个片只负责总数据的一部分，最后通过一个均衡器来对各个分片进行均衡（数据迁移）。</p><p>replica set，中文翻译副本集，其实就是shard的备份，防止shard挂掉之后数据丢失。复制提供了数据的冗余备份，并在多个服务器上存储数据副本，提高了数据的可用性， 并可以保证数据的安全性。</p><p>仲裁者（Arbiter），是复制集中的一个MongoDB实例，它并不保存数据。仲裁节点使用最小的资源并且不要求硬件设备，不能将Arbiter部署在同一个数据集节点中，可以部署在其他应用服务器或者监视服务器中，也可部署在单独的虚拟机中。为了确保复制集中有奇数的投票成员（包括primary），需要添加仲裁节点做为投票，否则primary不能运行时不会自动切换primary。</p><p>简单了解之后，我们可以这样总结一下，应用请求mongos来操作mongodb的增删改查，配置服务器存储数据库元信息，并且和mongos做同步，数据最终存入在shard（分片）上，为了防止数据丢失同步在副本集中存储了一份，仲裁在数据存储到分片的时候决定存储到哪个节点。</p><table><thead><tr><th>服务器</th><th>ceph-node-1</th><th>ceph-node-2</th><th>ceph-node-3</th></tr></thead><tbody><tr><td>ip</td><td>10.30.0.48</td><td>10.30.0.49</td><td>10.30.0.50</td></tr><tr><td>server-route</td><td>mongos</td><td>mongos</td><td>mongos</td></tr><tr><td>server-config</td><td>config server</td><td>config server</td><td>config server</td></tr><tr><td>server-config</td><td>shard server1 主节点</td><td>shard server1 副节点</td><td>shard server1 仲裁</td></tr><tr><td>server-config</td><td>shard server2 仲裁</td><td>shard server2 主节点</td><td>shard server2 副节点</td></tr><tr><td>server-config</td><td>shard server3 副节点</td><td>shard server3 仲裁</td><td>shard server3 主节点</td></tr></tbody></table><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/mongo/MongoDB/conf</span><br><span class="line"><span class="built_in">mkdir</span> -p /opt/mongo/MongoDB/server</span><br><span class="line"><span class="built_in">mkdir</span> -p /opt/mongo/MongoDB/mongos/log</span><br><span class="line"><span class="built_in">mkdir</span> -p /opt/mongo/MongoDB/config/data</span><br><span class="line"><span class="built_in">mkdir</span> -p /opt/mongo/MongoDB/config/log</span><br><span class="line"><span class="built_in">mkdir</span> -p /opt/mongo/MongoDB/shard1/data</span><br><span class="line"><span class="built_in">mkdir</span> -p /opt/mongo/MongoDB/shard1/log</span><br><span class="line"><span class="built_in">mkdir</span> -p /opt/mongo/MongoDB/shard2/data</span><br><span class="line"><span class="built_in">mkdir</span> -p /opt/mongo/MongoDB/shard2/log</span><br><span class="line"><span class="built_in">mkdir</span> -p /opt/mongo/MongoDB/shard3/data</span><br><span class="line"><span class="built_in">mkdir</span> -p /opt/mongo/MongoDB/shard3/log</span><br><span class="line"></span><br><span class="line">wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-4.4.22.tgz</span><br><span class="line">tar -xvzf mongodb-linux-x86_64-rhel70-4.4.22.tgz -C /opt/mongo/MongoDB/server/</span><br><span class="line"><span class="built_in">mv</span> /opt/mongo/MongoDB/server/mongodb-linux-x86_64-rhel70-4.4.22 /opt/mongo/MongoDB/server/mongodb</span><br><span class="line"></span><br><span class="line">vim /etc/profile</span><br><span class="line"><span class="built_in">export</span> MONGODB_HOME=/opt/mongo/MongoDB/server/mongodb</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$MONGODB_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line">:wq!</span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line">vim /opt/mongo/MongoDB/conf/config.conf </span><br><span class="line">vim /opt/mongo/MongoDB/conf/shard1.conf</span><br><span class="line">vim /opt/mongo/MongoDB/conf/shard2.conf</span><br><span class="line">vim /opt/mongo/MongoDB/conf/shard3.conf</span><br><span class="line">vim /opt/mongo/MongoDB/conf/mongos.conf</span><br></pre></td></tr></table></figure><p>配置文件如mongo&#x2F;conf 下面<br>注意安装的时候不要设置最后的安全密钥，待完毕后添加</p><p>启动服务顺序</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mongod -f /opt/mongo/MongoDB/conf/config.conf</span><br><span class="line">mongod -f /opt/mongo/MongoDB/conf/shard1.conf</span><br><span class="line">mongod -f /opt/mongo/MongoDB/conf/shard2.conf</span><br><span class="line">mongod -f /opt/mongo/MongoDB/conf/shard3.conf</span><br><span class="line">mongos -f /opt/mongo/MongoDB/conf/mongos.conf</span><br></pre></td></tr></table></figure><p>随便登入一台</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mongo 10.30.0.48:21000</span><br><span class="line">use admin</span><br><span class="line">config = &#123;_id : &quot;config&quot;,members : [&#123;_id : 0, host : &quot;10.30.0.48:21000&quot; &#125;,</span><br><span class="line">&#123;_id : 1, host : &quot;10.30.0.49:21000&quot; &#125;,&#123;_id : 2, host : &quot;10.30.0.50:21000&quot; &#125;]&#125;</span><br><span class="line">rs.initiate(config)</span><br></pre></td></tr></table></figure><p>同理 server sharded1</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mongo 10.30.0.48:27001</span><br><span class="line">use admin</span><br><span class="line">config = &#123; _id : &quot;shard1&quot;,members : [&#123;_id : 0, host : &quot;10.30.0.48:27001&quot; ,priority: 2 &#125;,&#123;_id : 1, host : &quot;10.30.0.49:27001&quot; ,priority: 1 &#125;,&#123;_id : 2, host : &quot;10.30.0.50:27001&quot;,arbiterOnly: true&#125;]&#125;</span><br><span class="line">//(“priority”优先级，数字越大，优先等级越高；“arbiterOnly”冲裁节点；冲裁节点根据优先等级判断哪个节点作为主节点)</span><br><span class="line">rs.initiate(config)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mongo 10.30.0.48:27002</span><br><span class="line">server shard2</span><br><span class="line">use admin</span><br><span class="line">config = &#123; _id : <span class="string">&quot;shard2&quot;</span>,members : [&#123;_id : 0, host : <span class="string">&quot;10.30.0.48:27002&quot;</span> ,arbiterOnly: <span class="literal">true</span> &#125;,</span><br><span class="line">&#123;_id : 1, host : <span class="string">&quot;10.30.0.49:27002&quot;</span> ,priority: 2 &#125;,&#123;_id : 2, host : <span class="string">&quot;10.30.0.50:27002&quot;</span>,priority: 1&#125;]&#125;</span><br><span class="line">rs.initiate(config)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>server shard3</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mongo 10.30.0.48:27003</span><br><span class="line">use admin</span><br><span class="line">config = &#123; _id : &quot;shard3&quot;,members : [&#123;_id : 0, host : &quot;10.30.0.48:27003&quot; ,priority: 1 &#125;,</span><br><span class="line"></span><br><span class="line">&#123;_id : 1, host : &quot;10.30.0.49:27003&quot; ,arbiterOnly: true &#125;,&#123;_id : 2, host : &quot;10.30.0.50:27003&quot;,priority: 2&#125;]&#125;</span><br><span class="line"></span><br><span class="line">rs.initiate(config)</span><br></pre></td></tr></table></figure><p>添加分片服务器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">use admin</span><br><span class="line">sh.addShard(<span class="string">&quot;shard1/10.30.0.48:27001,10.30.0.49:27001,10.30.0.50:27001&quot;</span>)</span><br><span class="line"></span><br><span class="line">sh.addShard(<span class="string">&quot;shard2/10.30.0.48:27002,10.30.0.49:27002,10.30.0.50:27002&quot;</span>)</span><br><span class="line"></span><br><span class="line">sh.addShard(<span class="string">&quot;shard3/10.30.0.48:27003,10.30.0.49:27003,10.30.0.50:27003&quot;</span>)</span><br><span class="line"></span><br><span class="line">sh.status()</span><br></pre></td></tr></table></figure><p>创建用户</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">执行命令： mongo -port 20000</span><br><span class="line">执行命令： use admin//这个条件是必须的</span><br><span class="line">执行命令：db.createUser(</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line"></span><br><span class="line">        user:<span class="string">&quot;ml_grp&quot;</span>,</span><br><span class="line"></span><br><span class="line">        <span class="built_in">pwd</span>:<span class="string">&quot;ml&amp;dl#mongodb&quot;</span>,</span><br><span class="line"></span><br><span class="line">        roles:[&#123;role:<span class="string">&quot;root&quot;</span>,db:<span class="string">&quot;admin&quot;</span>&#125;]</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>use admin<br>执行命令：db.auth(‘ml_grp’,’passwd’)<br>执行命令：db.runCommand( { enablesharding :”zjxndc”});&#x2F;&#x2F;为zjxndc开启分片功能<br>执行命令：db.runCommand( { shardcollection : “zjxndc.measureHisvalues”,key : {_id: 1} } )&#x2F;</p><p>use config<br>db.settings.save({“_id”:”chunksize”,”value”:1})<br>use zjxndc<br>d、执行命令：for (var i &#x3D; 1; i &lt;&#x3D; 100000; i++){</p><p>db.measureHisvalues.insert({“_id”:i,”test1”:”testval1”+i});</p><p>}</p><p><img src="/1408af41c022dc62726ecf884c95ff0a.png" alt="enable partition"><br><img src="/image.png" alt="查看是否分区成功"></p><h3 id="配置安全"><a href="#配置安全" class="headerlink" title="配置安全"></a>配置安全</h3><h4 id="4-1-安全验证设置用户"><a href="#4-1-安全验证设置用户" class="headerlink" title="4.1 安全验证设置用户"></a>4.1 安全验证设置用户</h4><p>1、副本集和共享集群的各个节点成员之间使用内部身份验证，可以使用密钥文件或x.509证书。密钥文件比较简单，官方推荐如果是测试环境可以使用密钥文件，但是正是环境，官方推荐x.509证书。原理就是，集群中每一个实例彼此连接的时候都检验彼此使用的证书的内容是否相同。只有证书相同的实例彼此才可以访问。使用客户端连接到mongodb集群时，开启访问授权。对于集群外部的访问。如通过可视化客户端，或者通过代码连接的时候，需要开启授权。<br>a、生成密钥文件，在keyfile身份验证中，副本集中的每个mongod实例都使用keyfile的内容作为共享密码，只有具有正确密钥文件的mongod或者mongos实例可以连接到副本集。密钥文件的内容必须在6到1024个字符之间，并且在unix&#x2F;linux系统中文件所有者必须有对文件至少有读的权限。可以用任何方式生成密钥文件例如：(任意一台机器即可)</p><p>执行命令：openssl rand -base64 756 &gt; &#x2F;opt&#x2F;mongo&#x2F;MongoDB&#x2F;testKeyFile.file &#x2F;&#x2F;生成密钥</p><p>执行命令：chmod 400 &#x2F;opt&#x2F;mongo&#x2F;MongoDB&#x2F;testKeyFile.file &#x2F;&#x2F;赋予权限</p><p>执行命令：scp -P22 &#x2F;opt&#x2F;mongo&#x2F;MongoDB&#x2F;testKeyFile.file <a href="mailto:&#114;&#x6f;&#111;&#x74;&#64;&#49;&#48;&#x2e;&#x33;&#x30;&#x2e;&#x30;&#x2e;&#x34;&#x39;">&#114;&#x6f;&#111;&#x74;&#64;&#49;&#48;&#x2e;&#x33;&#x30;&#x2e;&#x30;&#x2e;&#x34;&#x39;</a>:&#x2F;opt&#x2F;mongo&#x2F;MongoDB &#x2F;&#x2F;拷贝至其他0.55服务器上（“-P22”是端口，根据实际情况来）</p><p>执行命令：scp -P22 &#x2F;opt&#x2F;mongo&#x2F;MongoDB&#x2F;testKeyFile.file root@:10.30.0.49 &#x2F;opt&#x2F;mongo&#x2F;MongoDB &#x2F;&#x2F;拷贝至其他0.56服务器上</p><p>创建用户成功后，关闭所有的节点（三台机都需要操作）</p><p>执行命令：按照先后顺序来处理关闭，mongos&gt;config&gt;shadr3&gt;shadr2&gt;shadr1</p><p>&#x2F;&#x2F;注意的是每一个服务的关闭都需要在三台机上关闭，在关闭其他服务。例如关闭shadr3服务，先关闭0.54服务器上的shadr3服务，其次0.55服务器上的shadr3服务，再是0.56服务器上的shadr3服务；然后在关闭shadr2服务，也是按照这个顺序处理。（这个地方主要新手操作避免出错）</p><p>执行命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mongod -f /opt/mongo/MongoDB/conf/shard1.conf --shutdown</span><br><span class="line">mongod -f /opt/mongo/MongoDB/conf/shard2.conf --shutdown</span><br><span class="line">mongod -f /opt/mongo/MongoDB/conf/shard3.conf --shutdown</span><br><span class="line">mongod -f /opt/mongo/MongoDB/conf/config.conf --shutdown</span><br><span class="line">mongo 10.30.0.48:20000//mongos需要这样关闭，用上面的命令有问题。</span><br><span class="line"></span><br><span class="line">use admin</span><br><span class="line">db.auth(<span class="string">&#x27;ml_grp&#x27;</span>,<span class="string">&#x27;passwd&#x27;</span>)</span><br><span class="line">db.shutdownServer()</span><br></pre></td></tr></table></figure><p>3、配置testKeyFile.file，依次在每台机器上的mongos.conf、config.conf、shard1.conf、shard2.conf、shard3.conf的配置和开启授权验证。<br>a、先是config.conf、shard1.conf、shard2.conf、shard3.conf的配置和开启授权验证。（三台机器的这些文件都需要添加）<br>在conf这几个文件的的最后添加：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">security:</span><br><span class="line">  keyFile: /opt/mongo/MongoDB/testKeyFile.file</span><br><span class="line">  authorization: enabled</span><br></pre></td></tr></table></figure><p>b、然后在三台机器的mongos.conf配置文件中最后添加：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">security:</span><br><span class="line">  keyFile: /opt/mongo/MongoDB/testKeyFile.file</span><br></pre></td></tr></table></figure><p>&#x2F;&#x2F;这里就说明了testKeyFile.file最好在每台机器放在一个位置，为了后面复制粘贴处理</p><p>&#x2F;&#x2F;解释说明： mongos比mongod少了authorization：enabled的配置。原因是，副本集加分片的安全认证需要配置两方面的，副本集各个节点之间使用内部身份验证，用于内部各个mongo实例的通信，只有相同keyfile才能相互访问。所以都要开启keyFile: &#x2F;data&#x2F;mongodb&#x2F;testKeyFile.file</p><pre><code>然而对于所有的mongod，才是真正的保存数据的分片。mongos只做路由，不保存数据。所以所有的mongod开启访问数据的授权authorization:enabled。这样用户只有账号密码正确才能访问到数据</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>fedora k8s 安装</title>
      <link href="/2023/08/16/fedora-k8s-%E5%AE%89%E8%A3%85/"/>
      <url>/2023/08/16/fedora-k8s-%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>spark group by 操作</title>
      <link href="/2023/08/16/spark-group-by-%E6%93%8D%E4%BD%9C/"/>
      <url>/2023/08/16/spark-group-by-%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>scala-spark-dataframe—groupby基本操作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[andrew@hadoop102 bin]$ ./spark-shell</span><br><span class="line">2022-05-07 20:35:13,392 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">Setting default <span class="built_in">log</span> level to <span class="string">&quot;WARN&quot;</span>.</span><br><span class="line">To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).</span><br><span class="line">Spark context Web UI available at http://hadoop102:4040</span><br><span class="line">Spark context available as <span class="string">&#x27;sc&#x27;</span> (master = <span class="built_in">local</span>[*], app <span class="built_in">id</span> = local-1651926921962).</span><br><span class="line">Spark session available as <span class="string">&#x27;spark&#x27;</span>.</span><br><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  <span class="string">&#x27;_/</span></span><br><span class="line"><span class="string">   /___/ .__/\_,_/_/ /_/\_\   version 3.0.0</span></span><br><span class="line"><span class="string">      /_/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Using Scala version 2.12.10 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_212)</span></span><br><span class="line"><span class="string">Type in expressions to have them evaluated.</span></span><br><span class="line"><span class="string">Type :help for more information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; val df = spark.createDataset(Seq(</span></span><br><span class="line"><span class="string">     |   (&quot;aaa&quot;,1,2),(&quot;bbb&quot;,3,4),(&quot;ccc&quot;,3,5),(&quot;bbb&quot;,4, 6))   ).toDF(&quot;key1&quot;,&quot;key2&quot;,&quot;key3&quot;)</span></span><br><span class="line"><span class="string">df: org.apache.spark.sql.DataFrame = [key1: string, key2: int ... 1 more field]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; df.show()</span></span><br><span class="line"><span class="string">+----+----+----+</span></span><br><span class="line"><span class="string">|key1|key2|key3|</span></span><br><span class="line"><span class="string">+----+----+----+</span></span><br><span class="line"><span class="string">| aaa|   1|   2|</span></span><br><span class="line"><span class="string">| bbb|   3|   4|</span></span><br><span class="line"><span class="string">| ccc|   3|   5|</span></span><br><span class="line"><span class="string">| bbb|   4|   6|</span></span><br><span class="line"><span class="string">+----+----+----+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; df.printSchema()</span></span><br><span class="line"><span class="string">root</span></span><br><span class="line"><span class="string"> |-- key1: string (nullable = true)</span></span><br><span class="line"><span class="string"> |-- key2: integer (nullable = false)</span></span><br><span class="line"><span class="string"> |-- key3: integer (nullable = false)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; df.groupBy(&quot;key1&quot;).count.show</span></span><br><span class="line"><span class="string">+----+-----+</span></span><br><span class="line"><span class="string">|key1|count|</span></span><br><span class="line"><span class="string">+----+-----+</span></span><br><span class="line"><span class="string">| ccc|    1|</span></span><br><span class="line"><span class="string">| aaa|    1|</span></span><br><span class="line"><span class="string">| bbb|    2|</span></span><br><span class="line"><span class="string">+----+-----+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; df.select(&quot;key1&quot;).distinct.show</span></span><br><span class="line"><span class="string">+----+</span></span><br><span class="line"><span class="string">|key1|</span></span><br><span class="line"><span class="string">+----+</span></span><br><span class="line"><span class="string">| ccc|</span></span><br><span class="line"><span class="string">| aaa|</span></span><br><span class="line"><span class="string">| bbb|</span></span><br><span class="line"><span class="string">+----+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; df.select(&quot;key1&quot;).distinct.count</span></span><br><span class="line"><span class="string">res4: Long = 3</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; f.groupBy(&quot;key1&quot;).count.sort(&quot;key1&quot;).show</span></span><br><span class="line"><span class="string">&lt;console&gt;:24: error: not found: value f</span></span><br><span class="line"><span class="string">       f.groupBy(&quot;key1&quot;).count.sort(&quot;key1&quot;).show</span></span><br><span class="line"><span class="string">       ^</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; df.groupBy(&quot;key1&quot;).count.sort(&quot;key1&quot;).show</span></span><br><span class="line"><span class="string">+----+-----+</span></span><br><span class="line"><span class="string">|key1|count|</span></span><br><span class="line"><span class="string">+----+-----+</span></span><br><span class="line"><span class="string">| aaa|    1|</span></span><br><span class="line"><span class="string">| bbb|    2|</span></span><br><span class="line"><span class="string">| ccc|    1|</span></span><br><span class="line"><span class="string">+----+-----+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; df.groupBy(&quot;key1&quot;).count.sort($&quot;count&quot;.desc).show</span></span><br><span class="line"><span class="string">+----+-----+</span></span><br><span class="line"><span class="string">|key1|count|</span></span><br><span class="line"><span class="string">+----+-----+</span></span><br><span class="line"><span class="string">| bbb|    2|</span></span><br><span class="line"><span class="string">| ccc|    1|</span></span><br><span class="line"><span class="string">| aaa|    1|</span></span><br><span class="line"><span class="string">+----+-----+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; df.groupBy(&quot;key1&quot;).count.withColumnRenamed(&quot;count&quot;, &quot;cnt&quot;).sort($&quot;cnt&quot;.desc).show</span></span><br><span class="line"><span class="string">+----+---+</span></span><br><span class="line"><span class="string">|key1|cnt|</span></span><br><span class="line"><span class="string">+----+---+</span></span><br><span class="line"><span class="string">| bbb|  2|</span></span><br><span class="line"><span class="string">| aaa|  1|</span></span><br><span class="line"><span class="string">| ccc|  1|</span></span><br><span class="line"><span class="string">+----+---+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; df.groupBy(&quot;key1&quot;).agg(count(&quot;key1&quot;).as(&quot;cnt&quot;)).show</span></span><br><span class="line"><span class="string">+----+---+</span></span><br><span class="line"><span class="string">|key1|cnt|</span></span><br><span class="line"><span class="string">+----+---+</span></span><br><span class="line"><span class="string">| ccc|  1|</span></span><br><span class="line"><span class="string">| aaa|  1|</span></span><br><span class="line"><span class="string">| bbb|  2|</span></span><br><span class="line"><span class="string">+----+---+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt;  df.groupBy(&quot;key1&quot;).agg(count(&quot;key1&quot;), max(&quot;key2&quot;), avg(&quot;key3&quot;)).show</span></span><br><span class="line"><span class="string">+----+-----------+---------+---------+</span></span><br><span class="line"><span class="string">|key1|count(key1)|max(key2)|avg(key3)|</span></span><br><span class="line"><span class="string">+----+-----------+---------+---------+</span></span><br><span class="line"><span class="string">| ccc|          1|        3|      5.0|</span></span><br><span class="line"><span class="string">| aaa|          1|        1|      2.0|</span></span><br><span class="line"><span class="string">| bbb|          2|        4|      5.0|</span></span><br><span class="line"><span class="string">+----+-----------+---------+---------+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; f.groupBy(&quot;key1&quot;)</span></span><br><span class="line"><span class="string">&lt;console&gt;:24: error: not found: value f</span></span><br><span class="line"><span class="string">       f.groupBy(&quot;key1&quot;)</span></span><br><span class="line"><span class="string">       ^</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt;        df.groupBy(&quot;key1&quot;).agg(&quot;key1&quot;-&gt;&quot;count&quot;, &quot;key2&quot;-&gt;&quot;max&quot;, &quot;key3&quot;-&gt;&quot;avg&quot;).show</span></span><br><span class="line"><span class="string">+----+-----------+---------+---------+</span></span><br><span class="line"><span class="string">|key1|count(key1)|max(key2)|avg(key3)|</span></span><br><span class="line"><span class="string">+----+-----------+---------+---------+</span></span><br><span class="line"><span class="string">| ccc|          1|        3|      5.0|</span></span><br><span class="line"><span class="string">| aaa|          1|        1|      2.0|</span></span><br><span class="line"><span class="string">| bbb|          2|        4|      5.0|</span></span><br><span class="line"><span class="string">+----+-----------+---------+---------+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; df.groupBy(&quot;key1&quot;).agg(Map((&quot;key1&quot;,&quot;count&quot;), (&quot;key2&quot;,&quot;max&quot;), (&quot;key3&quot;,&quot;avg&quot;))).show</span></span><br><span class="line"><span class="string">+----+-----------+---------+---------+</span></span><br><span class="line"><span class="string">|key1|count(key1)|max(key2)|avg(key3)|</span></span><br><span class="line"><span class="string">+----+-----------+---------+---------+</span></span><br><span class="line"><span class="string">| ccc|          1|        3|      5.0|</span></span><br><span class="line"><span class="string">| aaa|          1|        1|      2.0|</span></span><br><span class="line"><span class="string">| bbb|          2|        4|      5.0|</span></span><br><span class="line"><span class="string">+----+-----------+---------+---------+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; df.groupBy(&quot;key1&quot;).agg(count(&quot;key1&quot;).as(&quot;cnt&quot;), max(&quot;key2&quot;).as(&quot;max_key2&quot;), avg(&quot;key3&quot;).as(&quot;avg_key3&quot;)).sort($&quot;cnt&quot;,$&quot;max_key2&quot;.desc).show</span></span><br><span class="line"><span class="string">+----+---+--------+--------+</span></span><br><span class="line"><span class="string">|key1|cnt|max_key2|avg_key3|</span></span><br><span class="line"><span class="string">+----+---+--------+--------+</span></span><br><span class="line"><span class="string">| ccc|  1|       3|     5.0|</span></span><br><span class="line"><span class="string">| aaa|  1|       1|     2.0|</span></span><br><span class="line"><span class="string">| bbb|  2|       4|     5.0|</span></span><br><span class="line"><span class="string">+----+---+--------+--------+</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">package groupby</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">import org.apache.spark.SparkConf</span></span><br><span class="line"><span class="string">import org.apache.spark.sql.SparkSession</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">object demos &#123;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  def main(args: Array[String]): Unit = &#123;</span></span><br><span class="line"><span class="string">    val conf = new SparkConf().setAppName(&quot;LzSparkDatasetExamples&quot;).setMaster(&quot;local[*]&quot;)</span></span><br><span class="line"><span class="string">    val sparkSession = SparkSession.builder().enableHiveSupport().config(conf).getOrCreate()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">//    //LOGGER.info(&quot;-------- this is info --------&quot;)</span></span><br><span class="line"><span class="string">    import sparkSession.implicits._</span></span><br><span class="line"><span class="string">    val df = sparkSession.createDataset(Seq(</span></span><br><span class="line"><span class="string">      (&quot;aaa&quot;, 1, 2),</span></span><br><span class="line"><span class="string">      (&quot;bbb&quot;, 3, 4),</span></span><br><span class="line"><span class="string">      (&quot;ccc&quot;, 3, 5),</span></span><br><span class="line"><span class="string">      (&quot;bbb&quot;, 4, 6)</span></span><br><span class="line"><span class="string">    )).toDF(&quot;key1&quot;, &quot;key2&quot;, &quot;key3&quot;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    import org.apache.spark.sql.functions._</span></span><br><span class="line"><span class="string">    //LOGGER.info(&quot;--------df.groupBy(\&quot;key1\&quot;).count().show()-----------&quot;)</span></span><br><span class="line"><span class="string">    df.groupBy(&quot;key1&quot;).count().show()</span></span><br><span class="line"><span class="string">    //LOGGER.info(&quot;--------df.select(\&quot;key1\&quot;).distinct().show()-----------&quot;)</span></span><br><span class="line"><span class="string">    df.select(&quot;key1&quot;).distinct().show()</span></span><br><span class="line"><span class="string">    val key1Count = df.select(&quot;key1&quot;).distinct().count()</span></span><br><span class="line"><span class="string">    //LOGGER.info(&quot;--------df.select(\&quot;key1\&quot;).distinct().count()-----------&quot; +key1Count)</span></span><br><span class="line"><span class="string">    //LOGGER.info(&quot;--------df.groupBy(\&quot;key1\&quot;).count().sort(\&quot;key1\&quot;).show()-----------&quot;)</span></span><br><span class="line"><span class="string">    df.groupBy(&quot;key1&quot;).count().sort(&quot;key1&quot;).show()</span></span><br><span class="line"><span class="string">    //LOGGER.info(&quot;--------df.groupBy(\&quot;key1\&quot;).count().sort($\&quot;key1\&quot;.desc).show()-----------&quot;)</span></span><br><span class="line"><span class="string">    df.groupBy(&quot;key1&quot;).count().sort($&quot;key1&quot;.desc).show()</span></span><br><span class="line"><span class="string">    //LOGGER.info(&quot;--------df.groupBy(\&quot;key1\&quot;).count.withColumnRenamed(\&quot;count\&quot;, \&quot;cnt\&quot;).sort($\&quot;cnt\&quot;.desc).show-----------&quot;)</span></span><br><span class="line"><span class="string">    df.groupBy(&quot;key1&quot;).count</span></span><br><span class="line"><span class="string">      .withColumnRenamed(&quot;count&quot;, &quot;cnt&quot;).sort($&quot;cnt&quot;.desc).show()</span></span><br><span class="line"><span class="string">    //LOGGER.info(&quot;--------df.groupBy(\&quot;key1\&quot;).agg(count(\&quot;key1\&quot;).as(\&quot;cnt\&quot;)).show-----------&quot;)</span></span><br><span class="line"><span class="string">    df.groupBy(&quot;key1&quot;).agg(count(&quot;key1&quot;).as(&quot;cnt&quot;)).show()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    // 使用agg聚合函数</span></span><br><span class="line"><span class="string">    df.groupBy(&quot;key1&quot;).agg(count(&quot;key1&quot;), max(&quot;key2&quot;), avg(&quot;key3&quot;)).show</span></span><br><span class="line"><span class="string">    df.groupBy(&quot;key1&quot;).agg(&quot;key1&quot;-&gt;&quot;count&quot;, &quot;key2&quot;-&gt;&quot;max&quot;, &quot;key3&quot;-&gt;&quot;avg&quot;).show()</span></span><br><span class="line"><span class="string">    df.groupBy(&quot;key1&quot;).agg(Map((&quot;key1&quot;,&quot;count&quot;), (&quot;key2&quot;,&quot;max&quot;), (&quot;key3&quot;,&quot;avg&quot;))).show()</span></span><br><span class="line"><span class="string">    df.groupBy(&quot;key1&quot;).agg((&quot;key1&quot;,&quot;count&quot;), (&quot;key2&quot;,&quot;max&quot;), (&quot;key3&quot;,&quot;avg&quot;)).show</span></span><br><span class="line"><span class="string">    df.groupBy(&quot;key1&quot;)</span></span><br><span class="line"><span class="string">      .agg(count(&quot;key1&quot;).as(&quot;cnt&quot;), max(&quot;key2&quot;).as(&quot;max_key2&quot;), avg(&quot;key3&quot;).as(&quot;avg_key3&quot;))</span></span><br><span class="line"><span class="string">      .sort($&quot;cnt&quot;,$&quot;max_key2&quot;.desc).show</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>spark null 值处理</title>
      <link href="/2023/08/16/spark-null-%E5%80%BC%E5%A4%84%E7%90%86/"/>
      <url>/2023/08/16/spark-null-%E5%80%BC%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ceph分布式安装</title>
      <link href="/2023/08/11/ceph%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/"/>
      <url>/2023/08/11/ceph%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p>1.环境配置<br>#在所有节点配置YUM：<br>#清空原来自带配置文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/yum.repos.d/</span><br><span class="line"><span class="built_in">mkdir</span> /tmp/bak</span><br><span class="line"><span class="built_in">mv</span> * /tmp/bak/</span><br></pre></td></tr></table></figure><p>#配置系统源码，epel源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line">yum install wget -y</span><br><span class="line">wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo</span><br><span class="line"><span class="comment">#YUM优先级别：</span></span><br><span class="line">yum -y install yum-plugin-priorities.noarch</span><br></pre></td></tr></table></figure><p>#配置ceph源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | tee /etc/yum.repos.d/ceph.repo</span></span><br><span class="line"><span class="string">[Ceph]</span></span><br><span class="line"><span class="string">name=Ceph packages for $basearch</span></span><br><span class="line"><span class="string">baseurl=http://mirrors.163.com/ceph/rpm-nautilus/el7/\$basearch</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=1</span></span><br><span class="line"><span class="string">type=rpm-md</span></span><br><span class="line"><span class="string">gpgkey=https://download.ceph.com/keys/release.asc</span></span><br><span class="line"><span class="string">priority=1</span></span><br><span class="line"><span class="string">[Ceph-noarch]</span></span><br><span class="line"><span class="string">name=Ceph noarch packages</span></span><br><span class="line"><span class="string">baseurl=http://mirrors.163.com/ceph/rpm-nautilus/el7/noarch</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=1</span></span><br><span class="line"><span class="string">type=rpm-md</span></span><br><span class="line"><span class="string">gpgkey=https://download.ceph.com/keys/release.asc</span></span><br><span class="line"><span class="string">priority=1</span></span><br><span class="line"><span class="string">[ceph-source]</span></span><br><span class="line"><span class="string">name=Ceph source packages</span></span><br><span class="line"><span class="string">baseurl=http://mirrors.163.com/ceph/rpm-nautilus/el7/SRPMS</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=1</span></span><br><span class="line"><span class="string">type=rpm-md</span></span><br><span class="line"><span class="string">gpgkey=https://download.ceph.com/keys/release.asc</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>#关闭防火墙：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line">systemctl status firewalld</span><br></pre></td></tr></table></figure><p>#配置主机名称：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ceph1节点：</span><br><span class="line">hostnamectl --static set-hostname ceph1</span><br><span class="line">ceph2节点：</span><br><span class="line">hostnamectl --static set-hostname ceph2</span><br><span class="line">ceph3节点：</span><br><span class="line">hostnamectl --static set-hostname ceph3</span><br></pre></td></tr></table></figure><p>#所有节点配置hosts文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.0.231    ceph1</span><br><span class="line">192.168.0.232    ceph2</span><br><span class="line">192.168.0.233    ceph3</span><br></pre></td></tr></table></figure><p>#所有节点NTP配置：<br>在所有集群和客户端节点安装NTP，修改配置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ntp ntpdate</span><br><span class="line"><span class="comment"># 以ceph1为NTP服务端节点，在ceph1新建NTP文件。</span></span><br><span class="line">vi /etc/ntp.conf</span><br><span class="line"><span class="comment"># 并新增如下内容作为NTP服务端：</span></span><br><span class="line">restrict 127.0.0.1</span><br><span class="line">restrict ::1</span><br><span class="line">restrict 192.168.3.0 mask 255.255.255.0 //ceph1的网段与掩码</span><br><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 8</span><br></pre></td></tr></table></figure><p>在ceph2、ceph3及所有客户机节点新建NTP文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/ntp.conf</span><br><span class="line"><span class="comment"># 并新增如下内容作为客户端：</span></span><br><span class="line">server 192.168.3.166</span><br><span class="line"></span><br><span class="line">systemctl start ntpd</span><br><span class="line">systemctl <span class="built_in">enable</span> ntpd</span><br><span class="line">systemctl status ntpd</span><br></pre></td></tr></table></figure><p>#ssh配置，在ceph1节点生成公钥，并发放到各个主机&#x2F;客户机节点。：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa <span class="comment">#回车采取默认配置</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> &#123;1..3&#125;; <span class="keyword">do</span> ssh-copy-id ceph<span class="variable">$i</span>; <span class="keyword">done</span> <span class="comment">#根据提示输入yes及节点密码</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> &#123;1..3&#125;; <span class="keyword">do</span> ssh-copy-id client<span class="variable">$i</span>; <span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>#在所有节点，关闭SELinux</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed -i <span class="string">&#x27;s/enforcing/disabled/&#x27;</span> /etc/selinux/config</span><br><span class="line">setenforce 0</span><br></pre></td></tr></table></figure><ol><li>安装Ceph软件<br>使用yum install安装ceph的时候会默认安装当前已有的最新版，如果不想安装最新版本，可以在&#x2F;etc&#x2F;yum.conf文件中加以限制。<br>2.1 在所有集群和客户端节点安装Ceph<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ceph</span><br><span class="line">ceph -v命令查看版本:</span><br><span class="line">[root@ceph1 ~]<span class="comment"># ceph -v</span></span><br><span class="line">ceph version 14.2.9 (581f22da52345dba46ee232b73b990f06029a2a0) nautilus (stable)</span><br><span class="line">[root@ceph2 ~]<span class="comment"># ceph -v</span></span><br><span class="line">ceph version 14.2.9 (581f22da52345dba46ee232b73b990f06029a2a0) nautilus (stable)</span><br><span class="line">[root@ceph3 ~]<span class="comment"># ceph -v</span></span><br><span class="line">ceph version 14.2.9 (581f22da52345dba46ee232b73b990f06029a2a0) nautilus (stable)</span><br></pre></td></tr></table></figure>2.2 在ceph1节点额外安装ceph-deploy。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ceph-deploy</span><br></pre></td></tr></table></figure>3.部署MON节点<br>3.1 创建目录生成配置文件<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">mkdir</span> <span class="keyword">cluster</span></span><br><span class="line"><span class="keyword">cd</span> <span class="keyword">cluster</span></span><br><span class="line">ceph-deploy new ceph1 ceph2 ceph3</span><br></pre></td></tr></table></figure></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph1 ~]<span class="comment"># cd cluster/</span></span><br><span class="line">[root@ceph1 cluster]<span class="comment"># ceph-deploy new ceph1 ceph2 ceph3</span></span><br><span class="line">[ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf</span><br><span class="line">[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy new ceph1 ceph2 ceph3</span><br><span class="line">[ceph_deploy.cli][INFO  ] ceph-deploy options:</span><br><span class="line">[ceph_deploy.cli][INFO  ]  username                      : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  func                          : &lt;<span class="keyword">function</span> new at 0x7ffb7dc07de8&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  verbose                       : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  overwrite_conf                : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  quiet                         : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7ffb7d58c6c8&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cluster                       : ceph</span><br><span class="line">[ceph_deploy.cli][INFO  ]  ssh_copykey                   : True</span><br><span class="line">[ceph_deploy.cli][INFO  ]  mon                           : [<span class="string">&#x27;ceph1&#x27;</span>, <span class="string">&#x27;ceph2&#x27;</span>, <span class="string">&#x27;ceph3&#x27;</span>]</span><br><span class="line">[ceph_deploy.cli][INFO  ]  public_network                : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  ceph_conf                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cluster_network               : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  default_release               : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  fsid                          : None</span><br><span class="line">[ceph_deploy.new][DEBUG ] Creating new cluster named ceph</span><br><span class="line">[ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds</span><br><span class="line">[ceph1][DEBUG ] connected to host: ceph1 </span><br><span class="line">[ceph1][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph1][DEBUG ] detect machine <span class="built_in">type</span></span><br><span class="line">[ceph1][DEBUG ] find the location of an executable</span><br><span class="line">[ceph1][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ip <span class="built_in">link</span> show</span><br><span class="line">[ceph1][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ip addr show</span><br><span class="line">[ceph1][DEBUG ] IP addresses found: [u<span class="string">&#x27;192.168.0.231&#x27;</span>]</span><br><span class="line">[ceph_deploy.new][DEBUG ] Resolving host ceph1</span><br><span class="line">[ceph_deploy.new][DEBUG ] Monitor ceph1 at 192.168.0.231</span><br><span class="line">[ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds</span><br><span class="line">[ceph2][DEBUG ] connected to host: ceph1 </span><br><span class="line">[ceph2][INFO  ] Running <span class="built_in">command</span>: ssh -CT -o BatchMode=<span class="built_in">yes</span> ceph2</span><br><span class="line">[ceph2][DEBUG ] connected to host: ceph2 </span><br><span class="line">[ceph2][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph2][DEBUG ] detect machine <span class="built_in">type</span></span><br><span class="line">[ceph2][DEBUG ] find the location of an executable</span><br><span class="line">[ceph2][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ip <span class="built_in">link</span> show</span><br><span class="line">[ceph2][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ip addr show</span><br><span class="line">[ceph2][DEBUG ] IP addresses found: [u<span class="string">&#x27;192.168.0.232&#x27;</span>]</span><br><span class="line">[ceph_deploy.new][DEBUG ] Resolving host ceph2</span><br><span class="line">[ceph_deploy.new][DEBUG ] Monitor ceph2 at 192.168.0.232</span><br><span class="line">[ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds</span><br><span class="line">[ceph3][DEBUG ] connected to host: ceph1 </span><br><span class="line">[ceph3][INFO  ] Running <span class="built_in">command</span>: ssh -CT -o BatchMode=<span class="built_in">yes</span> ceph3</span><br><span class="line">[ceph3][DEBUG ] connected to host: ceph3 </span><br><span class="line">[ceph3][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph3][DEBUG ] detect machine <span class="built_in">type</span></span><br><span class="line">[ceph3][DEBUG ] find the location of an executable</span><br><span class="line">[ceph3][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ip <span class="built_in">link</span> show</span><br><span class="line">[ceph3][INFO  ] Running <span class="built_in">command</span>: /usr/sbin/ip addr show</span><br><span class="line">[ceph3][DEBUG ] IP addresses found: [u<span class="string">&#x27;192.168.0.233&#x27;</span>]</span><br><span class="line">[ceph_deploy.new][DEBUG ] Resolving host ceph3</span><br><span class="line">[ceph_deploy.new][DEBUG ] Monitor ceph3 at 192.168.0.233</span><br><span class="line">[ceph_deploy.new][DEBUG ] Monitor initial members are [<span class="string">&#x27;ceph1&#x27;</span>, <span class="string">&#x27;ceph2&#x27;</span>, <span class="string">&#x27;ceph3&#x27;</span>]</span><br><span class="line">[ceph_deploy.new][DEBUG ] Monitor addrs are [<span class="string">&#x27;192.168.0.231&#x27;</span>, <span class="string">&#x27;192.168.0.232&#x27;</span>, <span class="string">&#x27;192.168.0.233&#x27;</span>]</span><br><span class="line">[ceph_deploy.new][DEBUG ] Creating a random mon key...</span><br><span class="line">[ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...</span><br><span class="line">[ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...</span><br></pre></td></tr></table></figure><p>3.2 初始化密钥</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy mon create-initial</span><br></pre></td></tr></table></figure><p>3.3 将ceph.client.admin.keyring拷贝到各个节点上</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy --overwrite-conf admin ceph1 ceph2 ceph3</span><br></pre></td></tr></table></figure><p>3.4 查看是否配置成功。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph1 cluster]<span class="comment"># ceph -scluster:id:     ea192428-05d2-437a-8cce-9d187de82dd5health: HEALTH_OKservices:mon: 3 daemons, quorum ceph1,ceph2,ceph3 (age 5m)mgr: no daemons activeosd: 0 osds: 0 up, 0 indata:pools:   0 pools, 0 pgsobjects: 0 objects, 0 Busage:   0 B used, 0 B / 0 B availpgs:  </span></span><br></pre></td></tr></table></figure><p>4 部署MGR节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy mgr create ceph1 ceph2 ceph3</span><br></pre></td></tr></table></figure><p>查看MGR是否部署成功。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ceph -s</span><br><span class="line">[root@ceph1 cluster]<span class="comment"># ceph -scluster:id:     ea192428-05d2-437a-8cce-9d187de82dd5health: HEALTH_WARNOSD count 0 &lt; osd_pool_default_size 3services:mon: 3 daemons, quorum ceph1,ceph2,ceph3 (age 8m)mgr: ceph1(active, since 22s), standbys: ceph2, ceph3osd: 0 osds: 0 up, 0 indata:pools:   0 pools, 0 pgsobjects: 0 objects, 0 Busage:   0 B used, 0 B / 0 B availpgs: </span></span><br><span class="line">```  </span><br><span class="line">5 部署OSD节点</span><br><span class="line">```bash</span><br><span class="line">ceph-deploy osd create --data /dev/sdb ceph1</span><br><span class="line">ceph-deploy osd create --data /dev/sdc ceph1</span><br><span class="line">ceph-deploy osd create --data /dev/sdd ceph1</span><br><span class="line">ceph-deploy osd create --data /dev/sdb ceph2</span><br><span class="line">ceph-deploy osd create --data /dev/sdc ceph2</span><br><span class="line">ceph-deploy osd create --data /dev/sdd ceph2</span><br><span class="line">ceph-deploy osd create --data /dev/sdb ceph3</span><br><span class="line">ceph-deploy osd create --data /dev/sdc ceph3</span><br><span class="line">ceph-deploy osd create --data /dev/sdd ceph3</span><br></pre></td></tr></table></figure><p>创建成功后，查看是否正常</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph1 cluster]<span class="comment"># ceph -scluster:id:     ea192428-05d2-437a-8cce-9d187de82dd5health: HEALTH_OKservices:mon: 3 daemons, quorum ceph1,ceph2,ceph3 (age 14m)mgr: ceph1(active, since 6m), standbys: ceph2, ceph3osd: 9 osds: 9 up (since 2m), 9 in (since 2m)data:pools:   0 pools, 0 pgsobjects: 0 objects, 0 Busage:   9.0 GiB used, 135 GiB / 144 GiB availpgs:  </span></span><br></pre></td></tr></table></figure><p>6 验证Ceph<br>创建存储池</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool create vdbench 10 10</span><br></pre></td></tr></table></figure><p>创建块设备</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rbd create image01 --size 200--pool vdbench --image-format 2 --image-feature layering</span><br><span class="line">rbd <span class="built_in">ls</span> --pool vdbench</span><br><span class="line">[root@ceph1 cluster]<span class="comment"># rbd create image01 --size 200 --pool  vdbench --image-format 2 --image-feature layering</span></span><br><span class="line">[root@ceph1 cluster]<span class="comment"># rbd ls --pool vdbench</span></span><br><span class="line">image01</span><br></pre></td></tr></table></figure><p>#PG 分 配 计 算<br>归置组(PG)的数量是由管理员在创建存储池的时候指定的，然后由 CRUSH 负责创建和使用，PG 的数量是 2 的 N 次方的倍数,每个 OSD 的 PG 不要超出 250 个 PG<br>Total PGs &#x3D; (Total_number_of_OSD * 100) &#x2F; max_replication_count<br>单个 pool 的 PG 计算如下：<br>有 100 个 osd，3 副本，5 个 pool<br>Total PGs &#x3D;100*100&#x2F;3&#x3D;3333<br>每个 pool 的 PG&#x3D;3333&#x2F;5&#x3D;512，那么创建 pool 的时候就指定 pg 为 512<br>客户端在读写对象时，需要提供的是对象标识和存储池名称<br>客户端需要在存储池中读写对象时，需要客户端将对象名称，对象名称的hash码，存储池中的PG数量和存储池名称作为输入信息提供给ceph，然后由CRUSH计算出PG的ID以及PG针对的主OSD即可读写OSD中的对象。<br>具体写操作如下：<br>1.APP向ceph客户端发送对某个对象的请求，此请求包含对象和存储池，然后ceph客户端对访问的对象做hash计算，并根据此hash值计算出对象所在的PG，完成对象从Pool至PG的映射。<br>APP 访问 pool ID 和 object ID （比如 pool &#x3D; pool1 and object-id &#x3D; “name1”）<br>ceph client 对 objectID 做哈希<br>ceph client 对该 hash 值取 PG 总数的模，得到 PG 编号(比如 32)<br>ceph client 对 pool ID 取 hash（比如 “pool1” &#x3D; 3）<br>ceph client 将 pool ID 和 PG ID 组合在一起(比如 3.23)得到 PG 的完整 ID。<br>2.然后客户端据 PG、CRUSH 运行图和归置组(placement rules)作为输入参数并再次进行计<br>算，并计算出对象所在的 PG 内的主 OSD ，从而完成对象从 PG 到 OSD 的映射。<br>3.客户端开始对主 OSD 进行读写请求(副本池 IO)，如果发生了写操作，会有 ceph 服务端完<br>成对象从主 OSD 到备份 OSD 的同步  </p><p>二.熟练 ceph 的用户管理及授权<br>客户端使用 session key 向 mon 请求所需要的服务，mon 向客户端提供一个 tiket，用于向实际处理数据的 OSD 等服务验证客户端身份，MON 和 OSD 共享同一个 secret.<br>ceph 用户需要拥有存储池访问权限，才能读取和写入数据<br>ceph 用户必须拥有执行权限才能使用 ceph 的管理命令<br>ceph 支持多种类型的用户，但可管理的用户都属于 client 类型<br>通过点号来分割用户类型和用户名，格式为 TYPE.ID，例如 client.admin。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@ceph-deploy:~<span class="comment"># cat /etc/ceph/ceph.client.admin.keyring </span></span><br><span class="line">[client.admin]</span><br><span class="line">        key = AQBnFaNj1iyBMBAAd+9hKWXaNw3GYxT9PEXvrQ==</span><br><span class="line">        caps mds = <span class="string">&quot;allow *&quot;</span></span><br><span class="line">        caps mgr = <span class="string">&quot;allow *&quot;</span></span><br><span class="line">        caps mon = <span class="string">&quot;allow *&quot;</span></span><br><span class="line">        caps osd = <span class="string">&quot;allow *&quot;</span></span><br></pre></td></tr></table></figure><p>#列 出 指 定 用 户 信 息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@ceph-deploy:~<span class="comment"># ceph auth get osd.10</span></span><br><span class="line">[osd.10]</span><br><span class="line">        key = AQB+I6Njk4KWNBAAL09FFayLKF44IgUQ1fjKYQ==</span><br><span class="line">        caps mgr = <span class="string">&quot;allow profile osd&quot;</span></span><br><span class="line">        caps mon = <span class="string">&quot;allow profile osd&quot;</span></span><br><span class="line">        caps osd = <span class="string">&quot;allow *&quot;</span></span><br><span class="line"></span><br><span class="line">exported keyring <span class="keyword">for</span> osd.10</span><br></pre></td></tr></table></figure><p>#: 列 出 用 户</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cephadmin@ceph-deploy:~$ ceph auth list</span><br><span class="line">mds.ceph-mgr1</span><br><span class="line">        key: AQAdRbFjOwBXIRAAUTdwElBzYPHW+4uFicFC7Q==</span><br><span class="line">        caps: [mds] allow</span><br><span class="line">        caps: [mon] allow profile mds</span><br><span class="line">        caps: [osd] allow rwx</span><br><span class="line">osd.0</span><br><span class="line">        key: AQC0IqNjbcgKIxAA+BCNpQeZiMujR+r+69Miig==</span><br><span class="line">        caps: [mgr] allow profile osd</span><br><span class="line">        caps: [mon] allow profile osd</span><br><span class="line">        caps: [osd] allow *</span><br></pre></td></tr></table></figure><p>#可以结合使用-o 文件名选项和 ceph auth list 将输出保存到某个文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph auth list -o 123.key</span><br></pre></td></tr></table></figure><p>#ceph auth add<br>此命令是添加用户的规范方法。它会创建用户、生成密钥，并添加所有指定的能力<br>添加认证 key：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph auth add client.tom mon <span class="string">&#x27;allow r&#x27;</span> osd <span class="string">&#x27;allow rwx pool=testpool2&#x27;</span></span><br><span class="line">added key <span class="keyword">for</span> client.tom</span><br></pre></td></tr></table></figure><p>##验证 key</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph auth get client.tom</span><br><span class="line">[client.tom]</span><br><span class="line">        key = AQD2vbJj8fIiDBAArtJBzQiuPy8nDWPSFVs0bw==</span><br><span class="line">        caps mon = <span class="string">&quot;allow r&quot;</span></span><br><span class="line">        caps osd = <span class="string">&quot;allow rwx pool=testpool2&quot;</span></span><br><span class="line">exported keyring <span class="keyword">for</span> client.tom</span><br></pre></td></tr></table></figure><p>##创建用户</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph auth get-or-create client.jack mon <span class="string">&#x27;allow r&#x27;</span> osd <span class="string">&#x27;allow rwx pool=testpool2&#x27;</span></span><br><span class="line">[client.jack]</span><br><span class="line">        key = AQC/vrJj5kenHhAAGeRJpY64feS4Dn6DD/R8VA==</span><br></pre></td></tr></table></figure><p>##再次创建用户</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph auth get-or-create client.jack mon <span class="string">&#x27;allow r&#x27;</span> osd <span class="string">&#x27;allow rwx pool=testpool2&#x27;</span></span><br><span class="line">[client.jack]</span><br><span class="line">        key = AQC/vrJj5kenHhAAGeRJpY64feS4Dn6DD/R8VA==</span><br></pre></td></tr></table></figure><p>#ceph auth get-or-create-key:<br>此命令是创建用户并返回用户密钥，对于只需要密钥的客户端(例如 libvrirt),此命令非常有用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph auth get-or-create-key client.jack</span><br><span class="line">mon <span class="string">&#x27;allow r&#x27;</span> osd <span class="string">&#x27;allow rwx pool=mypool&#x27;</span></span><br><span class="line">AQAtr8dfi37XMhAADbHWEZ0shY1QZ5A8eBpeoQ==</span><br></pre></td></tr></table></figure><p>用户有 key 就显示没有就创建<br>#修 改 用 户 能 力</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph auth get client.jack</span><br><span class="line">[client.jack]</span><br><span class="line">        key = AQC/vrJj5kenHhAAGeRJpY64feS4Dn6DD/R8VA==</span><br><span class="line">        caps mon = <span class="string">&quot;allow r&quot;</span></span><br><span class="line">        caps osd = <span class="string">&quot;allow rwx pool=testpool2&quot;</span></span><br><span class="line">exported keyring <span class="keyword">for</span> client.jack</span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph auth caps client.jack mon <span class="string">&#x27;allow r&#x27;</span> osd <span class="string">&#x27;allow rw pool=testpool2&#x27;</span></span><br><span class="line">updated caps <span class="keyword">for</span> client.jack</span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph auth get client.jack</span><br><span class="line">[client.jack]</span><br><span class="line">        key = AQC/vrJj5kenHhAAGeRJpY64feS4Dn6DD/R8VA==</span><br><span class="line">        caps mon = <span class="string">&quot;allow r&quot;</span></span><br><span class="line">        caps osd = <span class="string">&quot;allow rw pool=testpool2&quot;</span></span><br><span class="line">exported keyring <span class="keyword">for</span> client.jack</span><br></pre></td></tr></table></figure><p>#删 除 用 户 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph auth del client.tom</span><br><span class="line">updated</span><br></pre></td></tr></table></figure><p>#导出 keyring 至指定文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph auth get client.user1 -o</span><br><span class="line">ceph.client.user1.keyring</span><br><span class="line">exported keyring <span class="keyword">for</span> client.user1</span><br></pre></td></tr></table></figure><p>#验证指定用户的 keyring 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ <span class="built_in">cat</span> ceph.client.user1.keyring</span><br><span class="line">[client.user1]</span><br><span class="line">key = AQAUUchfjpMqGRAARV6h0ofdDEneuaRnxuHjoQ==</span><br><span class="line">caps mon = <span class="string">&quot;allow r&quot;</span></span><br><span class="line">caps osd = <span class="string">&quot;allow * pool=mypool&quot;</span></span><br><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph auth del client.user1 <span class="comment">#演示误删除用户</span></span><br><span class="line">Updated</span><br><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph auth get client.user1 <span class="comment">#确认用户被删除</span></span><br><span class="line">Error ENOENT: failed to find client.user1 <span class="keyword">in</span> keyring</span><br><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph auth import -i</span><br><span class="line">ceph.client.user1.keyring <span class="comment">#导入用户</span></span><br><span class="line">imported keyring</span><br><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph auth get client.user1 <span class="comment">#验证已恢复用户</span></span><br><span class="line">exported keyring <span class="keyword">for</span> client.user1</span><br></pre></td></tr></table></figure><p>#将多 用 户 导 出 至 秘 钥 环 ：<br>#创建 keyring 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ceph-authtool --create-keyring ceph.client.user.keyring <span class="comment">#创建空的 keyring 文件</span></span><br><span class="line">creating ceph.client.user.keyring</span><br></pre></td></tr></table></figure><p>#把指定的 admin 用户的 keyring 文件内容导入到 user 用户的 keyring 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ceph</span>-authtool ./ceph.client.user.keyring</span><br><span class="line">--import-keyring ./ceph.client.admin.keyring</span><br><span class="line">importing contents of ./ceph.client.admin.keyring into ./ceph.client.user.keyring</span><br></pre></td></tr></table></figure><p>#验证 keyring 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph-authtool -l ./ceph.client.user.keyring</span><br><span class="line">[client.admin]</span><br><span class="line">key = AQAGDKJfQk/dAxAA3Y+9xoE/p8in6QjoHeXmeg==</span><br><span class="line">caps mds = <span class="string">&quot;allow *&quot;</span></span><br><span class="line">caps mgr = <span class="string">&quot;allow *&quot;</span></span><br><span class="line">caps mon = <span class="string">&quot;allow *&quot;</span></span><br><span class="line">caps osd = <span class="string">&quot;allow *&quot;</span></span><br></pre></td></tr></table></figure><p>#再导入一个其他用户的 keyring：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph-authtool ./ceph.client.user.keyring</span><br><span class="line">--import-keyring ./ceph.client.user1.keyring</span><br><span class="line">importing contents of ./ceph.client.user1.keyring into ./ceph.client.user.keyring</span><br></pre></td></tr></table></figure><p>#再次验证 keyring 文件是否包含多个用户的认证信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph-authtool -l ./ceph.client.user.keyring</span><br><span class="line">[client.admin]</span><br><span class="line">key = AQAGDKJfQk/dAxAA3Y+9xoE/p8in6QjoHeXmeg==</span><br><span class="line">caps mds = <span class="string">&quot;allow *&quot;</span></span><br><span class="line">caps mgr = <span class="string">&quot;allow *&quot;</span></span><br><span class="line">caps mon = <span class="string">&quot;allow *&quot;</span></span><br><span class="line">caps osd = <span class="string">&quot;allow *&quot;</span></span><br><span class="line">[client.user1]</span><br><span class="line">key = AQAUUchfjpMqGRAARV6h0ofdDEneuaRnxuHjoQ==</span><br><span class="line">caps mon = <span class="string">&quot;allow r&quot;</span></span><br><span class="line">caps osd = <span class="string">&quot;allow * pool=mypool&quot;</span></span><br></pre></td></tr></table></figure><p>三. 使用普通客户挂载块存储<br>#创建存储池：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br></pre></td><td class="code"><pre><span class="line">cephadmin@ceph-deploy:~/ceph-cluster<span class="variable">$ceph</span> osd pool create rbd-data1 32 32</span><br><span class="line"></span><br><span class="line"><span class="comment">#存储池启用 rbd</span></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster<span class="variable">$ceph</span> osd pool application <span class="built_in">enable</span> rbd-data1 rbd</span><br><span class="line"><span class="comment">#初始化 rbd</span></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster<span class="variable">$rbd</span> pool init -p rbd-data1</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建两个镜像：</span></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster<span class="variable">$rbd</span> create data-img1 --size 3G --pool rbd-data1 --image-format 2 --image-feature layering</span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster<span class="variable">$rbd</span> create data-img2 --size 5G --pool rbd-data1 --image-format 2 --image-feature layering</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#列出镜像信息</span></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster<span class="variable">$rbd</span> <span class="built_in">ls</span> --pool rbd-data1</span><br><span class="line"><span class="comment">#以 json 格 式 显 示 镜 像 信 息</span></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster<span class="variable">$rbd</span> <span class="built_in">ls</span> --pool rbd-data1 -l --format json --pretty-format</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建普通账户</span></span><br><span class="line">ceph auth add client.shijie mon <span class="string">&#x27;allow r&#x27;</span> osd <span class="string">&#x27;allow rwx pool=rbd-data1&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#验证用户信息</span></span><br><span class="line">ceph auth get client.shijie</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建用 keyring 文件</span></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph-authtool --create-keyring ceph.client.shijie.keyring</span><br><span class="line"></span><br><span class="line"><span class="comment">#导出用户 keyring</span></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph auth get client.shijie -o ceph.client.shijie.keyring </span><br><span class="line"></span><br><span class="line"><span class="comment">#验证指定用户的 keyring 文件</span></span><br><span class="line"></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster<span class="variable">$cat</span> ceph.client.shijie.keyring </span><br><span class="line">  </span><br><span class="line"><span class="comment">#同 步 普 通 用 户 认 证 文 件</span></span><br><span class="line"></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ scp ceph.client.shijie.keyring root@172.31.6.109:/etc/ceph/</span><br><span class="line"></span><br><span class="line"><span class="comment">#管理端验证镜像状态</span></span><br><span class="line"></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster<span class="variable">$rbd</span> <span class="built_in">ls</span> -p rbd-data1 -l</span><br><span class="line"></span><br><span class="line"><span class="comment">#在client上操作</span></span><br><span class="line"><span class="comment">#映射 rbd</span></span><br><span class="line"></span><br><span class="line">root@ceph-node4:/<span class="comment"># rbd -p rbd-data1 map data-img1</span></span><br><span class="line">/dev/rbd0</span><br><span class="line">root@ceph-node4:/<span class="comment"># lsblk</span></span><br><span class="line">rbd0</span><br><span class="line">root@ceph-node4:/<span class="comment"># mkfs.xfs /dev/rbd0</span></span><br><span class="line">root@ceph-node4:/<span class="comment"># mount /dev/rbd0 /data</span></span><br><span class="line">root@ceph-node4:/<span class="comment"># docker run -it -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=&quot;12345678&quot; -v /data:/var/lib/mysql mysql:5.6.46</span></span><br><span class="line">48374db8541a7fa375c00611373051ef21690e89adfd4c156b3f6ffb0dbe95a2</span><br><span class="line">root@ceph-node4:/data<span class="comment"># ls</span></span><br><span class="line">ibdata1  ib_logfile0  ib_logfile1  mysql  performance_schema  <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#在client上操作</span></span><br><span class="line"><span class="comment">#使用普通用户映射 rbd</span></span><br><span class="line"></span><br><span class="line">root@ceph-node4:/etc/ceph<span class="comment"># rbd --user shijie -p rbd-data1 map data-img2</span></span><br><span class="line">/dev/rbd1</span><br><span class="line"><span class="comment">#格式化</span></span><br><span class="line">root@ceph-node4:/etc/ceph<span class="comment">#mkfs.ext4 /dev/rbd0</span></span><br><span class="line">root@ceph-node4:/etc/ceph<span class="comment"># mkdir /data1</span></span><br><span class="line">root@ceph-node4:/etc/ceph<span class="comment"># mount /dev/rbd1 /data1</span></span><br><span class="line">root@ceph-node4:/etc/ceph<span class="comment"># cp /var/log/auth.log /data1</span></span><br><span class="line">root@ceph-node4:/etc/ceph<span class="comment"># cd /data1</span></span><br><span class="line">root@ceph-node4:/data1<span class="comment"># ls</span></span><br><span class="line">auth.log  lost+found</span><br><span class="line">四. 使用普通用户挂载 cephfs（可以通过 secret 或者 secretfile 的形式多主机同时挂载）</span><br><span class="line">Ceph FS 需要运行 Meta Data Services(MDS)服务，其守护进程为 ceph-mds，ceph-mds进程管理与 cephFS 上存储的文件相关的元数据，并协调对 ceph 存储集群的访问。</span><br><span class="line"></span><br><span class="line"><span class="comment">#部署MDS服务:</span></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ apt-cache madison ceph-mds</span><br><span class="line">  ceph-mds | 16.2.10-1bionic | https://mirrors.tuna.tsinghua.edu.cn/ceph/debian-pacific bionic/main amd64 Packages</span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ apt install ceph-mds=16.2.10-1bionic</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建CephFS meta data和data存储池</span></span><br><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph osd pool create cephfs-metadata 32 32</span><br><span class="line">pool <span class="string">&#x27;cephfs-metadata&#x27;</span> created <span class="comment">#保存 metadata 的 pool</span></span><br><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph osd pool create cephfs-data 64 64</span><br><span class="line">pool <span class="string">&#x27;cephfs-data&#x27;</span> created <span class="comment">#保存数据的 pool</span></span><br><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph fs new mycephfs cephfs-metadata</span><br><span class="line">cephfs-data</span><br><span class="line">new fs with metadata pool 7 and data pool 8</span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph fs <span class="built_in">ls</span></span><br><span class="line">name: mycephfs, metadata pool: cephfs-metadata, data pools: [cephfs-data ]</span><br><span class="line"><span class="comment">#查看指定 cephFS 状态</span></span><br><span class="line"></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph fs status mycephfs</span><br><span class="line">mycephfs - 0 clients</span><br><span class="line">RANK  STATE      MDS        ACTIVITY     DNS    INOS   DIRS   CAPS  </span><br><span class="line"> 0    active  ceph-mgr1  Reqs:    0 /s    10     13     12      0   </span><br><span class="line">      POOL         TYPE     USED  AVAIL  </span><br><span class="line">cephfs-metadata  metadata   146k  18.9T  </span><br><span class="line">  cephfs-data      data       0   18.9T  </span><br><span class="line">MDS version: ceph version 16.2.10 (45fa1a083152e41a408d15505f594ec5f1b4fe17) pacific (stable)</span><br><span class="line"><span class="comment">#验证cephFS服务状态</span></span><br><span class="line"></span><br><span class="line">cephadmin@ceph-deploy:~$ ceph mds <span class="built_in">stat</span></span><br><span class="line">mycephfs:1 &#123;0=ceph-mgr1=up:active&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建客户端账户</span></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster<span class="variable">$ceph</span> auth add client.yanyan mon <span class="string">&#x27;allow r&#x27;</span> mds <span class="string">&#x27;allow rw&#x27;</span> osd <span class="string">&#x27;allow rwx pool=cephfs-data&#x27;</span></span><br><span class="line"><span class="comment">#验证账户</span></span><br><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph auth get client.yanyan</span><br><span class="line">exported keyring <span class="keyword">for</span> client.yanyan</span><br><span class="line">[client.yanyan]</span><br><span class="line">key = AQCxpdhfjQt1OxAAGe0mqTMveNu2ZMEem3tb0g==</span><br><span class="line">caps mds = <span class="string">&quot;allow rw&quot;</span></span><br><span class="line">caps mon = <span class="string">&quot;allow r&quot;</span></span><br><span class="line">caps osd = <span class="string">&quot;allow rwx pool=cephfs-data&quot;</span></span><br><span class="line"><span class="comment">#创建keyring 文件</span></span><br><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph auth get client.yanyan -o</span><br><span class="line">ceph.client.yanyan.keyring</span><br><span class="line">exported keyring <span class="keyword">for</span> client.yanyan</span><br><span class="line"><span class="comment">#创建 key 文件：</span></span><br><span class="line"></span><br><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph auth print-key client.yanyan &gt; yanyan.key</span><br><span class="line"><span class="comment">#验证用户的 keyring 文件</span></span><br><span class="line"></span><br><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ <span class="built_in">cat</span> ceph.client.yanyan.keyring</span><br><span class="line">[client.yanyan]</span><br><span class="line">key = AQCxpdhfjQt1OxAAGe0mqTMveNu2ZMEem3tb0g==</span><br><span class="line">caps mds = <span class="string">&quot;allow rw&quot;</span></span><br><span class="line">caps mon = <span class="string">&quot;allow r&quot;</span></span><br><span class="line">caps osd = <span class="string">&quot;allow rwx pool=cephfs-data&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#同步客户端认证文件 ：</span></span><br><span class="line"></span><br><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ scp ceph.conf ceph.client.yanyan.keyring</span><br><span class="line">yanyan.key root@172.31.6.109:/etc/ceph/</span><br><span class="line"></span><br><span class="line"><span class="comment">#客户端验证权限</span></span><br><span class="line"></span><br><span class="line">root@ceph-node4:~<span class="comment"># ceph --user yanyan -s</span></span><br><span class="line">  cluster:</span><br><span class="line">    <span class="built_in">id</span>:     7c088d6f-06b0-4584-b23f-c0f150af51d4</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph-mon1,ceph-mon2,ceph-mon3 (age 24m)</span><br><span class="line">    mgr: ceph-mgr1(active, since 65m)</span><br><span class="line">    mds: 1/1 daemons up</span><br><span class="line">    osd: 16 osds: 16 up (since 24m), 16 <span class="keyword">in</span> (since 13d)</span><br><span class="line">    rgw: 1 daemon active (1 hosts, 1 zones)</span><br><span class="line">  data:</span><br><span class="line">    volumes: 1/1 healthy</span><br><span class="line">    pools:   10 pools, 329 pgs</span><br><span class="line">    objects: 296 objects, 218 MiB</span><br><span class="line">    usage:   948 MiB used, 60 TiB / 60 TiB avail</span><br><span class="line">    pgs:     329 active+clean</span><br><span class="line"></span><br><span class="line"><span class="comment">#客户端通过 key 文件挂载:</span></span><br><span class="line"></span><br><span class="line"> root@ceph-node4:~<span class="comment">#mkdir /data</span></span><br><span class="line"> root@ceph-node4:/etc/ceph<span class="comment"># mount -t ceph 172.31.6.101:6789,172.31.6.102:6789,172.31.6.103:6789:/ /data -o name=yanyan,secretfile=/etc/ceph/yanyan.key</span></span><br><span class="line">root@ceph-node4:/etc/ceph<span class="comment"># df -h</span></span><br><span class="line">Filesystem                                               Size  Used Avail Use% Mounted on</span><br><span class="line">udev                                                     955M     0  955M   0% /dev</span><br><span class="line">172.31.6.101:6789,172.31.6.102:6789,172.31.6.103:6789:/   19T     0   19T   0% /data</span><br><span class="line"></span><br><span class="line"><span class="comment">#客户端通过key挂载</span></span><br><span class="line"></span><br><span class="line">root@ceph-node3:~<span class="comment"># mkdir /data</span></span><br><span class="line">root@ceph-node3:~<span class="comment"># mount -t ceph 172.31.6.101:6789,172.31.6.102:6789,172.31.6.103:6789:/ /data -o name=yanyan,secret=AQAfebVjaIPgABAAzkW4ChX2Qm2Sha/5twdxPA==</span></span><br><span class="line">root@ceph-node3:~<span class="comment"># df -h</span></span><br><span class="line">Filesystem                                               Size  Used Avail Use% Mounted on</span><br><span class="line">udev                                                     955M     0  955M   0% /dev</span><br><span class="line">172.31.6.101:6789,172.31.6.102:6789,172.31.6.103:6789:/   19T     0   19T   0% /data</span><br><span class="line">root@ceph-node3:~<span class="comment"># cp /var/log/auth.log /data</span></span><br><span class="line">root@ceph-node3:~<span class="comment"># cd /data</span></span><br><span class="line">root@ceph-node3:/data<span class="comment"># ls</span></span><br><span class="line">auth.log</span><br><span class="line">root@ceph-node3:/data<span class="comment"># vim auth.log </span></span><br><span class="line">root@ceph-node3:/data<span class="comment"># echo &quot;12345678&quot; &gt;&gt; auth.log </span></span><br><span class="line">root@ceph-node3:/data<span class="comment"># echo &quot;testlog&quot; &gt;&gt; auth.log</span></span><br><span class="line"><span class="comment">#在node4客户端上查看cephfs挂载点/data 目录下内容，已经同步</span></span><br><span class="line"></span><br><span class="line">root@ceph-node4:/<span class="comment"># tail -f /data/auth.log </span></span><br><span class="line">Jan  4 22:25:01 ceph-node3 CRON[4365]: pam_unix(cron:session): session closed <span class="keyword">for</span> user root</span><br><span class="line">12345678</span><br><span class="line">testlog</span><br><span class="line"><span class="comment">#客户端内核加载 ceph.ko 模块挂载 cephfs 文件系统</span></span><br><span class="line"></span><br><span class="line">root@ceph-node4:/<span class="comment"># lsmod|grep ceph</span></span><br><span class="line">ceph                  380928  1</span><br><span class="line">libceph               315392  1 ceph</span><br><span class="line">fscache                65536  1 ceph</span><br><span class="line">libcrc32c              16384  5 nf_conntrack,nf_nat,xfs,raid456,libceph</span><br><span class="line">root@ceph-node4:/<span class="comment"># modinfo ceph</span></span><br><span class="line">filename:       /lib/modules/4.15.0-130-generic/kernel/fs/ceph/ceph.ko</span><br><span class="line">license:        GPL</span><br><span class="line">description:    Ceph filesystem <span class="keyword">for</span> Linux</span><br><span class="line">author:         Patience Warnick &lt;patience@newdream.net&gt;</span><br><span class="line">author:         Yehuda Sadeh &lt;yehuda@hq.newdream.net&gt;</span><br><span class="line">author:         Sage Weil &lt;sage@newdream.net&gt;</span><br><span class="line"><span class="built_in">alias</span>:          fs-ceph</span><br><span class="line">srcversion:     CB79D9E4790452C6A392A1C</span><br><span class="line">depends:        libceph,fscache</span><br><span class="line">retpoline:      Y</span><br><span class="line">intree:         Y</span><br><span class="line">name:           ceph</span><br><span class="line">vermagic:       4.15.0-130-generic SMP mod_unload </span><br><span class="line">signat:         PKCS<span class="comment">#7</span></span><br><span class="line">signer:         </span><br><span class="line">sig_key:        </span><br><span class="line">sig_hashalgo:   md4</span><br></pre></td></tr></table></figure><p>五.实现 MDS 服务的多主一备高可用架构</p><p>#当前mds服务器状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cephadmin@ceph-deploy:~$ ceph mds <span class="built_in">stat</span></span><br><span class="line">mycephfs:1 &#123;0=ceph-mgr1=up:active&#125;</span><br><span class="line"><span class="comment">#添加MDS服务器</span></span><br><span class="line">将 ceph-mgr2 和 ceph-mon2 和 ceph-mon3 作为 mds 服务角色添加至 ceph 集群，最后实两主两备的 mds 高可用和高性能结构。</span><br><span class="line"><span class="comment">#mds 服务器安装 ceph-mds 服务</span></span><br><span class="line"></span><br><span class="line">[root@ceph-mgr2 ~]<span class="comment"># apt install ceph-mds -y</span></span><br><span class="line">[root@ceph-mon2 ~]<span class="comment"># apt install ceph-mds -y</span></span><br><span class="line">[root@ceph-mon3 ~]<span class="comment"># apt install ceph-mds -y</span></span><br><span class="line"><span class="comment">#添加 mds 服务器</span></span><br><span class="line"></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph-deploy mds create ceph-mgr2</span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph-deploy mds create ceph-mon2</span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph-deploy mds create ceph-mon3</span><br></pre></td></tr></table></figure><p>#验证 mds 服务器当前状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[cephadmin@ceph-deploy ceph-cluster]$ ceph mds <span class="built_in">stat</span></span><br><span class="line">mycephfs-1/1/1 up &#123;0=ceph-mgr1=up:active&#125;, 3 up:standby</span><br></pre></td></tr></table></figure><p>#验证 ceph集群当前状态<br>当前处于激活状态的 mds 服务器有一台，处于备份状态的 mds 服务器有三台。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph fs status</span><br><span class="line">mycephfs - 0 clients</span><br><span class="line">RANK  STATE      MDS        ACTIVITY     DNS    INOS   DIRS   CAPS  </span><br><span class="line"> 0    active  ceph-mgr1  Reqs:    0 /s    16     14     12      0   </span><br><span class="line">      POOL         TYPE     USED  AVAIL  </span><br><span class="line">cephfs-metadata  metadata   282k  18.9T  </span><br><span class="line">  cephfs-data      data     564k  18.9T  </span><br><span class="line">STANDBY MDS  </span><br></pre></td></tr></table></figure><p>#当前的文件系统状态:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph fs get mycephfs</span><br><span class="line">Filesystem <span class="string">&#x27;mycephfs&#x27;</span> (1)</span><br><span class="line">fs_name        mycephfs</span><br><span class="line">epoch        28</span><br><span class="line">flags        12</span><br><span class="line">created        2023-01-01T19:09:29.258956+0800</span><br><span class="line">modified        2023-01-05T14:58:00.369468+0800</span><br><span class="line">tableserver        0</span><br><span class="line">root        0</span><br><span class="line">session_timeout        60</span><br><span class="line">session_autoclose        300</span><br><span class="line">max_file_size        1099511627776</span><br><span class="line">required_client_features        &#123;&#125;</span><br><span class="line">last_failure        0</span><br><span class="line">last_failure_osd_epoch        406</span><br><span class="line">compat        compat=&#123;&#125;,rocompat=&#123;&#125;,incompat=&#123;1=base v0.20,2=client writeable ranges,3=default file layouts on <span class="built_in">dirs</span>,4=<span class="built_in">dir</span> inode <span class="keyword">in</span> separate object,5=mds uses versioned encoding,6=dirfrag is stored <span class="keyword">in</span> omap,7=mds uses inline data,8=no anchor table,9=file layout v2,10=snaprealm v2&#125;</span><br><span class="line">max_mds        1</span><br><span class="line"><span class="keyword">in</span>        0</span><br><span class="line">up        &#123;0=144106&#125;</span><br><span class="line">failed        </span><br><span class="line">damaged        </span><br><span class="line">stopped        </span><br><span class="line">data_pools        [8]</span><br><span class="line">metadata_pool        7</span><br><span class="line">inline_data        disabled</span><br><span class="line">balancer        </span><br><span class="line">standby_count_wanted        1</span><br><span class="line">[mds.ceph-mgr1&#123;0:144106&#125; state up:active <span class="built_in">seq</span> 27 addr [v2:172.31.6.104:6800/428364709,v1:172.31.6.104:6801/428364709] compat &#123;c=[1],r=[1],i=[7ff]&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置处于激活状态mds的数量</span></span><br><span class="line">目前有四个 mds 服务器，但是有一个主三个备，可以优化一下部署架构，设置为为两主两备。</span><br><span class="line"></span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph fs <span class="built_in">set</span> mycephfs max_mds 2</span><br><span class="line">cephadmin@ceph-deploy:~/ceph-cluster$ ceph fs status</span><br><span class="line">mycephfs - 0 clients</span><br><span class="line">RANK  STATE      MDS        ACTIVITY     DNS    INOS   DIRS   CAPS  </span><br><span class="line"> 0    active  ceph-mgr1  Reqs:    0 /s    16     14     12      0   </span><br><span class="line"> 1    active  ceph-mon2  Reqs:    0 /s    10     13     11      0   </span><br><span class="line">      POOL         TYPE     USED  AVAIL  </span><br><span class="line">cephfs-metadata  metadata   354k  18.9T  </span><br><span class="line">  cephfs-data      data     564k  18.9T  </span><br><span class="line">STANDBY MDS  </span><br><span class="line"> ceph-mgr2   </span><br><span class="line"> ceph-mon3   </span><br><span class="line">MDS version: ceph version 16.2.10 (45fa1a083152e41a408d15505f594ec5f1b4fe17) pacific (stable)</span><br></pre></td></tr></table></figure><p>安装完成后ceph -s提示：“mon is allowing insecure global_id reclaim”。</p><p>解决方案：禁用不安全模式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph config <span class="built_in">set</span> mon auth_allow_insecure_global_id_reclaim <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>输入完成后需要等待5-10秒。</p><p>PG数量计算公式：</p><p>（总OSD数量*100）&#x2F; 副本数（复制分数，默认为3）&#x3D; PG数量</p><p>一般情况下结果取2的N次方，尽量先设置小点，后期可以增大。如果先设置的比较大的话后期减小风险较高，所以尽量取小的2的N次方结果。<br>建一个存储池，要想使用ceph的存储功能，必须先创建存储池</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool create rbd 128 128 </span><br></pre></td></tr></table></figure><p>初始化存储池</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd pool init -p rbd</span><br></pre></td></tr></table></figure><p>1.设置存储池副本数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@controller-1 ~]<span class="comment"># ceph osd pool get rbd size</span></span><br><span class="line">size: 2</span><br><span class="line">[root@controller-1 ~]<span class="comment"># ceph osd pool set rbd size 1</span></span><br><span class="line"><span class="built_in">set</span> pool 1 size to 1</span><br></pre></td></tr></table></figure><p>升级client的虚拟机内核到5版本</p><p>修改client下文件权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +r /etc/ceph/ceph.client.admin.keyring</span><br><span class="line">client节点创建设备镜像，单位是M</span><br><span class="line">rbd create --size 4096 --pool rbd img</span><br><span class="line">client节点映射镜像到主机：</span><br><span class="line">rbd map img --name client.admin</span><br><span class="line">client节点格式化块设备</span><br><span class="line">mkfs.ext4 -m 0 /dev/rbd/rbd/foo </span><br><span class="line">client节点挂载mount块设备</span><br><span class="line"><span class="built_in">mkdir</span> /mnt/ceph-block-device</span><br><span class="line">mount /dev/rbd/rbd/foo /mnt/ceph-block-device -o discard</span><br><span class="line">创建文件系统时报不支持EC数据池问题</span><br><span class="line">当拥有一个ceph_metadata元数据副本类型池和一个ceph_data数据EC类型池时，建立文件系统：</span><br><span class="line">ceph fs new cephfs cephfs_metadata cephfs_data</span><br><span class="line">N版可能会报：</span><br><span class="line">Error EINVAL: pool <span class="string">&#x27;cephfs_data&#x27;</span> (<span class="built_in">id</span> <span class="string">&#x27;11&#x27;</span>) is an erasure-coded pool. Use of an EC pool <span class="keyword">for</span> the default data pool is discouraged; see the online CephFS documentation <span class="keyword">for</span> more information. Use --force to override.</span><br><span class="line">加上—force后：</span><br><span class="line">ceph fs new cephfs cephfs_metadata cephfs_data --force</span><br><span class="line"></span><br><span class="line">也可能会报：</span><br><span class="line"></span><br><span class="line">Error EINVAL: pool <span class="string">&#x27;cephfs_data&#x27;</span> (<span class="built_in">id</span> <span class="string">&#x27;11&#x27;</span>) is an erasure-coded pool, with no overwrite support</span><br><span class="line"></span><br><span class="line">这是需要手动设置ceph_data池 allow_ec_overwrites=<span class="literal">true</span></span><br><span class="line">ceph osd pool <span class="built_in">set</span> cephfs_data allow_ec_overwrites <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">再执行</span><br><span class="line">ceph fs new cephfs cephfs_metadata cephfs_data –forc</span><br><span class="line">就可以创建文件系统成功。</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>gitlab_ci runners</title>
      <link href="/2022/08/18/gitlab-ci-runners/"/>
      <url>/2022/08/18/gitlab-ci-runners/</url>
      
        <content type="html"><![CDATA[<h1 id="Download-the-binary-for-your-system"><a href="#Download-the-binary-for-your-system" class="headerlink" title="Download the binary for your system"></a>Download the binary for your system</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo curl -L --output /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64</span><br></pre></td></tr></table></figure><h1 id="Give-it-permissions-to-execute"><a href="#Give-it-permissions-to-execute" class="headerlink" title="Give it permissions to execute"></a>Give it permissions to execute</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">chmod</span> +x /usr/local/bin/gitlab-runner</span><br></pre></td></tr></table></figure><h1 id="Create-a-GitLab-CI-user"><a href="#Create-a-GitLab-CI-user" class="headerlink" title="Create a GitLab CI user"></a>Create a GitLab CI user</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo useradd --comment <span class="string">&#x27;GitLab Runner&#x27;</span> --create-home gitlab-runner --shell /bin/bash</span><br></pre></td></tr></table></figure><h1 id="Install-and-run-as-service"><a href="#Install-and-run-as-service" class="headerlink" title="Install and run as service"></a>Install and run as service</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner</span><br><span class="line">sudo gitlab-runner start</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gitlab-runner register --url http://andrewandbecky.top:30000/ --registration-token <span class="variable">$REGISTRATION_TOKEN</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hdfs</title>
      <link href="/2022/06/17/hdfs/"/>
      <url>/2022/06/17/hdfs/</url>
      
        <content type="html"><![CDATA[<h2 id="HDFS概述"><a href="#HDFS概述" class="headerlink" title="HDFS概述"></a>HDFS概述</h2><h3 id="HDFS产生背景"><a href="#HDFS产生背景" class="headerlink" title="HDFS产生背景"></a>HDFS产生背景</h3><p>随着数据量越来越大，在一个操作系统管辖的范围内存不下了，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种<br>系统来管理多台机器上的文件，这就是分布式文件管理系统。HDFS只是分布式文件管理系统中的一种。</p><h3 id="HDFS概念"><a href="#HDFS概念" class="headerlink" title="HDFS概念"></a>HDFS概念</h3><p>HDFS，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有<br>各自的角色。HDFS的设计适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用</p><h3 id="HDFS优缺点"><a href="#HDFS优缺点" class="headerlink" title="HDFS优缺点"></a>HDFS优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li><p>高容错性</p><ul><li>数据自动保存多个副本。它通过增加副本的形式，提高容错性；</li><li>某一个副本丢失以后，它可以自动恢复</li></ul></li><li><p>适合大数据处理</p><ul><li>数据规模：能够处理数据规模达到GB、TB、甚至PB级别的数据；</li><li>文件规模：能够处理百万规模以上的文件数量，数量相当之大。</li></ul></li><li><p>流式数据访问，它能保证数据的一致性。</p></li><li><p>可构建在廉价机器上，通过多副本机制，提高可靠性。</p></li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul><li>不适合低延时数据访问，比如毫秒级的存储数据，是做不到的。</li><li>无法高效的对大量小文件进行存储。<ul><li>存储大量小文件的话，它会占用NameNode大量的内存来存储文件、目录和块信息。这样是不可取的，因为NameNode的内存总是有限的；</li><li>小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标。</li></ul></li><li>并发写入、文件随机修改。<ul><li>一个文件只能有一个写，不允许多个线程同时写；</li><li>仅支持数据append（追加），不支持文件的随机修改。</li></ul></li></ul><h3 id="HDFS组成架构"><a href="#HDFS组成架构" class="headerlink" title="HDFS组成架构"></a>HDFS组成架构</h3><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9fb5b498df7b444087880236c63cdc3d~tplv-k3u1fbpfcp-watermark.image"></p><p>这种架构主要由四个部分组成，分别为HDFS Client、NameNode、DataNode和Secondary NameNode。下面我们分别介绍这四个组成部分。</p><ul><li><p>Client：就是客户端。</p><ul><li>文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行存储；</li><li>与NameNode交互，获取文件的位置信息；</li><li>与DataNode交互，读取或者写入数据；</li><li>Client提供一些命令来管理HDFS，比如启动或者关闭HDFS；</li><li>Client可以通过一些命令来访问HDFS；</li></ul></li><li><p>NameNode：就是Master，它是一个主管、管理者。</p><ul><li>管理HDFS的名称空间；</li><li>管理数据块（Block）映射信息；</li><li>配置副本策略；<br>- 处理客户端读写请求。</li></ul></li><li><p>DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。</p><ul><li>存储实际的数据块</li><li>执行数据块的读&#x2F;写操作。</li></ul></li><li><p>Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。</p><ul><li>辅助NameNode，分担其工作量；</li><li>定期合并Fsimage和Edits，并推送给NameNode；</li><li>在紧急情况下，可辅助恢复NameNode。</li></ul></li></ul><h3 id="HDFS文件块大小"><a href="#HDFS文件块大小" class="headerlink" title="HDFS文件块大小"></a>HDFS文件块大小</h3><p>HDFS中的文件在物理上是分块存储（block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x<br>版本中是128M，老版本中是64M。HDFS的块比磁盘的块大，其目的是为了最小化寻址开销。如果块设置得足够大，从磁盘传输数据的<br>时间会明显大于定位这个块开始位置所需的时间。因而，传输一个由多个块组成的文件的时间取决于磁盘传输速率。如果寻址时间约为<br>10ms，而传输速率为100MB&#x2F;s，为了使寻址时间仅占传输时间的1%，我们要将块大小设置约为100MB。默认的块大小128MB。块的大小：<br>10ms<em>100</em>100M&#x2F;s &#x3D; 100M</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/32ad8b86eab94a68b65c10857a3c31eb~tplv-k3u1fbpfcp-watermark.image"></p><h3 id="HDFS写数据流程"><a href="#HDFS写数据流程" class="headerlink" title="HDFS写数据流程"></a>HDFS写数据流程</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c6014ed71d4c4d57ae45c7c958e02e7c~tplv-k3u1fbpfcp-watermark.image"></p><ul><li>客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。</li><li>NameNode返回是否可以上传。</li><li>客户端请求第一个block上传到哪几个datanode服务器上。</li><li>NameNode返回3个datanode节点，分别为dn1、dn2、dn3。</li><li>客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</li><li>dn1、dn2、dn3逐级应答客户端。</li><li>客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1收到一个packet就会传给dn2，<br>dn传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</li><li>当一个block传输完成之后，客户端再次请求NameNode上传第二个block的服务器。（重复执行3-7步）。</li></ul><h3 id="网络拓扑概念"><a href="#网络拓扑概念" class="headerlink" title="网络拓扑概念"></a>网络拓扑概念</h3><p>在本地网络中，两个节点被称为“彼此近邻”是什么意思？在海量数据处理中，其主要限制因素是节点之间数据的传输速率——带宽很稀缺。<br>这里的想法是将两个节点间的带宽作为距离的衡量标准。</p><p>节点距离：两个节点到达最近的共同祖先的距离总和。<br><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c5daea537fea42d7bc72fca6edc765c6~tplv-k3u1fbpfcp-watermark.image"></p><h3 id="HDFS读数据流程"><a href="#HDFS读数据流程" class="headerlink" title="HDFS读数据流程"></a>HDFS读数据流程</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b7689706f7194aafa32acdd07b9df0da~tplv-k3u1fbpfcp-watermark.image"></p><ul><li>客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</li><li>挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。</li><li>DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以packet为单位来做校验）。</li><li>客户端以packet为单位接收，先在本地缓存，然后写入目标文件。</li></ul><h2 id="MapReduce入门"><a href="#MapReduce入门" class="headerlink" title="MapReduce入门"></a>MapReduce入门</h2><h3 id="MapReduce定义"><a href="#MapReduce定义" class="headerlink" title="MapReduce定义"></a>MapReduce定义</h3><p>Mapreduce是一个分布式运算程序的编程框架，是用户开发“基于hadoop的数据分析应用”的核心框架。Mapreduce核心功能是将用户编写的<br>业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个hadoop集群上。</p><h3 id="MapReduce优缺点"><a href="#MapReduce优缺点" class="headerlink" title="MapReduce优缺点"></a>MapReduce优缺点</h3><ul><li><p>优点</p><ul><li>MapReduce易于编程。它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的PC机器上运行。<br>也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得MapReduce编程变得非常流行。</li><li>良好的扩展性。当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。</li><li>高容错性。MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，<br>它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由Hadoop内部完成的。</li><li>适合PB级以上海量数据的离线处理。这里加红字体离线处理，说明它适合离线处理而不适合在线处理。比如像毫秒级别的返回一个结果，<br>MapReduce很难做到。</li></ul></li><li><p>缺点 MapReduce不擅长做实时计算、流式计算、DAG（有向图）计算。</p><ul><li>实时计算。MapReduce无法像Mysql一样，在毫秒或者秒级内返回结果。</li><li>流式计算。流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定-<br>据源必须是静态的。</li><li>DAG（有向图）计算。多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，<br>而是使用后，每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。</li></ul><h3 id="MapReduce核心思想"><a href="#MapReduce核心思想" class="headerlink" title="MapReduce核心思想"></a>MapReduce核心思想</h3><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/591d6d1a27e243f7bf5be80ff9904e1b~tplv-k3u1fbpfcp-watermark.image"></p></li><li><p>分布式的运算程序往往需要分成至少2个阶段。</p></li><li><p>第一个阶段的maptask并发实例，完全并行运行，互不相干。</p></li><li><p>第二个阶段的reduce task并发实例互不相干，但是他们的数据依赖于上一个阶段的所有maptask并发实例的输出。</p></li><li><p>MapReduce编程模型只能包含一个map阶段和一个reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个mapreduce程序，串行运行。</p></li></ul><h3 id="MapReduce进程"><a href="#MapReduce进程" class="headerlink" title="MapReduce进程"></a>MapReduce进程</h3><p>一个完整的mapreduce程序在分布式运行时有三类实例进程：</p><ul><li>MrAppMaster：负责整个程序的过程调度及状态协调。</li><li>MapTask：负责map阶段的整个数据处理流程。</li><li>ReduceTask：负责reduce阶段的整个数据处理流程。</li></ul><h3 id="MapReduce编程规范"><a href="#MapReduce编程规范" class="headerlink" title="MapReduce编程规范"></a>MapReduce编程规范</h3><p>用户编写的程序分成三个部分：Mapper、Reducer和Driver。</p><ul><li><p>Mapper阶段</p><ul><li>用户自定义的Mapper要继承自己的父类</li><li>Mapper的输入数据是KV对的形式（KV的类型可自定义）</li><li>Mapper中的业务逻辑写在map()方法中</li><li>Mapper的输出数据是KV对的形式（KV的类型可自定义）</li></ul></li><li><p>Reducer阶段</p><ul><li>用户自定义的Reducer要继承自己的父类</li><li>Reducer的输入数据类型对应Mapper的输出数据类型，也是KV</li><li>Reducer的业务逻辑写在reduce()方法中</li><li>Reducetask进程对每一组相同k的&lt;k,v&gt;组调用一次reduce()方法</li></ul></li><li><p>Driver阶段</p></li></ul><p>整个程序需要一个Drvier来进行提交，提交的是一个描述了各种必要信息的job对象</p><blockquote><p>其实吧我们真实开发也不会说去写mr 但是还是建议大家把最简单的wordcount做了。</p></blockquote><h2 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h2><h3 id="Yarn-概述"><a href="#Yarn-概述" class="headerlink" title="Yarn 概述"></a>Yarn 概述</h3><p>Yarn 是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式<br>的操作系统平台，而 MapReduce 等运算程序则相当于运行于操作系统之上的应用程序。</p><h3 id="Yarn-基本架构"><a href="#Yarn-基本架构" class="headerlink" title="Yarn 基本架构"></a>Yarn 基本架构</h3><p>YARN 主要由 ResourceManager、NodeManager、ApplicationMaster 和 Container 等组件<br>构成<br><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6c85d606218e477bbfa8cdcdb7022af4~tplv-k3u1fbpfcp-watermark.image"></p><h3 id="Yarn-工作机制"><a href="#Yarn-工作机制" class="headerlink" title="Yarn 工作机制"></a>Yarn 工作机制</h3><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ac47a79a89a142e3b7fe9a09df062d77~tplv-k3u1fbpfcp-watermark.image"></p><ul><li>Mr 程序提交到客户端所在的节点。</li><li>Yarnrunner 向 Resourcemanager 申请一个 Application。 </li><li>rm 将该应用程序的资源路径返回给 yarnrunner。 </li><li>该程序将运行所需资源提交到 HDFS 上。 </li><li>程序资源提交完毕后，申请运行 mrAppMaster。 </li><li>RM 将用户的请求初始化成一个 task。 </li><li>其中一个 NodeManager 领取到 task 任务。</li><li>该 NodeManager 创建容器 Container，并产生 MRAppmaster。 </li><li>Container 从 HDFS 上拷贝资源到本地。 </li><li>MRAppmaster 向 RM 申请运行 maptask 资源。</li><li>RM 将运行 maptask 任务分配给另外两个 NodeManager，另两个 NodeManager 分别领取任务并创建容器。</li><li>MR 向两个接收到任务的 NodeManager 发送程序启动脚本，这两个 NodeManager分别启动 maptask，maptask 对数据分区排序。</li><li>MrAppMaster 等待所有 maptask 运行完毕后，向 RM 申请容器，运行 reduce task。 </li><li>reduce task 向 maptask 获取相应分区的数据。</li><li>程序运行完毕后，MR 会向 RM 申请注销自己。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hive</title>
      <link href="/2022/06/16/hive/"/>
      <url>/2022/06/16/hive/</url>
      
        <content type="html"><![CDATA[<h4 id="Hive安装"><a href="#Hive安装" class="headerlink" title="Hive安装"></a>Hive安装</h4><h5 id="2-1-Hive-安装地址"><a href="#2-1-Hive-安装地址" class="headerlink" title="2.1 Hive 安装地址"></a>2.1 Hive 安装地址</h5><p>1)Hive 官网地址 <a href="http://hive.apache.org/">http://hive.apache.org/</a><br>2)文档查看地址 <a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted">https://cwiki.apache.org/confluence/display/Hive/GettingStarted</a><br>3)下载地址 <a href="http://archive.apache.org/dist/hive/">http://archive.apache.org/dist/hive/</a><br>4)github 地址 <a href="https://github.com/apache/hive">https://github.com/apache/hive</a></p><h5 id="2-2Hive-安装部署-2-2-1-安装-Hive"><a href="#2-2Hive-安装部署-2-2-1-安装-Hive" class="headerlink" title="2.2Hive 安装部署 2.2.1 安装 Hive"></a>2.2Hive 安装部署 2.2.1 安装 Hive</h5><p>1)把 apache-hive-3.1.2-bin.tar.gz 上传到 linux 的&#x2F;opt&#x2F;software 目录下<br>2)解压 apache-hive-3.1.2-bin.tar.gz 到&#x2F;opt&#x2F;module&#x2F;目录下面<br>3)修改 apache-hive-3.1.2-bin.tar.gz 的名称为 hive<br>4)修改&#x2F;etc&#x2F;profile.d&#x2F;my_env.sh，添加环境变量<br>    [andrw@hadoop101 software]$ sudo vim &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh<br>5)添加内容<br>6)解决日志 Jar 包冲突<br>7)初始化元数据库<br>    [andrw@hadoop101 hive]$ bin&#x2F;schematool -dbType derby -initSchema<br>2.2.2 启动并使用 Hive 1)启动 Hive<br>    [andrw@hadoop101 hive]$ bin&#x2F;hive<br>2)使用 Hive<br>3)在 CRT 窗口中开启另一个窗口开启 Hive，在&#x2F;tmp&#x2F;andrw 目录下监控 hive.log 文件<br>    [andrw@hadoop101 software]$ tar -zxvf &#x2F;opt&#x2F;software&#x2F;apache-hive-3.1.2-bin.tar.gz -C &#x2F;opt&#x2F;module&#x2F;<br>    [andrw@hadoop101 software]$ mv &#x2F;opt&#x2F;module&#x2F;apache-hive-3.1.2-bin&#x2F; &#x2F;opt&#x2F;module&#x2F;hive  </p><p>#HIVE_HOME</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HIVE_HOME=/opt/module/hive  </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin  </span><br><span class="line">[andrw@hadoop101 software]$ <span class="built_in">mv</span> <span class="variable">$HIVE_HOME</span>/lib/log4j-slf4j-impl-2.10.0.jar <span class="variable">$HIVE_HOME</span>/lib/log4j-slf4j-impl-2.10.0.bak  </span><br><span class="line">hive&gt; show databases;  </span><br><span class="line">hive&gt; show tables;  </span><br><span class="line">hive&gt; create table <span class="built_in">test</span>(<span class="built_in">id</span> int);  </span><br><span class="line">hive&gt; insert into <span class="built_in">test</span> values(1);  </span><br><span class="line">hive&gt; <span class="keyword">select</span> * from <span class="built_in">test</span>;  </span><br><span class="line">Caused by: ERROR XSDB6: Another instance of Derby may have already booted  </span><br><span class="line">the database /opt/module/hive/metastore_db.at  </span><br><span class="line">org.apache.derby.iapi.error.StandardException.newException(Unknown  </span><br><span class="line">Source)  </span><br><span class="line">       at  </span><br><span class="line">org.apache.derby.iapi.error.StandardException.newException(Unknown  </span><br><span class="line">Source) at  </span><br><span class="line">org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockO  </span><br><span class="line">nDB(Unknown Source)  </span><br><span class="line">       at  </span><br><span class="line">org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown  </span><br><span class="line">Source)  </span><br></pre></td></tr></table></figure><p>原因在于 Hive 默认使用的元数据库为 derby，开启 Hive 之后就会占用元数据库，且不与 其他客户端共享数据，所以我们需要将 Hive 的元数据地址改为 MySQL。</p><p>2.4 Hive 元数据配置到 MySQL 2.4.1 拷贝驱动<br>将 MySQL 的 JDBC 驱动拷贝到 Hive 的 lib 目录下<br>2.4.2 配置 Metastore 到 MySQL<br>1)在$HIVE_HOME&#x2F;conf 目录下新建 hive-site.xml 文件<br>    [andrew@hadoop101 software]$ vim $HIVE_HOME&#x2F;conf&#x2F;hive-site.xml<br>添加如下内容<br>   [andrew@hadoop101 software]$ cp &#x2F;opt&#x2F;software&#x2F;mysql-connector-java-5.1.37.jar $HIVE_HOME&#x2F;lib  </p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- jdbc 连接的 URL --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hadoop101:3306/metastore?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- jdbc 连接的 Driver--&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- jdbc 连接的 username--&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- jdbc 连接的 password --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Hive 元数据存储版本的验证 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--元数据存储授权--&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Hive 默认在 HDFS 的工作目录 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2)登陆 MySQL  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[andrew@hadoop101 software]$ mysql -uroot -p000000 </span><br></pre></td></tr></table></figure><p>3)新建 Hive 元数据库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create database metastore chartset utf8mb4;</span><br><span class="line">mysql&gt; quit;</span><br></pre></td></tr></table></figure><ol start="4"><li>初始化 Hive 元数据库<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">schematool -initSchema -dbType mysql -verbose</span><br></pre></td></tr></table></figure>2.4.3 再次启动 Hive</li></ol><p>1)启动 Hive</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br><span class="line">hive&gt; show tables;</span><br><span class="line">hive&gt; create table <span class="built_in">test</span> (<span class="built_in">id</span> int);</span><br><span class="line">hive&gt; insert into <span class="built_in">test</span> values(1);</span><br><span class="line">hive&gt; <span class="keyword">select</span> * from <span class="built_in">test</span>;</span><br></pre></td></tr></table></figure><p>2.5 使用元数据服务的方式访问 Hive </p><p>1)在 hive-site.xml 文件中添加如下配置信息</p><!-- 指定存储元数据要连接的地址 --><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://hadoop101:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2)启动 metastore</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[andrew@hadoop101 hive]$ hive --service metastore </span><br><span class="line">2020-04-24 16:58:08: Starting Hive Metastore Server </span><br></pre></td></tr></table></figure><p> 注意: 启动后窗口不能再操作，需打开一个新的 shell 窗口做别的操作</p><p>3)启动 hive</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[andrew@hadoop101 hive]$ bin/hive</span><br></pre></td></tr></table></figure><p>2.6 使用 JDBC 方式访问 Hive<br>1)在 hive-site.xml 文件中添加如下配置信息</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">&lt;!-- 指定 hiveserver2 连接的 host --&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop101<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定 hiveserver2 连接的端口号 --&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2)启动 hiveserver2</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive --service hiveserver2</span><br></pre></td></tr></table></figure><p>3)启动 beeline 客户端(需要多等待一会)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">beeline -u jdbc:hive2://hadoop101:10000 -n andrew</span><br></pre></td></tr></table></figure><p>4)看到如下界面</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Connecting to jdbc:hive2://hadoop101:10000</span><br><span class="line">Connected to: Apache Hive (version 3.1.2)</span><br><span class="line">Driver: Hive JDBC (version 3.1.2)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">Beeline version 3.1.2 by Apache Hive</span><br><span class="line">0: jdbc:hive2://hadoop101:10000&gt;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">nohup</span> hive --service metastore 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="built_in">nohup</span> hive --service hiveserver2 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>打印当前数据库名和表头</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>查看当前设置<br>hive&gt;set;</p><p>comment 中文乱码</p><p>①修改表字段注解和表注解<br>alter table COLUMNS_V2 modify column COMMENT varchar(256) character set utf8;<br>alter table TABLE_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;<br>② 修改分区字段注解：<br>alter table PARTITION_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;<br>alter table PARTITION_KEYS modify column PKEY_COMMENT varchar(4000) character set utf8;<br>③修改索引注解：<br>alter table INDEX_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;  </p>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop</title>
      <link href="/2022/01/16/hadoop/"/>
      <url>/2022/01/16/hadoop/</url>
      
        <content type="html"><![CDATA[<h2 id="大数据概念"><a href="#大数据概念" class="headerlink" title="大数据概念"></a>大数据概念</h2><p>大数据（big data）：指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、<br>洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。</p><blockquote><p>主要解决，海量数据的存储和海量数据的分析计算问题。</p></blockquote><h2 id="大数据技术生态体系"><a href="#大数据技术生态体系" class="headerlink" title="大数据技术生态体系"></a>大数据技术生态体系</h2><p>当然，目前这个生态是越来越大了，但是它的本质还是在二个方面 计算 和 存储</p><h3 id="开源生态"><a href="#开源生态" class="headerlink" title="开源生态"></a>开源生态</h3><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5f63ebfc9e784f7690d0ed92f290e7bb~tplv-k3u1fbpfcp-watermark.image"></p><ul><li><p>Sqoop：sqoop是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql)间进行数据的传递，可以将一个关系型数据库（例如：MySQL ,<br>Oracle 等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。</p></li><li><p>Flume：Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，<br>用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。</p></li><li><p>Kafka：Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性：</p><ul><li>通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。</li><li>高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。</li><li>支持通过Kafka服务器和消费机集群来分区消息。</li><li>支持Hadoop并行数据加载。</li></ul></li><li><p>Storm：Storm为分布式实时计算提供了一组通用原语，可被用于“流处理”之中，实时处理消息并更新数据库。这是管理队列及工作者集群的另一种方式。<br>Storm也可被用于“连续计算”（continuous computation），对数据流做连续查询，在计算时就将结果以流的形式输出给用户。</p></li><li><p>Spark：Spark是当前最流行的开源大数据内存计算框架。可以基于Hadoop上存储的大数据进行计算。</p></li><li><p>Oozie：Oozie是一个管理Hdoop作业（job）的工作流程调度管理系统。Oozie协调作业就是通过时间（频率）和有效数据触发当前的Oozie工作流程。</p></li><li><p>Hbase：HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。</p></li><li><p>Hive：hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce<br>任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p></li><li><p>Mahout:Apache Mahout是个可扩展的机器学习和数据挖掘库，当前Mahout支持主要的4个用例：推荐挖掘：搜集用户动作并以此给用户推荐可能喜欢的事物。<br>聚集：收集文件并进行相关文件分组。分类：从现有的分类文档中学习，寻找文档中的相似特征，并为无标签的文档进行正确的归类。频繁项集挖掘：将一组项分组，<br>并识别哪些个别项会经常一起出现。</p></li><li><p>ZooKeeper：Zookeeper是Google的Chubby一个开源的实现。它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、<br>组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p></li></ul><h3 id="阿里云MaxCompute"><a href="#阿里云MaxCompute" class="headerlink" title="阿里云MaxCompute"></a>阿里云MaxCompute</h3><p>MaxCompute（大数据计算服务）是是一种快速、完全托管的TB&#x2F;PB级数据仓库解决方案。MaxCompute主要用于实时性要求不高的、批量结构化数据的存储和计算。<br>并可提供大数据分析建模服务。其特点如下： </p><ul><li>采用分布式架构高效处理海量数据</li><li>基于表的数据存储</li><li>于SQL的数据处理</li><li>支持多用户协同分析数据，多种权限管理方式，具有灵活的数据访问控制策略</li><li>兼容Hive</li></ul><p>MaxCompute架构<br><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/521857b4c5af453e8967446f719eee2c~tplv-k3u1fbpfcp-watermark.image"></p><p>MaxCompute功能</p><ul><li>数据存储</li></ul><p>适用于TB以上规模的存储及计算需求，最大可达EB级别。数据分布式存储，多副本冗余，数据存储对外仅开放表的操作接口，不提供文件系统访问接口。表数据列式存储，<br>默认高度压缩，后续将提供兼容ORC的Ali-ORC存储格式。<br>支持外表，将存储在OSS对象存储、OTS表格存储的数据映射为二维表。<br>支持Partition、Bucket的分区、分桶存储。<br>底层是盘古文件系统（不是HDFS）。<br>使用时，存储与计算解耦，不需要仅仅为了存储而扩大不必要的计算资源。</p><ul><li>数据通道<br>TUNNEL：提供高并发的离线数据上传下载服务。支持每天TB&#x2F;PB级别的数据导入导出。适合于全量数据或历史数据的批量导入。</li></ul><p>DataHub：针对实时数据上传的场景，具有延迟低、使用方便的特点，适用于增量数据的导入。Datahub还支持多种数据传输插件，包括Logstash、Flume、Fluentd、<br>Sqoop等。同时支持日志服务Log Service中的日志数据的一键投递至MaxCompute，进而利用大数据开发套件进行日志分析和挖掘。</p><ul><li>多种计算模型<br>SQL：以二维表的形式存储数据，支持多种数据类型，MaxCompute以二维表的形式存储数据，对外提供了SQL查询功能。不支持事务、索引及Update&#x2F;Delete等操作，<br>SQL语法与Oracle，MySQL等有一定差别。无法在毫秒级别返回结果。</li></ul><p>MapReduce：支持MapReduce java编程接口（提供优化增强的MaxCompute MapReduce，也提供高度兼容Hadoop的MapReduce版本）。不暴露文件系统，<br>输入输出都是表。通过MaxCompute客户端工具、Dataworks提交作业。</p><p>Graph：是一套面向迭代的图计算处理框架。图计算作业使用图进行建模，图由点（Vertex）和边（Edge）组成，点和边包含权值（Value）。通过迭代对图进行编辑、<br>演化，最终求解出结果，典型应用：PageRank、单源最短距离算法 、K-均值聚类算法等。</p><ul><li>Spark</li></ul><p>MaxCompute提供了Spark on MaxCompute的解决方案，在统一的计算资源和数据集权限体系之上，提供Spark计算框架，支持用户以熟悉的开发使用方式提交运行<br>Spark作业。</p><ul><li>交互式分析(Lightning)<br>MaxCompute产品的交互式查询服务。兼容PostgreSQL协议的JDBC&#x2F;ODBC接口。支持主流BI及SQL客户端工具的连接访问，如Tableau、帆软BI、Navicat、SQL<br>Workbench&#x2F;J等。</li></ul><h2 id="Hadoop是什么"><a href="#Hadoop是什么" class="headerlink" title="Hadoop是什么"></a>Hadoop是什么</h2><ul><li>Hadoop是一个由Apache基金会所开发的分布式系统基础架构。</li><li>主要解决，海量数据的存储和海量数据的分析计算问题。</li><li>广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈。</li></ul><h2 id="Hadoop的组成"><a href="#Hadoop的组成" class="headerlink" title="Hadoop的组成"></a>Hadoop的组成</h2><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/94def613dbab4f819ff61a0802b4a5d2~tplv-k3u1fbpfcp-watermark.image"></p><h3 id="HDFS架构概述"><a href="#HDFS架构概述" class="headerlink" title="HDFS架构概述"></a>HDFS架构概述</h3><ul><li>NameNode（nn）：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。</li><li>DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。</li><li>Secondary NameNode(2nn)：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</li></ul><h3 id="YARN架构概述"><a href="#YARN架构概述" class="headerlink" title="YARN架构概述"></a>YARN架构概述</h3><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0e22495656df4cb1b6bbf187dac7b733~tplv-k3u1fbpfcp-watermark.image"></p><h3 id="MapReduce架构概述"><a href="#MapReduce架构概述" class="headerlink" title="MapReduce架构概述"></a>MapReduce架构概述</h3><p>MapReduce将计算过程分为两个阶段：Map和Reduce</p><ul><li>Map阶段并行处理输入数据</li><li>Reduce阶段对Map结果进行汇总</li></ul><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2fe4c16a0a4b4ea3b04b80c2318513cb~tplv-k3u1fbpfcp-watermark.image"></p><h2 id="Hadoop分布式搭建"><a href="#Hadoop分布式搭建" class="headerlink" title="Hadoop分布式搭建"></a>Hadoop分布式搭建</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>hbase安装</title>
      <link href="/2021/08/16/hbase%E5%AE%89%E8%A3%85/"/>
      <url>/2021/08/16/hbase%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h3 id="2-1-HBase-安装部署"><a href="#2-1-HBase-安装部署" class="headerlink" title="2.1 HBase 安装部署"></a>2.1 HBase 安装部署</h3><h5 id="2-1-1-Zookeeper-正常部署"><a href="#2-1-1-Zookeeper-正常部署" class="headerlink" title="2.1.1 Zookeeper 正常部署"></a>2.1.1 Zookeeper 正常部署</h5><p>首先保证 Zookeeper 集群的正常部署，并启动之:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[andrew@hadoop101 zookeeper-3.4.10]$ bin/zkServer.sh start </span><br><span class="line">[andrew@hadoop101 zookeeper-3.4.10]$ bin/zkServer.sh start </span><br><span class="line">[andrew@hadoop101 zookeeper-3.4.10]$ bin/zkServer.sh start</span><br></pre></td></tr></table></figure><h5 id="2-1-2-Hadoop-正常部署-Hadoop-集群的正常部署并启动"><a href="#2-1-2-Hadoop-正常部署-Hadoop-集群的正常部署并启动" class="headerlink" title="2.1.2 Hadoop 正常部署 Hadoop 集群的正常部署并启动:"></a>2.1.2 Hadoop 正常部署 Hadoop 集群的正常部署并启动:</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[andrew@hadoop101 hadoop-2.7.2]$ sbin/start-dfs.sh </span><br><span class="line">[andrew@hadoop103 hadoop-2.7.2]$ sbin/start-yarn.sh</span><br></pre></td></tr></table></figure><h5 id="2-1-3-HBase-的解压-解压-Hbase-到指定目录"><a href="#2-1-3-HBase-的解压-解压-Hbase-到指定目录" class="headerlink" title="2.1.3 HBase 的解压 解压 Hbase 到指定目录:"></a>2.1.3 HBase 的解压 解压 Hbase 到指定目录:</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[andrew@hadoop101 software]$ tar -zxvf hbase-1.3.1-bin.tar.gz -C /opt/module</span><br></pre></td></tr></table></figure><p>2.1.4 HBase 的配置文件<br>修改 HBase 对应的配置文件。</p><p> 1)hbase-env.sh 修改内容: 2)hbase-site.xml 修改内容:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc  </span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144   </span><br><span class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">false</span> </span><br></pre></td></tr></table></figure><p>hbase-site.xml 修改内容</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:8020/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 0.98 后的新变动，之前版本没有.port,默认端口为 60000 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>16000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/zookeeper-3.5.7/zkData<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.unsafe.stream.capability.enforce<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="comment">&lt;!-- &lt;property&gt;</span></span><br><span class="line"><span class="comment">      &lt;name&gt;phoenix.schema.isNamespaceMappingEnabled&lt;/name&gt;</span></span><br><span class="line"><span class="comment">      &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="comment">    &lt;/property&gt;</span></span><br><span class="line"><span class="comment">    &lt;property&gt;</span></span><br><span class="line"><span class="comment">    &lt;name&gt;phoenix.schema.mapSystemTablesToNamespace&lt;/name&gt;</span></span><br><span class="line"><span class="comment">      &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="comment">   &lt;/property&gt; --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim regionservers</span><br><span class="line"></span><br><span class="line">localhost</span><br></pre></td></tr></table></figure><p>启动hbase</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hbase-daemon.sh start </span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>k8s安装</title>
      <link href="/2021/08/16/k8s%E5%AE%89%E8%A3%85/"/>
      <url>/2021/08/16/k8s%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p>k8s-安装<br>Kubernetes是什么？<br>Kubernetes是容器集群管理系统，是一个开源的平台，可以实现容器集群的自动化部署、自动扩缩容、维护等功能。 通过Kubernetes你可以：</p><p>快速部署应用<br>快速扩展应用<br>无缝对接新的应用功能<br>节省资源，优化硬件资源的使用<br>Kubernetes 特点<br>可移植: 支持公有云，私有云，混合云，多重云（multi-cloud）<br>可扩展: 模块化, 插件化, 可挂载, 可组合<br>自动化: 自动部署，自动重启，自动复制，自动伸缩&#x2F;扩展<br>使用Kubernetes能做什么？<br>多个进程（作为容器运行）协同工作。（Pod）<br>存储系统挂载<br>Distributing secrets<br>应用健康检测<br>应用实例的复制<br>Pod自动伸缩&#x2F;扩展<br>Naming and discovering<br>负载均衡<br>滚动更新<br>资源监控<br>日志访问<br>调试应用程序<br>提供认证和授权<br>Kubernetes 组件<br>K8s是由许多个的组件组成的 分为Master组件和节点（Node）组件</p><p>Master组件<br>Master组件提供集群的管理控制中心。 Master组件可以在集群中任何节点上运行。但是为了简单起见，通常在一台VM&#x2F;机器上启动所有Master组件，并且不会在此VM&#x2F;机器上运行用户容器。</p><p>kube-apiserver<br>kube-apiserver用于暴露Kubernetes API。任何的资源请求&#x2F;调用操作都是通过kube-apiserver提供的接口进行。请参阅构建高可用群集。</p><p>ETCD<br>etcd是Kubernetes提供默认的存储系统，保存所有集群数据，使用时需要为etcd数据提供备份计划。</p><p>kube-controller-manager<br>kube-controller-manager运行管理控制器，它们是集群中处理常规任务的后台线程。逻辑上，每个控制器是一个单独的进程，但为了降低复杂性，它们都被编译成单个二进制文件，并在单个进程中运行。</p><p>kube-scheduler<br>kube-scheduler 监视新创建没有分配到Node的Pod，为Pod选择一个Node。</p><p>节点（Node）组件<br>节点组件运行在Node，提供Kubernetes运行时环境，以及维护Pod。</p><p>kubelet<br>kubelet是主要的节点代理，它会监视已分配给节点的pod，具体功能：</p><p>安装Pod所需的volume。<br>下载Pod的Secrets。<br>Pod中运行的 docker（或experimentally，rkt）容器。<br>定期执行容器健康检查。<br>Reports the status of the pod back to the rest of the system, by creating a mirror pod if necessary.<br>Reports the status of the node back to the rest of the system.<br>kube-proxy<br>kube-proxy通过在主机上维护网络规则并执行连接转发来实现Kubernetes服务抽象。</p><p>Kubernetes 安装前的准备<br>概述<br>本次安装采用 Ubuntu Server X64 16.04 LTS 版本安装 kubernetes 集群环境，集群节点为 1 主 2 从模式，此次对虚拟机会有些基本要求，如下：</p><p>OS：Ubuntu Server X64 18.04 LTS（16.04 版本步骤相同，再之前则不同）<br>CPU：最低要求，1 CPU 2 核<br>内存：最低要求，2GB<br>磁盘：最低要求，20GB<br>创建三台虚拟机，分别命名如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Ubuntu Server 18.04 X64 Kubernetes Master</span><br><span class="line">Ubuntu Server 18.04 X64 Kubernetes Slave1</span><br><span class="line">Ubuntu Server 18.04 X64 Kubernetes Slave2</span><br></pre></td></tr></table></figure><p>对虚拟机系统的配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">关闭交换空间：sudo swapoff -a</span><br><span class="line">避免开机启动交换空间：注释 /etc/fstab 中的 swap</span><br><span class="line">关闭防火墙：ufw <span class="built_in">disable</span></span><br><span class="line">使用 APT 安装 Docker</span><br><span class="line">安装</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新软件源  </span></span><br><span class="line">sudo apt-get update  </span><br><span class="line"><span class="comment"># 安装所需依赖</span></span><br><span class="line">sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common</span><br><span class="line"><span class="comment"># 安装 GPG 证书</span></span><br><span class="line">curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class="line"><span class="comment"># 新增软件源信息</span></span><br><span class="line">sudo add-apt-repository <span class="string">&quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu <span class="subst">$(lsb_release -cs)</span> stable&quot;</span></span><br><span class="line"><span class="comment"># 再次更新软件源</span></span><br><span class="line">sudo apt-get -y update</span><br><span class="line"><span class="comment"># 安装 Docker CE 版</span></span><br><span class="line">sudo apt-get -y install docker-ce  </span><br></pre></td></tr></table></figure><p>验证</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">docker version</span><br><span class="line">Client:</span><br><span class="line"> Version:           18.09.6</span><br><span class="line"> API version:       1.39</span><br><span class="line"> Go version:        go1.10.8</span><br><span class="line"> Git commit:        481bc77</span><br><span class="line"> Built:             Sat May  4 02:35:57 2019</span><br><span class="line"> OS/Arch:           linux/amd64</span><br><span class="line"> Experimental:      <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">Server: Docker Engine - Community</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          18.09.6</span><br><span class="line">  API version:      1.39 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.10.8</span><br><span class="line">  Git commit:       481bc77</span><br><span class="line">  Built:            Sat May  4 01:59:36 2019</span><br><span class="line">  OS/Arch:          linux/amd64</span><br><span class="line">  Experimental:     <span class="literal">false</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>配置加速器<br>对于使用 systemd 的系统，请在 &#x2F;etc&#x2F;docker&#x2F;daemon.json 中写入如下内容（如果文件不存在请新建该文件）</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;registry-mirrors&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;https://registry.docker-cn.com&quot;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>验证加速器是否配置成功：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart docker</span><br><span class="line">docker info</span><br></pre></td></tr></table></figure><h1 id="出现如下语句即表示配置成功"><a href="#出现如下语句即表示配置成功" class="headerlink" title="出现如下语句即表示配置成功"></a>出现如下语句即表示配置成功</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Registry Mirrors:</span><br><span class="line"> https://registry.docker-cn.com/</span><br></pre></td></tr></table></figure><p>修改主机名</p><p>在同一局域网中主机名不应该相同，所以我们需要做修改，直接修改 &#x2F;etc&#x2F;hostname 里的名称即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim  /etc/hostname  </span><br><span class="line"><span class="comment">#kubernetes-master</span></span><br></pre></td></tr></table></figure><p>安装 kubeadm<br>kubeadm 是 kubernetes 的集群安装工具，能够快速安装 kubernetes 集群。</p><p>配置软件源</p><p>安装系统工具</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apt-get update &amp;&amp; apt-get install -y apt-transport-https</span><br><span class="line"><span class="comment"># 安装 GPG 证书</span></span><br><span class="line">curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -</span><br><span class="line"><span class="comment"># 写入软件源；注意：我们用系统代号为 bionic，但目前阿里云不支持，所以沿用 16.04 的 xenial</span></span><br><span class="line"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span></span><br><span class="line"><span class="string">&gt; deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main</span></span><br><span class="line"><span class="string">&gt; EOF</span></span><br></pre></td></tr></table></figure><p>安装 kubeadm，kubelet，kubectl<br>安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt-get update  </span><br><span class="line">apt-get install -y kubelet kubeadm kubectl</span><br></pre></td></tr></table></figure><p>安装过程如下，注意 kubeadm 的版本号</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">Reading package lists... Done</span><br><span class="line">Building dependency tree       </span><br><span class="line">Reading state information... Done</span><br><span class="line">The following additional packages will be installed:</span><br><span class="line">  conntrack cri-tools kubernetes-cni socat</span><br><span class="line">The following NEW packages will be installed:</span><br><span class="line">  conntrack cri-tools kubeadm kubectl kubelet kubernetes-cni socat</span><br><span class="line">0 upgraded, 7 newly installed, 0 to remove and 96 not upgraded.</span><br><span class="line">Need to get 50.6 MB of archives.</span><br><span class="line">After this operation, 290 MB of additional disk space will be used.</span><br><span class="line">Get:1 http://mirrors.aliyun.com/ubuntu bionic/main amd64 conntrack amd64 1:1.4.4+snapshot20161117-6ubuntu2 [30.6 kB]</span><br><span class="line">Get:2 http://mirrors.aliyun.com/ubuntu bionic/main amd64 socat amd64 1.7.3.2-2ubuntu2 [342 kB]</span><br><span class="line">Get:3 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 cri-tools amd64 1.12.0-00 [5,343 kB]</span><br><span class="line">Get:4 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubernetes-cni amd64 0.7.5-00 [6,473 kB]</span><br><span class="line">Get:5 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubelet amd64 1.14.1-00 [21.5 MB]</span><br><span class="line">Get:6 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubectl amd64 1.14.1-00 [8,806 kB]</span><br><span class="line">Get:7 https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 kubeadm amd64 1.14.1-00 [8,150 kB]</span><br><span class="line">Fetched 50.6 MB <span class="keyword">in</span> 5s (9,912 kB/s) </span><br><span class="line">Selecting previously unselected package conntrack.</span><br><span class="line">(Reading database ... 67205 files and directories currently installed.)</span><br><span class="line">Preparing to unpack .../0-conntrack_1%3a1.4.4+snapshot20161117-6ubuntu2_amd64.deb ...</span><br><span class="line">Unpacking conntrack (1:1.4.4+snapshot20161117-6ubuntu2) ...</span><br><span class="line">Selecting previously unselected package cri-tools.</span><br><span class="line">Preparing to unpack .../1-cri-tools_1.12.0-00_amd64.deb ...</span><br><span class="line">Unpacking cri-tools (1.12.0-00) ...</span><br><span class="line">Selecting previously unselected package kubernetes-cni.</span><br><span class="line">Preparing to unpack .../2-kubernetes-cni_0.7.5-00_amd64.deb ...</span><br><span class="line">Unpacking kubernetes-cni (0.7.5-00) ...</span><br><span class="line">Selecting previously unselected package socat.</span><br><span class="line">Preparing to unpack .../3-socat_1.7.3.2-2ubuntu2_amd64.deb ...</span><br><span class="line">Unpacking socat (1.7.3.2-2ubuntu2) ...</span><br><span class="line">Selecting previously unselected package kubelet.</span><br><span class="line">Preparing to unpack .../4-kubelet_1.14.1-00_amd64.deb ...</span><br><span class="line">Unpacking kubelet (1.14.1-00) ...</span><br><span class="line">Selecting previously unselected package kubectl.</span><br><span class="line">Preparing to unpack .../5-kubectl_1.14.1-00_amd64.deb ...</span><br><span class="line">Unpacking kubectl (1.14.1-00) ...</span><br><span class="line">Selecting previously unselected package kubeadm.</span><br><span class="line">Preparing to unpack .../6-kubeadm_1.14.1-00_amd64.deb ...</span><br><span class="line">Unpacking kubeadm (1.14.1-00) ...</span><br><span class="line">Setting up conntrack (1:1.4.4+snapshot20161117-6ubuntu2) ...</span><br><span class="line">Setting up kubernetes-cni (0.7.5-00) ...</span><br><span class="line">Setting up cri-tools (1.12.0-00) ...</span><br><span class="line">Setting up socat (1.7.3.2-2ubuntu2) ...</span><br><span class="line">Setting up kubelet (1.14.1-00) ...</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /lib/systemd/system/kubelet.service.</span><br><span class="line">Setting up kubectl (1.14.1-00) ...</span><br><span class="line">Processing triggers <span class="keyword">for</span> man-db (2.8.3-2ubuntu0.1) ...</span><br><span class="line"><span class="comment"># 注意这里的版本号，我们使用的是 kubernetes v1.14.1</span></span><br><span class="line">Setting up kubeadm (1.14.1-00) ...</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置 kubelet 自启动，并启动 kubelet</span></span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet &amp;&amp; systemctl start kubelet</span><br><span class="line">kubeadm：用于初始化 Kubernetes 集群</span><br><span class="line">kubectl：Kubernetes 的命令行工具，主要作用是部署和管理应用，查看各种资源，创建，删除和更新组件</span><br><span class="line">kubelet：主要负责启动 Pod 和容器</span><br><span class="line">配置 kubeadm</span><br><span class="line">安装 kubernetes 主要是安装它的各个镜像，而 kubeadm 已经为我们集成好了运行 kubernetes 所需的基本镜像。但由于国内的网络原因，在搭建环境时，无法拉取到这些镜像。此时我们只需要修改为阿里云提供的镜像服务即可解决该问题</span><br></pre></td></tr></table></figure><p>创建并修改配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config <span class="built_in">print</span> init-defaults --kubeconfig ClusterConfiguration &gt; kubeadm.yml</span><br></pre></td></tr></table></figure><p>修改配置内容# 修改配置为如下内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: kubeadm.k8s.io/v1beta1</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- <span class="built_in">groups</span>:</span><br><span class="line">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">  token: abcdef.0123456789abcdef</span><br><span class="line">  ttl: 24h0m0s</span><br><span class="line">  usages:</span><br><span class="line">  - signing</span><br><span class="line">  - authentication</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  <span class="comment"># 修改为主节点 IP</span></span><br><span class="line">  advertiseAddress: 192.168.141.130</span><br><span class="line">  bindPort: 6443</span><br><span class="line">nodeRegistration:</span><br><span class="line">  criSocket: /var/run/dockershim.sock</span><br><span class="line">  name: kubernetes-master</span><br><span class="line">  taints:</span><br><span class="line">  - effect: NoSchedule</span><br><span class="line">    key: node-role.kubernetes.io/master</span><br><span class="line">---</span><br><span class="line">apiServer:</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta1</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controlPlaneEndpoint: <span class="string">&quot;&quot;</span></span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns:</span><br><span class="line">  <span class="built_in">type</span>: CoreDNS</span><br><span class="line">etcd:</span><br><span class="line">  <span class="built_in">local</span>:</span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line"><span class="comment"># 国内不能访问 Google，修改为阿里云</span></span><br><span class="line">imageRepository: registry.aliyuncs.com/google_containers</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line"><span class="comment"># 修改版本号</span></span><br><span class="line">kubernetesVersion: v1.17.0</span><br><span class="line">networking:</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">  <span class="comment"># 配置成 Calico 的默认网段</span></span><br><span class="line">  podSubnet: <span class="string">&quot;192.168.0.0/16&quot;</span></span><br><span class="line">  serviceSubnet: 10.96.0.0/12</span><br><span class="line">scheduler: &#123;&#125;</span><br><span class="line">---</span><br><span class="line"><span class="comment"># 开启 IPVS 模式</span></span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">featureGates:</span><br><span class="line">  SupportIPVSProxyMode: <span class="literal">true</span></span><br><span class="line">mode: ipvs</span><br></pre></td></tr></table></figure><p>查看和拉取镜像</p><h1 id="查看所需镜像列表"><a href="#查看所需镜像列表" class="headerlink" title="查看所需镜像列表"></a>查看所需镜像列表</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config images list --config kubeadm.yml</span><br><span class="line"><span class="comment"># 拉取镜像</span></span><br><span class="line">kubeadm config images pull --config kubeadm.yml</span><br></pre></td></tr></table></figure><p>安装 kubernetes 主节点<br>执行以下命令初始化主节点，该命令指定了初始化时需要使用的配置文件，其中添加 –upload-certs 参数可以在后续执行加入节点时自动分发证书文件。追加的 tee kubeadm-init.log 用以输出日志。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --config=kubeadm.yml --experimental-upload-certs | <span class="built_in">tee</span> kubeadm-init.log</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#your configuration file uses a deprecated API spec: &quot;kubeadm.k8s.io/v1beta1&quot;. Please use &#x27;kubeadm config migrate --old-config old.yaml --new-config new.yaml&#x27;, which will write the new, similar spec using a newer API version.</span></span><br><span class="line">W0106 17:26:39.941946   25748 common.go:77] your configuration file uses a deprecated API spec: <span class="string">&quot;kubeadm.k8s.io/v1beta1&quot;</span>. Please use <span class="string">&#x27;kubeadm config migrate --old-config old.yaml --new-config new.yaml&#x27;</span>, <span class="built_in">which</span> will write the new, similar spec using a newer API version.</span><br><span class="line">W0106 17:26:39.944487   25748 validation.go:28] Cannot validate kube-proxy config - no validator is available</span><br><span class="line">W0106 17:26:39.944533   25748 validation.go:28] Cannot validate kubelet config - no validator is available</span><br><span class="line">[init] Using Kubernetes version: v1.17.0</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[WARNING IsDockerSystemdCheck]: detected <span class="string">&quot;cgroupfs&quot;</span> as the Docker cgroup driver. The recommended driver is <span class="string">&quot;systemd&quot;</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br><span class="line">[preflight] Pulling images required <span class="keyword">for</span> setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action <span class="keyword">in</span> beforehand using <span class="string">&#x27;kubeadm config images pull&#x27;</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span></span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">&quot;/var/lib/kubelet/config.yaml&quot;</span></span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[certs] Using certificateDir folder <span class="string">&quot;/etc/kubernetes/pki&quot;</span></span><br><span class="line">[certs] Generating <span class="string">&quot;ca&quot;</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">&quot;apiserver&quot;</span> certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed <span class="keyword">for</span> DNS names [kubernetes-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.62.159]</span><br><span class="line">[certs] Generating <span class="string">&quot;apiserver-kubelet-client&quot;</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">&quot;front-proxy-ca&quot;</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">&quot;front-proxy-client&quot;</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">&quot;etcd/ca&quot;</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">&quot;etcd/server&quot;</span> certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed <span class="keyword">for</span> DNS names [kubernetes-master localhost] and IPs [192.168.62.159 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating <span class="string">&quot;etcd/peer&quot;</span> certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed <span class="keyword">for</span> DNS names [kubernetes-master localhost] and IPs [192.168.62.159 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating <span class="string">&quot;etcd/healthcheck-client&quot;</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">&quot;apiserver-etcd-client&quot;</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">&quot;sa&quot;</span> key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder <span class="string">&quot;/etc/kubernetes&quot;</span></span><br><span class="line">[kubeconfig] Writing <span class="string">&quot;admin.conf&quot;</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">&quot;kubelet.conf&quot;</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">&quot;controller-manager.conf&quot;</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">&quot;scheduler.conf&quot;</span> kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder <span class="string">&quot;/etc/kubernetes/manifests&quot;</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">&quot;kube-apiserver&quot;</span></span><br><span class="line">W0106 17:26:44.531537   25748 manifests.go:214] the default kube-apiserver authorization-mode is <span class="string">&quot;Node,RBAC&quot;</span>; using <span class="string">&quot;Node,RBAC&quot;</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">&quot;kube-controller-manager&quot;</span></span><br><span class="line">W0106 17:26:44.532749   25748 manifests.go:214] the default kube-apiserver authorization-mode is <span class="string">&quot;Node,RBAC&quot;</span>; using <span class="string">&quot;Node,RBAC&quot;</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">&quot;kube-scheduler&quot;</span></span><br><span class="line">[etcd] Creating static Pod manifest <span class="keyword">for</span> <span class="built_in">local</span> etcd <span class="keyword">in</span> <span class="string">&quot;/etc/kubernetes/manifests&quot;</span></span><br><span class="line">[wait-control-plane] Waiting <span class="keyword">for</span> the kubelet to boot up the control plane as static Pods from directory <span class="string">&quot;/etc/kubernetes/manifests&quot;</span>. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 24.504808 seconds</span><br><span class="line">[upload-config] Storing the configuration used <span class="keyword">in</span> ConfigMap <span class="string">&quot;kubeadm-config&quot;</span> <span class="keyword">in</span> the <span class="string">&quot;kube-system&quot;</span> Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap <span class="string">&quot;kubelet-config-1.17&quot;</span> <span class="keyword">in</span> namespace kube-system with the configuration <span class="keyword">for</span> the kubelets <span class="keyword">in</span> the cluster</span><br><span class="line">[upload-certs] Storing the certificates <span class="keyword">in</span> Secret <span class="string">&quot;kubeadm-certs&quot;</span> <span class="keyword">in</span> the <span class="string">&quot;kube-system&quot;</span> Namespace</span><br><span class="line">[upload-certs] Using certificate key:</span><br><span class="line">781e69718ac47389e4e65f025cb9cb842ae621f495323b08f8c3cc5fe69c5a82</span><br><span class="line">[mark-control-plane] Marking the node kubernetes-master as control-plane by adding the label <span class="string">&quot;node-role.kubernetes.io/master=&#x27;&#x27;&quot;</span></span><br><span class="line">[mark-control-plane] Marking the node kubernetes-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: abcdef.0123456789abcdef</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs <span class="keyword">in</span> order <span class="keyword">for</span> nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation <span class="keyword">for</span> all node client certificates <span class="keyword">in</span> the cluster</span><br><span class="line">[bootstrap-token] Creating the <span class="string">&quot;cluster-info&quot;</span> ConfigMap <span class="keyword">in</span> the <span class="string">&quot;kube-public&quot;</span> namespace</span><br><span class="line">[kubelet-finalize] Updating <span class="string">&quot;/etc/kubernetes/kubelet.conf&quot;</span> to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  <span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">&quot;kubectl apply -f [podnetwork].yaml&quot;</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br></pre></td></tr></table></figure><p>Then you can join any number of worker nodes by running the following on each as root:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm <span class="built_in">join</span> 192.168.62.159:6443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:7237dd082021214d77c1d99f0cdc2a1a110c33ba94c5e2df699ea3cebbab1ea4 </span><br></pre></td></tr></table></figure><p>注意：如果安装 kubernetes 版本和下载的镜像版本不统一则会出现 timed out waiting for the condition 错误。中途失败或是想修改配置可以使用 kubeadm reset 命令重置配置，再做初始化操作即可。</p><p>配置 kubectl</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config(非root才做)</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get node</span><br></pre></td></tr></table></figure><p>至此主节点配置完成</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init 的执行过程</span><br><span class="line">init：指定版本进行初始化操作</span><br><span class="line">preflight：初始化前的检查和下载所需要的 Docker 镜像文件</span><br><span class="line">kubelet-start：生成 kubelet 的配置文件 var/lib/kubelet/config.yaml，没有这个文件 kubelet 无法启动，所以初始化之前的 - kubelet 实际上启动不会成功</span><br><span class="line">certificates：生成 Kubernetes 使用的证书，存放在 /etc/kubernetes/pki 目录中</span><br><span class="line">kubeconfig：生成 KubeConfig 文件，存放在 /etc/kubernetes 目录中，组件之间通信需要使用对应文件</span><br><span class="line">control-plane：使用 /etc/kubernetes/manifest 目录下的 YAML 文件，安装 Master 组件</span><br><span class="line">etcd：使用 /etc/kubernetes/manifest/etcd.yaml 安装 Etcd 服务</span><br><span class="line">wait-control-plane：等待 control-plan 部署的 Master 组件启动</span><br><span class="line">apiclient：检查 Master 组件服务状态。</span><br><span class="line">uploadconfig：更新配置</span><br><span class="line">kubelet：使用 configMap 配置 kubelet</span><br><span class="line">patchnode：更新 CNI 信息到 Node 上，通过注释的方式记录</span><br><span class="line">mark-control-plane：为当前节点打标签，打了角色 Master，和不可调度标签，这样默认就不会使用 Master 节点来运行 Pod</span><br><span class="line">bootstrap-token：生成 token 记录下来，后边使用 kubeadm <span class="built_in">join</span> 往集群中添加节点时会用到</span><br><span class="line">addons：安装附加组件 CoreDNS 和 kube-proxy</span><br></pre></td></tr></table></figure><p>使用 kubeadm 配置 slave 节点<br>将 slave 节点加入到集群中很简单，只需要在 slave 服务器上安装 kubeadm，kubectl，kubelet 三个工具，然后使用 kubeadm join 命令加入即可。准备工作如下：</p><p>修改主机名<br>配置软件源<br>安装三个工具</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm <span class="built_in">join</span> 192.168.62.159:6443 --token abcdef.0123456789abcdef   --discovery-token-ca-cert-hash sha256:7237dd082021214d77c1d99f0cdc2a1a110c33ba94c5e2df699ea3cebbab1ea4 </span><br></pre></td></tr></table></figure><p>说明：</p><p>token<br>可以通过安装 master 时的日志查看 token 信息<br>可以通过 kubeadm token list 命令打印出 token 信息<br>如果 token 过期，可以使用 kubeadm token create 命令创建新的 token<br>discovery-token-ca-cert-hash<br>可以通过安装 master 时的日志查看 sha256 信息<br>可以通过</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl x509 -pubkey -<span class="keyword">in</span> /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed <span class="string">&#x27;s/^.* //&#x27;</span> </span><br></pre></td></tr></table></figure><p>命令查看 sha256 信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line">kubectl get pod -n kube-system -o wide</span><br></pre></td></tr></table></figure><p>配置网络<br>容器网络是容器选择连接到其他容器、主机和外部网络的机制。容器的 runtime 提供了各种网络模式，每种模式都会产生不同的体验。例如，Docker 默认情况下可以为容器配置以下网络：</p><p>none： 将容器添加到一个容器专门的网络堆栈中，没有对外连接。<br>host： 将容器添加到主机的网络堆栈中，没有隔离。<br>default bridge： 默认网络模式。每个容器可以通过 IP 地址相互连接。<br>自定义网桥： 用户定义的网桥，具有更多的灵活性、隔离性和其他便利功能。</p><p>什么是 CNI<br>CNI(Container Network Interface) 是一个标准的，通用的接口。在容器平台，Docker，Kubernetes，Mesos 容器网络解决方案 flannel，calico，weave。只要提供一个标准的接口，就能为同样满足该协议的所有容器平台提供网络功能，而 CNI 正是这样的一个标准接口协议。</p><p>Kubernetes 中的 CNI 插件<br>CNI 的初衷是创建一个框架，用于在配置或销毁容器时动态配置适当的网络配置和资源。插件负责为接口配置和管理 IP 地址，并且通常提供与 IP 管理、每个容器的 IP 分配、以及多主机连接相关的功能。容器运行时会调用网络插件，从而在容器启动时分配 IP 地址并配置网络，并在删除容器时再次调用它以清理这些资源。</p><p>运行时或协调器决定了容器应该加入哪个网络以及它需要调用哪个插件。然后，插件会将接口添加到容器网络命名空间中，作为一个 veth 对的一侧。接着，它会在主机上进行更改，包括将 veth 的其他部分连接到网桥。再之后，它会通过调用单独的 IPAM（IP地址管理）插件来分配 IP 地址并设置路由。</p><p>在 Kubernetes 中，kubelet 可以在适当的时间调用它找到的插件，为通过 kubelet 启动的 pod进行自动的网络配置。</p><p>Kubernetes 中可选的 CNI 插件如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Flannel</span><br><span class="line">Calico</span><br><span class="line">Canal</span><br><span class="line">Weave-</span><br></pre></td></tr></table></figure><p>什么是 Calico<br>Calico 为容器和虚拟机提供了安全的网络连接解决方案，并经过了大规模生产验证（在公有云和跨数千个集群节点中），可与 Kubernetes，OpenShift，Docker，Mesos，DC &#x2F; OS 和 OpenStack 集成。</p><p>Calico 还提供网络安全规则的动态实施。使用 Calico 的简单策略语言，您可以实现对容器，虚拟机工作负载和裸机主机端点之间通信的细粒度控制。</p><p>安装网络插件 Calico<br>参考官方文档安装：<a href="https://docs.projectcalico.org/v3.7/getting-started/kubernetes/">https://docs.projectcalico.org/v3.7/getting-started/kubernetes/</a></p><p>在 Master 节点操作即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://docs.projectcalico.org/v3.11/manifests/calico.yaml</span><br></pre></td></tr></table></figure><p>安装时显示如下输出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">configmap/calico-config created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/calico-node created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/calico-node created</span><br><span class="line">daemonset.extensions/calico-node created</span><br><span class="line">serviceaccount/calico-node created</span><br><span class="line">deployment.extensions/calico-kube-controllers created</span><br><span class="line">```serviceaccount/calico-kube-controllers created</span><br></pre></td></tr></table></figure><h3 id="确认安装是否成功"><a href="#确认安装是否成功" class="headerlink" title="确认安装是否成功"></a>确认安装是否成功</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">watch kubectl get pods --all-namespaces</span><br></pre></td></tr></table></figure><p>需要等待所有状态为 Running，注意时间可能较久，3 - 5 分钟的样子</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">2.0s: kubectl get pods –all-namespaces kubernetes-master: Fri May 10 18:16:51 2019</span><br><span class="line">NAMESPACE NAME READY STATUS RESTARTS AGE</span><br><span class="line">kube-system calico-kube-controllers-8646dd497f-g2lln 1/1 Running 0 50m</span><br><span class="line">kube-system calico-node-8jrtp 1/1 Running 0 50m</span><br><span class="line">kube-system coredns-8686dcc4fd-mhwfn 1/1 Running 0 51m</span><br><span class="line">kube-system coredns-8686dcc4fd-xsxwk 1/1 Running 0 51m</span><br><span class="line">kube-system etcd-kubernetes-master 1/1 Running 0 50m</span><br><span class="line">kube-system kube-apiserver-kubernetes-master 1/1 Running 0 51m</span><br><span class="line">kube-system kube-controller-manager-kubernetes-master 1/1 Running 0 51m</span><br><span class="line">kube-system kube-proxy-p8mdw 1/1 Running 0 51m</span><br><span class="line">kube-system kube-scheduler-kubernetes-master</span><br></pre></td></tr></table></figure><p>解决 ImagePullBackOff<br>在使用 watch kubectl get pods –all-namespaces 命令观察 Pods 状态时如果出现 ImagePullBackOff 无法 Running 的情况，请尝试使用如下步骤处理：</p><p>Master 中删除 Nodes：kubectl delete nodes<br>Slave 中重置配置：kubeadm reset<br>Slave 重启计算机：reboot<br>Slave 重新加入集群：kubeadm join<br>完成搭建</p><p>检查组件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">kubectl get cs</span><br><span class="line">输出如下</span><br><span class="line">NAME STATUS MESSAGE ERROR</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">调度服务，主要作用是将 POD 调度到 Node</span><br><span class="line">scheduler Healthy ok</span><br><span class="line"></span><br><span class="line">自动化修复服务，主要作用是 Node 宕机后自动修复 Node 回到正常的工作状态</span><br><span class="line">controller-manager Healthy ok</span><br><span class="line"></span><br><span class="line">服务注册与发现</span><br><span class="line">etcd-0 Healthy &#123;“health”:”<span class="literal">true</span>”&#125;</span><br><span class="line">检查 Master 状态</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl cluster-info</span><br><span class="line"><span class="comment">#输出如下</span></span><br><span class="line">Kubernetes master is running at https://192.168.62.159:6443</span><br><span class="line">KubeDNS is running at https://192.168.62.159:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span><br><span class="line">To further debug and diagnose cluster problems, use ‘kubectl cluster-info dump’.</span><br></pre></td></tr></table></figure><p>运行第一个容器实例</p><p>使用 kubectl 命令创建两个监听 80 端口的 Nginx Pod（Kubernetes 运行容器的最小单元）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl run nginx --image=nginx --replicas=2 --port=80</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed <span class="keyword">in</span> a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.</span><br><span class="line">deployment.apps/nginx created</span><br></pre></td></tr></table></figure><p>查看全部 Pods 的状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">nginx-5578584966-f7vl5   0/1     ContainerCreating   0          55s</span><br><span class="line">nginx-5578584966-p9s24   0/1     ContainerCreating   0          55s</span><br><span class="line">nginx-5578584966-f7vl5   1/1     Running   0          18m</span><br><span class="line">nginx-5578584966-p9s24   1/1     Running   0          18m</span><br><span class="line">查看已部署的服务</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">kubectl get deployment</span><br><span class="line">输出如下</span><br><span class="line">NAME READY UP-TO-DATE AVAILABLE AGE</span><br><span class="line">nginx 2/2 2 2 91m</span><br></pre></td></tr></table></figure><p>映射服务，让用户可以访问</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment nginx –port=80 –<span class="built_in">type</span>=LoadBalancer</span><br></pre></td></tr></table></figure><p>输出如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service/nginx exposed</span><br></pre></td></tr></table></figure><p>查看已发布的服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl get services</span><br><span class="line">NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE</span><br><span class="line">kubernetes ClusterIP 10.96.0.1 443/TCP 21h</span><br><span class="line">nginx LoadBalancer 10.96.133.79 80:31091/TCP 13m</span><br></pre></td></tr></table></figure><p>查看服务详情</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe service nginx</span><br><span class="line"></span><br><span class="line">Name: nginx</span><br><span class="line">Namespace: default</span><br><span class="line">Labels: run=nginx</span><br><span class="line">Annotations:</span><br><span class="line">Selector: run=nginx</span><br><span class="line">Type: LoadBalancer</span><br><span class="line">IP: 10.96.133.79</span><br><span class="line">Port: 80/TCP</span><br><span class="line">TargetPort: 80/TCP</span><br><span class="line">NodePort: 31091/TCP</span><br><span class="line">Endpoints: 192.168.17.1:80,192.168.8.130:80</span><br><span class="line">Session Affinity: None</span><br><span class="line">External Traffic Policy: Cluster</span><br><span class="line">Events:</span><br></pre></td></tr></table></figure><p>验证是否成功 通过浏览器访问 Master 服务器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.62.159:30830/</span><br></pre></td></tr></table></figure><p>停止服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete deployment nginx</span><br></pre></td></tr></table></figure><p>输出如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">deployment.extensions “nginx” deleted</span><br><span class="line">kubectl delete service nginx</span><br></pre></td></tr></table></figure><p>输出如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service “nginx” deleted</span><br></pre></td></tr></table></figure><p>结尾<br>目前是已经把K8s集群搭建完成了 并且我们用它部署了nginx,先到这里把</p><p>节点： Kubernetes 集群中的服务器<br>集群： Kubernetes 管理的一组服务器集合<br>边界路由器： 为局域网和 Internet 路由数据包的路由器，执行防火墙保护局域网络<br>集群网络： 遵循 Kubernetes 网络模型实现集群内的通信的具体实现，比如 Flannel 和 Calico<br>服务： Kubernetes 的服务 (Service) 是使用标签选择器标识的一组 Pod Service (Deployment)。<br>除非另有说明，否则服务的虚拟 IP 仅可在集群内部访问<br>内部访问方式 ClusterIP<br>ClusterIP 服务是 Kubernetes 的默认服务。它给你一个集群内的服务，集群内的其它应用都可以访问该服务。集群外部无法访问它。在某些场景下我们可以使用 Kubernetes 的 Proxy 模式来访问服务，比如调试服务时</p><p>这种访问方式，只能是在Service的内部访问。</p><p>三种外部访问方式<br>NodePort<br>NodePort 服务是引导外部流量到你的服务的最原始方式。NodePort，正如这个名字所示，在所有节点（虚拟机）上开放一个特定端口，任何发送到该端口的流量都被转发到对应服务。</p><p>NodePort 服务特征如下：</p><p>每个端口只能是一种服务<br>端口范围只能是 30000-32767（可调）<br>不在 YAML 配置文件中指定则会分配一个默认端口 </p><p>建议： 不要在生产环境中使用这种方式暴露服务，大多数时候我们应该让 Kubernetes 来选择端口<br>它这种模式就是我们第一次部署的那种模式，每个Node节点都可以通过这个ip+端口来访问这个服务</p><h3 id="LoadBalancer"><a href="#LoadBalancer" class="headerlink" title="LoadBalancer"></a>LoadBalancer</h3><p>LoadBalancer 服务是暴露服务到 Internet 的标准方式。所有通往你指定的端口的流量都会被转发到对应的服务。它没有过滤条件，没有路由等。这意味着你几乎可以发送任何种类的流量到该服务，像 HTTP，TCP，UDP，WebSocket，gRPC 或其它任意种类。</p><p>Ingress<br>Ingress 事实上不是一种服务类型。相反，它处于多个服务的前端，扮演着 “智能路由” 或者集群入口的角色。你可以用 Ingress 来做许多不同的事情，各种不同类型的 Ingress 控制器也有不同的能力。它允许你基于路径或者子域名来路由流量到后端服务。</p><p>Ingress 可能是暴露服务的最强大方式，但同时也是最复杂的。Ingress 控制器有各种类型，包括 Google Cloud Load Balancer， Nginx，Contour，Istio，等等。它还有各种插件，比如 cert-manager (它可以为你的服务自动提供 SSL 证书)&#x2F;</p><p>如果你想要使用同一个 IP 暴露多个服务，这些服务都是使用相同的七层协议（典型如 HTTP），你还可以获取各种开箱即用的特性（比如 SSL、认证、路由等等）</p><h3 id="什么是-Ingress"><a href="#什么是-Ingress" class="headerlink" title="什么是 Ingress"></a>什么是 Ingress</h3><p>通常情况下，Service 和 Pod 的 IP 仅可在集群内部访问。集群外部的请求需要通过负载均衡转发到 Service 在 Node 上暴露的 NodePort 上，然后再由 kube-proxy 通过边缘路由器 (edge router) 将其转发给相关的 Pod 或者丢弃。而 Ingress 就是为进入集群的请求提供路由规则的集合</p><p>Ingress 可以给 Service 提供集群外部访问的 URL、负载均衡、SSL 终止、HTTP 路由等。为了配置这些 Ingress 规则，集群管理员需要部署一个 Ingress Controller，它监听 Ingress 和 Service 的变化，并根据规则配置负载均衡并提供访问入口</p><p>使用 Nginx Ingress Controller<br>本次实践的主要目的就是将入口统一，不再通过 LoadBalancer 等方式将端口暴露出来，而是使用 Ingress 提供的反向代理负载均衡功能作为我们的唯一入口。通过以下步骤操作仔细体会。</p><h3 id="部署-Tomcat"><a href="#部署-Tomcat" class="headerlink" title="部署 Tomcat"></a>部署 Tomcat</h3><p>部署 Tomcat 但仅允许在内网访问，我们要通过 Ingress 提供的反向代理功能路由到 Tomcat 之上</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">apiVersion:  apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: tomcat-app</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: tomcat</span><br><span class="line">  replicas: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: tomcat</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: tomcat</span><br><span class="line">        image: tomcat</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: tomcat-http</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 8080</span><br><span class="line">      targetPort: 8080</span><br><span class="line">  <span class="comment"># ClusterIP, NodePort, LoadBalancer</span></span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">  selector:</span><br><span class="line">    app: tomcat</span><br></pre></td></tr></table></figure><p>安装 Nginx Ingress Controller<br>Ingress Controller 有许多种，我们选择最熟悉的 Nginx 来处理请求，其它可以参考官方文档</p><p>下载 Nginx Ingress Controller 配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml</span><br></pre></td></tr></table></figure><p>修改配置文件，找到配置如下位置 (搜索 serviceAccountName) 在下面增加一句 hostNetwork: true</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-ingress-controller</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># 可以部署多个实例</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">ingress-nginx</span></span><br><span class="line">      <span class="attr">annotations:</span></span><br><span class="line">        <span class="attr">prometheus.io/port:</span> <span class="string">&quot;10254&quot;</span></span><br><span class="line">        <span class="attr">prometheus.io/scrape:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">nginx-ingress-serviceaccount</span></span><br><span class="line">      <span class="comment"># 增加 hostNetwork: true，意思是开启主机网络模式，暴露 Nginx 服务端口 80</span></span><br><span class="line">      <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-ingress-controller</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.24.1</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">/nginx-ingress-controller</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--configmap=$(POD_NAMESPACE)/nginx-configuration</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--tcp-services-configmap=$(POD_NAMESPACE)/tcp-services</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--udp-services-configmap=$(POD_NAMESPACE)/udp-services</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--publish-service=$(POD_NAMESPACE)/ingress-nginx</span></span><br><span class="line"><span class="string">//</span> <span class="string">以下代码省略...</span></span><br></pre></td></tr></table></figure><h3 id="部署-Ingress"><a href="#部署-Ingress" class="headerlink" title="部署 Ingress"></a>部署 Ingress</h3><p>Ingress 翻译过来是入口的意思，说白了就是个 API 网关（想想 Zuul 和 Spring Cloud Gateway）</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-web</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="comment"># 指定 Ingress Controller 的类型</span></span><br><span class="line">    <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">&quot;nginx&quot;</span></span><br><span class="line">    <span class="comment"># 指定我们的 rules 的 path 可以使用正则表达式</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/use-regex:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="comment"># 连接超时时间，默认为 5s</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/proxy-connect-timeout:</span> <span class="string">&quot;600&quot;</span></span><br><span class="line">    <span class="comment"># 后端服务器回转数据超时时间，默认为 60s</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/proxy-send-timeout:</span> <span class="string">&quot;600&quot;</span></span><br><span class="line">    <span class="comment"># 后端服务器响应超时时间，默认为 60s</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/proxy-read-timeout:</span> <span class="string">&quot;600&quot;</span></span><br><span class="line">    <span class="comment"># 客户端上传文件，最大大小，默认为 20m</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/proxy-body-size:</span> <span class="string">&quot;10m&quot;</span></span><br><span class="line">    <span class="comment"># URL 重写</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/rewrite-target:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># 路由规则</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="comment"># 主机名，只能是域名，修改为你自己的</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">k8s.test.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="comment"># 后台部署的 Service Name，与上面部署的 Tomcat 对应</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">tomcat-http</span></span><br><span class="line">          <span class="comment"># 后台部署的 Service Port，与上面部署的 Tomcat 对应</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">8080</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>验证是否成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deployment</span><br></pre></td></tr></table></figure><h1 id="输出如下"><a href="#输出如下" class="headerlink" title="输出如下"></a>输出如下</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME         READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">tomcat-app   2/2     2            2           88m</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get service</span><br></pre></td></tr></table></figure><h1 id="输出如下-1"><a href="#输出如下-1" class="headerlink" title="输出如下"></a>输出如下</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">kubernetes    ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    2d5h</span><br><span class="line">tomcat-http   ClusterIP   10.97.222.179   &lt;none&gt;        8080/TCP   89m</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="查看-Nginx-Ingress-Controller"><a href="#查看-Nginx-Ingress-Controller" class="headerlink" title="查看 Nginx Ingress Controller"></a>查看 Nginx Ingress Controller</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -n ingress-nginx -o wide</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出如下，注意下面的 IP 地址，就是我们实际访问地址</span></span><br><span class="line">NAME                                        READY   STATUS    RESTARTS   AGE   IP                NODE                 NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-ingress-controller-76f9fddcf8-vzkm5   1/1     Running   0          61m   192.168.141.160   kubernetes-node-01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">kubectl get ingress</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出如下</span></span><br><span class="line">NAME        HOSTS          ADDRESS   PORTS   AGE</span><br><span class="line">nginx-web   k8s.test.com             80      61m</span><br></pre></td></tr></table></figure><p>测试访问<br>成功代理到 Tomcat 即表示成功</p>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图数据库对比</title>
      <link href="/2020/08/16/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E6%AF%94/"/>
      <url>/2020/08/16/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E6%AF%94/</url>
      
        <content type="html"><![CDATA[<p><span class="post-count">&lt;%&#x3D; wordcount(post.content) %&gt;</span><br><span class="post-count">&lt;%&#x3D; min2read(post.content) %&gt;</span><br><span class="post-count">&lt;%&#x3D; totalcount(site) %&gt;</span></p><h4 id="图数据库的对比"><a href="#图数据库的对比" class="headerlink" title="图数据库的对比"></a>图数据库的对比</h4><table><thead><tr><th>图数据库</th><th>是否分布式</th><th>开发语言</th><th>支持的节点数量</th><th>原生图存储</th><th align="left">multi_model</th><th>查询语言</th><th>支持开发的语言</th><th>开发公司</th><th>落地的公司</th><th>是否开源</th><th>使用场景</th><th>开源地址</th><th>文档地址</th><th></th></tr></thead><tbody><tr><td>neo4j</td><td>社区单机版&#x2F;商业是伪分布式</td><td>java</td><td>百亿</td><td>是</td><td align="left">否</td><td>cypher</td><td>java&#x2F;python</td><td>neo4j</td><td>使用非常广泛</td><td>否</td><td>OLAP</td><td></td><td></td><td></td></tr><tr><td>nebula graph</td><td>分布式</td><td>java</td><td>千亿个</td><td>是</td><td align="left">否</td><td>nsql</td><td>java</td><td></td><td>京东 &#x2F;360&#x2F;携程&#x2F;oppo&#x2F;各种银行</td><td></td><td>OLAP</td><td><a href="https://github.com/vesoft-inc/nebula-graph">https://github.com/vesoft-inc/nebula-graph</a></td><td></td><td></td></tr><tr><td>ultipa</td><td>分布式</td><td></td><td></td><td>是</td><td align="left">否</td><td></td><td></td><td>北京同心尚科技发展有限公司</td><td>金融行业</td><td>否</td><td>HTAP</td><td></td><td></td><td></td></tr><tr><td>janusgraph</td><td>分布式</td><td>java</td><td></td><td>否</td><td align="left">是</td><td>gremlin</td><td>java</td><td>The Linux Foundation</td><td>apache顶级项目</td><td>是</td><td>OLAP</td><td><a href="https://github.com/JanusGraph/janusgraph">https://github.com/JanusGraph/janusgraph</a></td><td><a href="https://docs.janusgraph.org/">https://docs.janusgraph.org/</a></td><td></td></tr><tr><td>hugegraph</td><td>分布式</td><td>java</td><td></td><td>否</td><td align="left">是</td><td>gremlin</td><td>java</td><td>百度</td><td>百度</td><td>是</td><td>OLAP</td><td><a href="https://github.com/hugegraph/hugegraph">https://github.com/hugegraph/hugegraph</a></td><td></td><td></td></tr><tr><td>tugraph</td><td>分布式</td><td>C++</td><td></td><td>是</td><td align="left">否</td><td>cypher</td><td>C++</td><td>费马科技</td><td>京东金融、  搜狗 、国家电网</td><td>否</td><td>OLAP</td><td>wget <a href="https://fma-ai.cn/download/lgraph_latest.tar">https://fma-ai.cn/download/lgraph_latest.tar</a></td><td><a href="https://fma-ai.cn/help/">https://fma-ai.cn/help/</a></td><td></td></tr><tr><td>tigergraph</td><td>单机开发&#x2F;商业是分布式</td><td>C++</td><td>万亿</td><td>是</td><td align="left">否</td><td>GSQL</td><td></td><td>tighergraph</td><td>国家电网、国有银行</td><td>否</td><td>OLTP</td><td></td><td><a href="https://www.tigergraph.com.cn/">https://www.tigergraph.com.cn/</a></td><td></td></tr><tr><td>geagraph</td><td></td><td></td><td></td><td></td><td align="left"></td><td></td><td></td><td></td><td></td><td>否</td><td></td><td></td><td></td><td></td></tr></tbody></table><h4 id="JanusGraph"><a href="#JanusGraph" class="headerlink" title="JanusGraph"></a>JanusGraph</h4><p>JanusGraph是一个可扩展的图数据库，可以把包含数千亿个顶点和边的图存储在多机集群上。它支持事务，支持数千用户实时、并发访问存储在其中的图。</p><p>anusGraph是2016年12月27日从Titan fork出来的一个分支<br>(1)分布式部署，因此，支持集群。<br>(2)可以存储大图，比如包含数千亿Vertices和edges的图。<br>(3)支持数千用户实时、并发访问。（并发访问肯定是实时的，这个唉，没必要强调好像）<br>(4)集群节点可以线性扩展，以支持更大的图和更多的并发访问用户。（Elastic and linear scalability for a growing data and user base）<br>(5)数据分布式存储，并且每一份数据都有多个副本，因此，有更好的计算性能和容错性。（Data distribution and replication for performance and fault tolerance）<br>(6)支持在多个数据中心做高可用，支持热备份。（Elastic and linear scalability for a growing data and user base）<br>(7)支持各种后端存储系统，目前标准支持以下四种，当然也可以增加第三方的存储系统：<br>Apache Cassandra®<br>Apache HBase®<br>Google Cloud Bigtable<br>Oracle BerkeleyDB<br>(8)通过集成大数据平台，比如Apache Spark、Apache Giraph、Apache Hadoop等，支持全局图数据分析、报表、ETL<br>(9)支持geo（Gene Expression Omnibus，基因数据分析）、numeric range（这个的含义不清楚）<br>(10)集成ElasticSearch、Apache Solr、Apache Lucene等系统后，可以支持全文搜索。<br>(11) 原生集成Apache TinkerPop图技术栈，包括Gremlin graph query language、Gremlin graph server、Gremin applications。<br>(12)开源，基于Apache 2 Licence。<br>(13)通过使用以下系统可以可视化存储在JanusGraph中的图数据：<br>Cytoscape<br>Gephi plugin for Apache TinkerPop<br>Graphexp<br>KeyLines by Cambridge Intelligence<br>Linkurious</p><p><img src="https://images2018.cnblogs.com/blog/513451/201805/513451-20180531112615520-1894246489.png" alt="avatar"></p><p>java语言开发，不支持python语言</p><ol><li><strong>性能</strong> 要求图查询及图分析算法的执行快，涉及到底层存储结构，原生图存储基于点和边，计算中不需要过多的逻辑和物理层转换。原生图存储(neo4j&#x2F;tigergraph)胜</li><li><strong>容量</strong> 大数据时代可获取的数据越来越多，单机的容量有限。原生图存储如何实现分布式存储是困难所在。TigerGraph自称是原生并行图；neo4j支持数据的高可用HA集群，但非分布式存储;JanusGraph利用HBase等NoSQL作为后端存储，在存储层面算是分布式的，容量可以很大。百度基于JanusGraph开源了HugeGraph，增加了很多特性，提高了易用性及性能，增加了一些图分析算法。</li><li><strong>查询能力</strong> 图数据库要具备点关系的查询能力，必不可少的如两点间所有路径，最短路径，多度查询等，这个一般都具备，差异主要是性能，普通图数据库查询3度及以上通常性能就很低了，而实际经常需要查询6度的关系，tigergraph自己的测试报告性能是很强劲的针对twitter的大图数据库，只有tigergraph完成了6度关系查询</li><li><strong>图分析计算能力</strong> 图数据库如果仅具备存储及查询能力，则还需要依赖外部的GraphX等计算引擎才能完成一些图算法分析，这样即在数据传输，又在图表达上存在转换浪费。TigerGraph可以通过GSQL实现类存储过程式的算法封装，且已实现了很多图算法<a href="https://link.zhihu.com/?target=https://www.tigergraph.com.cn/tigergraph%E5%BC%80%E6%BA%90%E5%8D%81%E5%A4%A7%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%97%E6%B3%95%E5%BA%93/">https://www.tigergraph.com.cn/tigergraph开源十大图数据库算法库/</a></li></ol><p>百度基于JanusGraph开源了HugeGraph，增加了很多特性，提高了易用性及性能，增加了一些图分析算法。</p><p><strong>JanusGraph&#x2F;HugeGraph</strong>是开源的，Apache协议，开放性最好</p><p><strong>neo4j</strong>社区版开源，非商用免费，商业版支持HA集群，并不是完全分布式，使用最广最流行</p><p><strong>TigerGraph</strong>将普通数据库归为第一第二代，自己为第三代，“TigerGraph是非常完备和优化的图数据库平台，支持大规模图存储以及大规模图的运行处理，具有非常强大的查询语言和算法库”。TigerGraph没有开源，<strong>开发者版支持单机单用户单图非商业免费，不支持DynamicSchemaChange等</strong>，图创建好之后也能通过界面手工去修改或添加，除非DropAll。TG的GSQL是类sql的语言，表达能力挺强，其将编写的query直接安装发布为restapi的形式让我感到很惊艳。目前TigerGraph的生态不是很全，编程api等能力也有一定限制，但值得尝试</p><p><img src="https://pic3.zhimg.com/v2-5abbeda0fb296d05d1516fcda2d3592e_r.jpg" alt="preview"></p><p>![image-20211109160429069](&#x2F;Users&#x2F;andrew&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20211109160429069.png)</p><p>geagraph 阿里联合清华发布，没有开源</p><p><img src="https://pic2.zhimg.com/v2-2ce2bd623678dd5dbd42933d49b2d321_r.jpg" alt="preview"></p><p>janusgraph</p><p><img src="https://img-blog.csdnimg.cn/20190123101621250.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pZQzg4ODg4,size_16,color_FFFFFF,t_70" alt="img"></p><p>tugraph</p><p><img src="https://fma-ai.cn/cover/%E6%88%AA%E5%B1%8F2020-07-09%20%E4%B8%8B%E5%8D%881-1594348883927.png" alt="img"></p><p>cypher 语法，没有开源，估计是neo4j套皮</p><p><img src="https://pic4.zhimg.com/v2-88a8c5a05d2fe6e93d44ddd937a7cc98_r.jpg" alt="preview"></p><p>tigergraph</p><p>![image-20211111104734637](&#x2F;Users&#x2F;andrew&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20211111104734637.png)</p><p><img src="https://img2018.cnblogs.com/blog/847408/201901/847408-20190118192620943-2101126015.png" alt="img"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>linux硬盘格式化与挂载</title>
      <link href="/2020/03/16/linux%E7%A1%AC%E7%9B%98%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%B8%8E%E6%8C%82%E8%BD%BD/"/>
      <url>/2020/03/16/linux%E7%A1%AC%E7%9B%98%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%B8%8E%E6%8C%82%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">yum install -y gdisk</span><br><span class="line">fdisk /dev/sdb</span><br><span class="line">m</span><br><span class="line">g</span><br><span class="line">w</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkfs -t ext4 /dev/sdb</span><br><span class="line"><span class="built_in">mkdir</span> /data</span><br><span class="line">mounr /dev/sdb /data</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>spark</title>
      <link href="/2019/08/16/spark/"/>
      <url>/2019/08/16/spark/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark简介"><a href="#Spark简介" class="headerlink" title="Spark简介"></a>Spark简介</h1><nav><a href="#一简介">一、简介</a><br/><a href="#二特点">二、特点</a><br/><a href="#三集群架构">三、集群架构</a><br/><a href="#四核心组件">四、核心组件</a><br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#31-Spark--SQL">3.1 Spark  SQL</a><br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#32-Spark-Streaming">3.2 Spark Streaming</a><br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#33-MLlib">3.3 MLlib</a><br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#34-Graphx">3.4 Graphx</a><br/><a href="#">  </a><br/></nav><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>Spark 于 2009 年诞生于加州大学伯克利分校 AMPLab，2013 年被捐赠给 Apache 软件基金会，2014 年 2 月成为 Apache 的顶级项目。相对于 MapReduce 的批处理计算，Spark 可以带来上百倍的性能提升，因此它成为继 MapReduce 之后，最为广泛使用的分布式计算框架。</p><h2 id="二、特点"><a href="#二、特点" class="headerlink" title="二、特点"></a>二、特点</h2><p>Apache Spark 具有以下特点：</p><ul><li>使用先进的 DAG 调度程序，查询优化器和物理执行引擎，以实现性能上的保证；</li><li>多语言支持，目前支持的有 Java，Scala，Python 和 R；</li><li>提供了 80 多个高级 API，可以轻松地构建应用程序；</li><li>支持批处理，流处理和复杂的业务分析；</li><li>丰富的类库支持：包括 SQL，MLlib，GraphX 和 Spark Streaming 等库，并且可以将它们无缝地进行组合；  </li><li>丰富的部署模式：支持本地模式和自带的集群模式，也支持在 Hadoop，Mesos，Kubernetes 上运行；</li><li>多数据源支持：支持访问 HDFS，Alluxio，Cassandra，HBase，Hive 以及数百个其他数据源中的数据。</li></ul><div align="center"> <img width="600px" src="https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/future-of-spark.png"/> </div><h2 id="三、集群架构"><a href="#三、集群架构" class="headerlink" title="三、集群架构"></a>三、集群架构</h2><table><thead><tr><th>Term（术语）</th><th>Meaning（含义）</th></tr></thead><tbody><tr><td>Application</td><td>Spark 应用程序，由集群上的一个 Driver 节点和多个 Executor 节点组成。</td></tr><tr><td>Driver program</td><td>主运用程序，该进程运行应用的 main() 方法并且创建  SparkContext</td></tr><tr><td>Cluster manager</td><td>集群资源管理器（例如，Standlone Manager，Mesos，YARN）</td></tr><tr><td>Worker node</td><td>执行计算任务的工作节点</td></tr><tr><td>Executor</td><td>位于工作节点上的应用进程，负责执行计算任务并且将输出数据保存到内存或者磁盘中</td></tr><tr><td>Task</td><td>被发送到 Executor 中的工作单元</td></tr></tbody></table><div align="center"> <img src="https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/spark-集群模式.png"/> </div><p><strong>执行过程</strong>：</p><ol><li>用户程序创建 SparkContext 后，它会连接到集群资源管理器，集群资源管理器会为用户程序分配计算资源，并启动 Executor；</li><li>Driver 将计算程序划分为不同的执行阶段和多个 Task，之后将 Task 发送给 Executor；</li><li>Executor 负责执行 Task，并将执行状态汇报给 Driver，同时也会将当前节点资源的使用情况汇报给集群资源管理器。</li></ol><h2 id="四、核心组件"><a href="#四、核心组件" class="headerlink" title="四、核心组件"></a>四、核心组件</h2><p>Spark 基于 Spark Core 扩展了四个核心组件，分别用于满足不同领域的计算需求。</p><div align="center"> <img  width="600px" src="https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/spark-stack.png"/> </div><h3 id="3-1-Spark-SQL"><a href="#3-1-Spark-SQL" class="headerlink" title="3.1 Spark  SQL"></a>3.1 Spark  SQL</h3><p>Spark SQL 主要用于结构化数据的处理。其具有以下特点：</p><ul><li>能够将 SQL 查询与 Spark 程序无缝混合，允许您使用 SQL 或 DataFrame API 对结构化数据进行查询；</li><li>支持多种数据源，包括 Hive，Avro，Parquet，ORC，JSON 和 JDBC；</li><li>支持 HiveQL 语法以及用户自定义函数 (UDF)，允许你访问现有的 Hive 仓库；</li><li>支持标准的 JDBC 和 ODBC 连接；</li><li>支持优化器，列式存储和代码生成等特性，以提高查询效率。</li></ul><h3 id="3-2-Spark-Streaming"><a href="#3-2-Spark-Streaming" class="headerlink" title="3.2 Spark Streaming"></a>3.2 Spark Streaming</h3><p>Spark Streaming 主要用于快速构建可扩展，高吞吐量，高容错的流处理程序。支持从 HDFS，Flume，Kafka，Twitter 和 ZeroMQ 读取数据，并进行处理。</p><div align="center"> <img width="600px" src="https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/spark-streaming-arch.png"/> </div><p> Spark Streaming 的本质是微批处理，它将数据流进行极小粒度的拆分，拆分为多个批处理，从而达到接近于流处理的效果。</p><div align="center"> <img width="600px"   src="https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/spark-streaming-flow.png"/> </div><h3 id="3-3-MLlib"><a href="#3-3-MLlib" class="headerlink" title="3.3 MLlib"></a>3.3 MLlib</h3><p>MLlib 是 Spark 的机器学习库。其设计目标是使得机器学习变得简单且可扩展。它提供了以下工具：</p><ul><li><strong>常见的机器学习算法</strong>：如分类，回归，聚类和协同过滤；</li><li><strong>特征化</strong>：特征提取，转换，降维和选择；</li><li><strong>管道</strong>：用于构建，评估和调整 ML 管道的工具；</li><li><strong>持久性</strong>：保存和加载算法，模型，管道数据；</li><li><strong>实用工具</strong>：线性代数，统计，数据处理等。</li></ul><h3 id="3-4-Graphx"><a href="#3-4-Graphx" class="headerlink" title="3.4 Graphx"></a>3.4 Graphx</h3><p>GraphX 是 Spark 中用于图形计算和图形并行计算的新组件。在高层次上，GraphX 通过引入一个新的图形抽象来扩展 RDD(一种具有附加到每个顶点和边缘的属性的定向多重图形)。为了支持图计算，GraphX 提供了一组基本运算符（如： subgraph，joinVertices 和 aggregateMessages）以及优化后的 Pregel API。此外，GraphX 还包括越来越多的图形算法和构建器，以简化图形分析任务。</p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><div align="center"> <img  src="https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/weixin-desc.png"/> </div>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>kafka</title>
      <link href="/2019/08/16/kafka/"/>
      <url>/2019/08/16/kafka/</url>
      
        <content type="html"><![CDATA[<h1 id="Kafka简介"><a href="#Kafka简介" class="headerlink" title="Kafka简介"></a>Kafka简介</h1><nav><a href="#一Kafka简介">一、Kafka简介</a><br/><a href="#二Kafka核心概念">二、Kafka核心概念</a><br/>&nbsp;&nbsp;&nbsp;&nbsp;<a href="#21-Messages-And-Batches">2.1 Messages And Batches</a><br/>&nbsp;&nbsp;&nbsp;&nbsp;<a href="#22-Topics-And-Partitions">2.2 Topics And Partitions</a><br/>&nbsp;&nbsp;&nbsp;&nbsp;<a href="#23-Producers-And-Consumers">2.3 Producers And Consumers</a><br/>&nbsp;&nbsp;&nbsp;&nbsp;<a href="#24-Brokers-And-Clusters">2.4 Brokers And Clusters </a><br/></nav><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>ApacheKafka 是一个分布式的流处理平台。它具有以下特点：</p><ul><li>支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列；</li><li>支持数据实时处理；</li><li>能保证消息的可靠性投递；</li><li>支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；</li><li>高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量。</li></ul><h2 id="二、基本概念"><a href="#二、基本概念" class="headerlink" title="二、基本概念"></a>二、基本概念</h2><h3 id="2-1-Messages-And-Batches"><a href="#2-1-Messages-And-Batches" class="headerlink" title="2.1 Messages And Batches"></a>2.1 Messages And Batches</h3><p>Kafka 的基本数据单元被称为 message(消息)，为减少网络开销，提高效率，多个消息会被放入同一批次 (Batch) 中后再写入。</p><h3 id="2-2-Topics-And-Partitions"><a href="#2-2-Topics-And-Partitions" class="headerlink" title="2.2 Topics And Partitions"></a>2.2 Topics And Partitions</h3><p>Kafka 的消息通过 Topics(主题) 进行分类，一个主题可以被分为若干个 Partitions(分区)，一个分区就是一个提交日志 (commit log)。消息以追加的方式写入分区，然后以先入先出的顺序读取。Kafka 通过分区来实现数据的冗余和伸缩性，分区可以分布在不同的服务器上，这意味着一个 Topic 可以横跨多个服务器，以提供比单个服务器更强大的性能。</p><p>由于一个 Topic 包含多个分区，因此无法在整个 Topic 范围内保证消息的顺序性，但可以保证消息在单个分区内的顺序性。</p><div align="center"> <img  src="https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-topic.png"/> </div><h3 id="2-3-Producers-And-Consumers"><a href="#2-3-Producers-And-Consumers" class="headerlink" title="2.3 Producers And Consumers"></a>2.3 Producers And Consumers</h3><h4 id="1-生产者"><a href="#1-生产者" class="headerlink" title="1. 生产者"></a>1. 生产者</h4><p>生产者负责创建消息。一般情况下，生产者在把消息均衡地分布到在主题的所有分区上，而并不关心消息会被写到哪个分区。如果我们想要把消息写到指定的分区，可以通过自定义分区器来实现。</p><h4 id="2-消费者"><a href="#2-消费者" class="headerlink" title="2. 消费者"></a>2. 消费者</h4><p>消费者是消费者群组的一部分，消费者负责消费消息。消费者可以订阅一个或者多个主题，并按照消息生成的顺序来读取它们。消费者通过检查消息的偏移量 (offset) 来区分读取过的消息。偏移量是一个不断递增的数值，在创建消息时，Kafka 会把它添加到其中，在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的偏移量保存在 Zookeeper 或 Kafka 上，如果消费者关闭或者重启，它还可以重新获取该偏移量，以保证读取状态不会丢失。</p><div align="center"> <img  src="https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-producer-consumer.png"/> </div><p>一个分区只能被同一个消费者群组里面的一个消费者读取，但可以被不同消费者群组中所组成的多个消费者共同读取。多个消费者群组中消费者共同读取同一个主题时，彼此之间互不影响。</p><div align="center"> <img  src="https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka消费者.png"/> </div><h3 id="2-4-Brokers-And-Clusters"><a href="#2-4-Brokers-And-Clusters" class="headerlink" title="2.4 Brokers And Clusters"></a>2.4 Brokers And Clusters</h3><p>一个独立的 Kafka 服务器被称为 Broker。Broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。Broker 为消费者提供服务，对读取分区的请求做出响应，返回已经提交到磁盘的消息。</p><p>Broker 是集群 (Cluster) 的组成部分。每一个集群都会选举出一个 Broker 作为集群控制器 (Controller)，集群控制器负责管理工作，包括将分区分配给 Broker 和监控 Broker。</p><p>在集群中，一个分区 (Partition) 从属一个 Broker，该 Broker 被称为分区的首领 (Leader)。一个分区可以分配给多个 Brokers，这个时候会发生分区复制。这种复制机制为分区提供了消息冗余，如果有一个 Broker 失效，其他 Broker 可以接管领导权。</p><div align="center"> <img  src="https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-cluster.png"/> </div><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>Neha Narkhede, Gwen Shapira ,Todd Palino(著) , 薛命灯 (译) . Kafka 权威指南 . 人民邮电出版社 . 2017-12-26</p><div align="center"> <img  src="https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/weixin-desc.png"/> </div>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>docker基本操作</title>
      <link href="/2019/08/16/docker%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
      <url>/2019/08/16/docker%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo</title>
      <link href="/2018/08/16/hexo/"/>
      <url>/2018/08/16/hexo/</url>
      
        <content type="html"><![CDATA[<p>1、安装node.js</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">https://nodejs.org/zh-cn/</span><br><span class="line">安装：https://blog.csdn.net/qq_40712862/article/details/120231621</span><br><span class="line"></span><br><span class="line">node -v判断是否安装成功</span><br></pre></td></tr></table></figure><p>下载慢解决方法:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">更换淘宝镜像下载源：npm config <span class="built_in">set</span> registry https://registry.npm.taobao.org</span><br><span class="line">或国内的npm镜像命令：npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure><p>安装指定版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">安装：https://blog.csdn.net/weixin_44198965/article/details/124140283</span><br><span class="line">版本：https://nodejs.org/download/release/v15.7.0/</span><br></pre></td></tr></table></figure><p>2、注册github<br><a href="https://github.com/">https://github.com/</a></p><p>3、安装hexo<br>新建文件夹，打开cmd，输入命令npm install hexo-cli -g<br>hexo -v出现版本号即安装成功<br>如果卸载hexo</p><p>安装成功后可在C:\Users\Administrator\AppData\Roaming文件夹下看到npm文件夹<br>卸载命令：卸载成功后npm文件夹会消失npm uninstall hexo-cli -g<br>安装指定版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">查看版本hexo --version</span><br><span class="line">安装 Hexo 指定版本npm i hexo@4.2.1 --save</span><br></pre></td></tr></table></figure><p>4、生成本地静态网页</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hexo init 博客名称初始化</span><br><span class="line"><span class="built_in">cd</span> 博客名称进入文件夹，npm install安装依赖</span><br><span class="line">hexo g生成静态网页</span><br><span class="line">hexo s打开本地预览</span><br><span class="line">hexo clean，清除缓存文件 db.json 和已生成的静态文件在 ./public/文件夹下</span><br></pre></td></tr></table></figure><p>5、上传github<br>创建仓库create repository<br>填写仓库名称需要和gihub账号一致，勾选Add a README file，点击创建<br>进入仓库点击settings-&gt;Pages，找到Github Page<br>Branch分支改成main或master<br>6、安装git</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://git-scm.com/</span><br></pre></td></tr></table></figure><p>配置ssh密钥</p><p>鼠标右键打开Git Bash Here窗口，执行ssh-keygen<br>然后打开此电脑–&gt;C盘–&gt;用户–&gt;Administrator–&gt;.ssh(文件夹)–&gt;用记事本打开 id_rsa.pub 文件，全选复制<br>或者：打开Git Bash Here窗口输入cat ~&#x2F;.ssh&#x2F;id_rsa.pub输出SSH Key，然后复制<br>打开注册的github，进入设置–&gt;SSH公钥–&gt;在公钥区粘贴刚才复制的公钥，点击确定输入github登陆密码进行验证即可<br>克隆github项目到本地</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">git init初始化本地仓库，后会在本地文件夹下生成一个 .git 文件夹</span><br><span class="line">开始克隆：git <span class="built_in">clone</span> 仓库地址</span><br><span class="line">git的推送操作</span><br><span class="line"></span><br><span class="line">git status 查看当前状态。</span><br><span class="line">git add 文件名表示将某个文件添加至暂存区。</span><br><span class="line">git add .表示将所有(进行修改的)文件添加至暂存区。</span><br><span class="line">git commit -m “xxx” xxx表示自己对本次提交所进行的备注或者标注。</span><br><span class="line">git remote add origin SSH链接 表示建立本地库与想要操作的远程仓库的联系。</span><br><span class="line">git push -u origin master 表示实现由本地库向远程仓库的推送。</span><br><span class="line"></span><br><span class="line">git的拉取操作</span><br><span class="line"></span><br><span class="line">git pull origin master 表示将远程仓库的内容文件同步更新拉取到本地库。</span><br></pre></td></tr></table></figure><p>问题<br>如果执行git push origin master报错:The project you were looking for could not be found，则通过(管理员运行)git config –system –unset credential.helper清除账户信息并且在windows凭证里添加账户信息</p><p>7、连接github，git config配置用户账户:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name <span class="string">&quot;username&quot;</span></span><br><span class="line">git config --global user.email <span class="string">&quot;email&quot;</span></span><br></pre></td></tr></table></figure><p>将username和email换成github的用户名和邮箱<br>–global 表示全局的，即当前用户都有效，该配置会出现在 <del>&#x2F;.gitconfig 文件中，</del>表示当前用户的目录，比如：C:\Users\username.gitconfig</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;你GitHub账号的邮箱&quot;</span>来生成SSH Key，中途按3次回车</span><br></pre></td></tr></table></figure><p>8、hexo 关联github<br>打开hexo文件夹里面的_config.yml文件，这是hexo的配置文件修改：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">      <span class="built_in">type</span>: git</span><br><span class="line">      repo: ssh://git@github.com/github账号名称/github账号名称.github.io.git</span><br><span class="line">      branch: master</span><br></pre></td></tr></table></figure><p>然后在cmd上输入npm install hexo-deployer-git –save安装GitHub推送插件<br>安装好了以后再输入hexo g生成静态网页，再输入hexo d上传到GitHub就可以了<br>9、hexo 主题</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://hexo.io/themes/</span><br></pre></td></tr></table></figure><p>比如安装主题next：npm install hexo-theme-next</p><p>10、hexo 配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Hexo Configuration Hexo配置文件</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/configuration.html</span></span><br><span class="line"><span class="comment">## Source: https://github.com/hexojs/hexo/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 网站信息</span></span><br><span class="line"><span class="comment">#标题</span></span><br><span class="line">title: 学志の博客</span><br><span class="line"><span class="comment">#副标题</span></span><br><span class="line">subtitle: 记录学习的技能和遇到的问题</span><br><span class="line"><span class="comment">#网站描述</span></span><br><span class="line">description: 做自己爱做的事，爱自己在做的事！</span><br><span class="line"><span class="comment">#作者昵称</span></span><br><span class="line">author: 张学志</span><br><span class="line"><span class="comment">#网站语言，默认英语，设置简体汉语</span></span><br><span class="line">language: zh-Hans</span><br><span class="line"></span><br><span class="line"><span class="comment">#时区，默认电脑时区</span></span><br><span class="line"><span class="comment">#timezone: </span></span><br><span class="line">timezone: Asia/Shanghai</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 网址设置</span></span><br><span class="line"><span class="comment">#如果网站是放在子目录中，将url设置成&#x27;http://yoursite.com/child&#x27;，将root设置成&#x27;/child/&#x27;</span></span><br><span class="line"><span class="comment">## If your site is put in a subdirectory, set url as &#x27;http://yoursite.com/child&#x27; and root as &#x27;/child/&#x27;</span></span><br><span class="line"><span class="comment">#网址</span></span><br><span class="line">url: http://zhangxuezhi.com</span><br><span class="line"><span class="comment">#网站根目录。如果网站是放在子目录中，将root设置成&#x27;子目录名&#x27;</span></span><br><span class="line">root: /</span><br><span class="line"><span class="comment">#文章链接地址格式 。即文章存放的目录。</span></span><br><span class="line">permalink: :year/:month/:day/:title/</span><br><span class="line">permalink_defaults:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 目录设置</span></span><br><span class="line"><span class="comment">#资源文件夹，放在里面的文件会上传到github中</span></span><br><span class="line">source_dir: <span class="built_in">source</span></span><br><span class="line"><span class="comment">#公共文件夹，存放生成的静态文件</span></span><br><span class="line">public_dir: public</span><br><span class="line"><span class="comment">#标签文件夹，默认是tags。实际存放在source/tags中。</span></span><br><span class="line">tag_dir: tags</span><br><span class="line">rss_dir: rss</span><br><span class="line"><span class="comment">#档案文件夹，默认是archives。</span></span><br><span class="line">archive_dir: archives</span><br><span class="line"><span class="comment">#分类文件夹，默认是categories。实际存放在source/categories中。</span></span><br><span class="line">category_dir: categories</span><br><span class="line"><span class="comment">#代码文件夹，默认是downloads/code</span></span><br><span class="line">code_dir: downloads/code</span><br><span class="line"><span class="comment">#国际化文件夹，默认跟language相同</span></span><br><span class="line">i18n_dir: :lang</span><br><span class="line"><span class="comment">#不需要渲染的文件夹或文件夹,放在[]中</span></span><br><span class="line"><span class="comment"># 这两个文件是百度和google的站长验证文件，不能渲染，否则会改变内容，不能验证过</span></span><br><span class="line">skip_render: [baidu_verify_R9MZjdMkXT.html, google0f8fac7da2b48ef8.html, README.md, 模板.md]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 写作选项</span></span><br><span class="line"><span class="comment"># 新建博文（帖子）的默认名称</span></span><br><span class="line"><span class="comment"># File name of new posts</span></span><br><span class="line">new_post_name: :title.md </span><br><span class="line"><span class="comment">#默认布局模板是post，而不是draft和page</span></span><br><span class="line">default_layout: post</span><br><span class="line"><span class="comment">#是否将标题转换成标题形式（首字母大写）</span></span><br><span class="line">titlecase: <span class="literal">false</span> <span class="comment"># Transform title into titlecase</span></span><br><span class="line"><span class="comment">#在新标签页面中打开网页</span></span><br><span class="line">external_link: <span class="literal">true</span> <span class="comment"># Open external links in new tab</span></span><br><span class="line">filename_case: 0</span><br><span class="line"><span class="comment">#是否渲染草稿</span></span><br><span class="line">render_drafts: <span class="literal">false</span></span><br><span class="line"><span class="comment">#启动 Asset 文件夹</span></span><br><span class="line">post_asset_folder: <span class="literal">false</span></span><br><span class="line"><span class="comment">#把链接改为与根目录的相对位址</span></span><br><span class="line">relative_link: <span class="literal">false</span></span><br><span class="line"><span class="comment">#显示未来的文章</span></span><br><span class="line">future: <span class="literal">true</span></span><br><span class="line"><span class="comment">#代码块的设置</span></span><br><span class="line">highlight:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span>          <span class="comment">#  使用代码高亮</span></span><br><span class="line">  line_number: <span class="literal">true</span> <span class="comment"># 显示行号</span></span><br><span class="line">  auto_detect: <span class="literal">true</span>  <span class="comment"># 自动检测语言</span></span><br><span class="line">  tab_replace:</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 分类和标签</span></span><br><span class="line"><span class="comment"># 默认分类</span></span><br><span class="line">default_category: uncategorized</span><br><span class="line"><span class="comment">#分类别名</span></span><br><span class="line">category_map:</span><br><span class="line"><span class="comment">#标签别名</span></span><br><span class="line">tag_map:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 日期和时间格式</span></span><br><span class="line"><span class="comment">#Hexo 使用 Moment.js 来解析和显示时间。</span></span><br><span class="line"><span class="comment">## You can customize the date format as defined in</span></span><br><span class="line"><span class="comment">## http://momentjs.com/docs/#/displaying/format/</span></span><br><span class="line">date_format: YYYY-MM-DD</span><br><span class="line">time_format: HH:mm:ss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分页配置</span></span><br><span class="line"><span class="comment"># ---------------下面选项需要对应插件的支持---------------</span></span><br><span class="line"><span class="comment"># npm install hexo-generator-index --save</span></span><br><span class="line"><span class="comment"># npm install hexo-generator-archive --save</span></span><br><span class="line"><span class="comment"># npm install hexo-generator-category --save</span></span><br><span class="line"><span class="comment"># npm install hexo-generator-tag --save</span></span><br><span class="line"><span class="comment">## Set per_page to 0 to disable pagination</span></span><br><span class="line"><span class="comment">#每页显示的文章量 </span></span><br><span class="line"><span class="comment">#per_page: 20</span></span><br><span class="line"><span class="comment">#首页的分页设置</span></span><br><span class="line">index_generator:</span><br><span class="line">  per_page: 5</span><br><span class="line"><span class="comment">#归档页的分页设置</span></span><br><span class="line">archive_generator:</span><br><span class="line">  per_page: 30</span><br><span class="line">  yearly: <span class="literal">true</span></span><br><span class="line">  monthly: <span class="literal">true</span></span><br><span class="line"><span class="comment">#标签页的分页设置</span></span><br><span class="line">tag_generator:</span><br><span class="line">  per_page: 20</span><br><span class="line"></span><br><span class="line"><span class="comment">#分页路径，在public中可以看到</span></span><br><span class="line"><span class="comment">#pagination_dir: page</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Extensions 拓展插件配置</span></span><br><span class="line"><span class="comment">## Plugins: https://hexo.io/plugins/</span></span><br><span class="line">plugins: </span><br><span class="line">baidusitemap: </span><br><span class="line">  path: baidusitemap.xml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置RSS</span></span><br><span class="line">feed: </span><br><span class="line">  <span class="comment">#feed 类型 (atom/rss2)</span></span><br><span class="line">  <span class="built_in">type</span>: atom   </span><br><span class="line">  <span class="comment">#rss 路径</span></span><br><span class="line">  path: atom.xml  </span><br><span class="line">  <span class="comment">#在 rss 中最多生成的文章数(0显示所有)</span></span><br><span class="line">  <span class="built_in">limit</span>: 0</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 自定义站点内容搜索</span></span><br><span class="line"><span class="comment"># 需要先安装插件：</span></span><br><span class="line"><span class="comment"># npm install hexo-generator-search --save</span></span><br><span class="line">search:</span><br><span class="line">  path: search.xml</span><br><span class="line">  <span class="comment"># 如只想索引文章，可设置为post</span></span><br><span class="line">  field: all </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 主题配置</span></span><br><span class="line"><span class="comment">## Themes: https://hexo.io/themes/</span></span><br><span class="line"><span class="comment">#theme: false #禁用主题</span></span><br><span class="line"><span class="comment">#theme: landscape</span></span><br><span class="line">theme: next</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 部署配置</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/deployment.html</span></span><br><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  <span class="comment">#repo: https://github.com/xuezhisd/xuezhisd.github.io.git</span></span><br><span class="line">  repo: </span><br><span class="line">    <span class="comment"># 部署到github</span></span><br><span class="line">    github: git@github.com:xuezhisd/xuezhisd.github.io.git,master</span><br><span class="line">    <span class="comment"># 部署到coding.net。取消注释，可同时部署</span></span><br><span class="line">    <span class="comment">#coding: git@git.coding.net:xuezhisd/blog.git,coding-pages</span></span><br><span class="line">  <span class="comment">#type: baidu_url_submitter</span></span><br></pre></td></tr></table></figure><p>11、 新增菜单栏选项<br>添加新页面：hexo new page “xx”<br>在主题配置文件的menu中加上该页面<br>在zh-CN.yml文件中加上中文意思<br>12、图片处理<br>配置文件中的post_asset_folder改成true<br>安装依赖npm install hexo-asset-image –save<br>放到该文件夹下，按照md格式输入(文件名称&#x2F;图片名.jpg)<br>13、搜索</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-安装依赖 npm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure><p>站点配置文件的扩展下添加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> search:</span><br><span class="line">      path: search.xml</span><br><span class="line">      field: post</span><br><span class="line">      format: html</span><br><span class="line">      <span class="built_in">limit</span>: 10000</span><br><span class="line"></span><br><span class="line">主题配置文件下，local_search改成<span class="literal">true</span>即可</span><br><span class="line">local_search:</span><br><span class="line">      <span class="built_in">enable</span>: <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>14、新建文章<br>hexo new 文章名称<br>存储在&#x2F;source&#x2F;_posts下<br>hexo 插件<br>插件汇总：<a href="https://blog.csdn.net/qq_43701912/article/details/107310923">https://blog.csdn.net/qq_43701912/article/details/107310923</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nginx</title>
      <link href="/2018/08/16/nginx/"/>
      <url>/2018/08/16/nginx/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>loguru elasticsearch kibana 日志处理</title>
      <link href="/2018/05/16/loguru-elasticsearch-kibana-%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86/"/>
      <url>/2018/05/16/loguru-elasticsearch-kibana-%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="日志的重要性"><a href="#日志的重要性" class="headerlink" title="日志的重要性"></a>日志的重要性</h3><p>常见日志记录方式</p><h4 id="一、print"><a href="#一、print" class="headerlink" title="一、print()"></a>一、print()</h4><h4 id="二、自写模板"><a href="#二、自写模板" class="headerlink" title="二、自写模板"></a>二、自写模板</h4><h4 id="三、Logging"><a href="#三、Logging" class="headerlink" title="三、Logging"></a>三、Logging</h4><h5 id="更优雅的解决方案：Loguru"><a href="#更优雅的解决方案：Loguru" class="headerlink" title="更优雅的解决方案：Loguru"></a>更优雅的解决方案：Loguru</h5><h5 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h5><p>开箱即用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">add() / remove()</span><br><span class="line">完整参数</span><br><span class="line">rotation 日志文件分隔</span><br><span class="line">retention 日志保留时间</span><br><span class="line">compression 日志压缩格式</span><br><span class="line">字符串格式化</span><br><span class="line">异常追溯</span><br></pre></td></tr></table></figure><h3 id="日志的重要性-1"><a href="#日志的重要性-1" class="headerlink" title="日志的重要性"></a>日志的重要性</h3><p>日志的作用非常重要，日志可以记录用户的操作、程序的异常，还可以为数据分析提供依据，日志的存在意义就是为了能够在程序在运行过程中记录错误，方便维护和调试，能够快速定位出错的地方，减少维护成本。每个程序员都应该知道，不是为了记录日志而记录日志，日志也不是随意记的。要实现能够只通过日志文件还原整个程序执行的过程，达到能透明地看到程序里执行情况，每个线程、每个过程到底执行到哪的目的。日志就像飞机的黑匣子一样，应当能够复原异常的整个现场乃至细节！</p><h3 id="常见日志记录方式"><a href="#常见日志记录方式" class="headerlink" title="常见日志记录方式"></a>常见日志记录方式</h3><h4 id="一、print-1"><a href="#一、print-1" class="headerlink" title="一、print()"></a>一、print()</h4><p>最常见的是把输出函数 print() 当作日志记录的方式，直接打印各种提示信息，常见于个人练习项目里，通常是懒得单独配置日志，而且项目太小不需要日志信息，不需要上线，不需要持续运行，完整的项目不推荐直接打印日志信息，现实中也几乎没有人这么做。</p><h4 id="二、自写模板-1"><a href="#二、自写模板-1" class="headerlink" title="二、自写模板"></a>二、自写模板</h4><p>我们可以在不少小项目里面看到作者自己写了一个日志模板，通常利用 print() 或者 sys.stdout 稍微封装一下即可实现简单的日志输出，这里的 sys.stdout 是 Python 中的标准输出流，print() 函数是对 sys.stdout 的高级封装，当我们在 Python 中打印对象调用 print(obj) 时候，事实上是调用了 sys.stdout.write(obj+’\n’)，print() 将内容打印到了控制台，然后追加了一个换行符 \n。</p><p>自写日志模板适合比较小的项目，可以按照自己的喜好编写模板，不需要太多复杂配置，方便快捷，但是这种记录日志的方式并不是很规范，有可能你自己觉得阅读体验不错，但是别人在接触你的项目的时候往往需要花费一定的时间去学习日志的逻辑、格式、输出方式等，比较大的项目同样不推荐这种方法。</p><p>一个简单的自写日志模板举例：</p><p>日志模板 log.py：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getnowtime</span>():</span><br><span class="line">    <span class="keyword">return</span> datetime.datetime.now().strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_log</span>(<span class="params">content, level, *args</span>):</span><br><span class="line">    sys.stdout.write(<span class="string">&quot;%s - %s - %s\n&quot;</span> % (getnowtime(), level, content))</span><br><span class="line">    <span class="keyword">for</span> arg <span class="keyword">in</span> args:</span><br><span class="line">        sys.stdout.write(<span class="string">&quot;%s\n&quot;</span> % arg)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">debug</span>(<span class="params">content, *args</span>):</span><br><span class="line">    _log(content, <span class="string">&#x27;DEBUG&#x27;</span>, *args)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">info</span>(<span class="params">content, *args</span>):</span><br><span class="line">    _log(content, <span class="string">&#x27;INFO&#x27;</span>, *args)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">warn</span>(<span class="params">content, *args</span>):</span><br><span class="line">    _log(content, <span class="string">&#x27;WARN&#x27;</span>, *args)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">error</span>(<span class="params">content, *args</span>):</span><br><span class="line">    _log(content, <span class="string">&#x27;ERROR&#x27;</span>, *args)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exception</span>(<span class="params">content</span>):</span><br><span class="line">    sys.stdout.write(<span class="string">&quot;%s - %s\n&quot;</span> % (getnowtime(), content))</span><br><span class="line">    traceback.print_exc(file=sys.stdout)</span><br></pre></td></tr></table></figure><p>调用日志模块：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> log</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">log.info(<span class="string">&quot;This is log info!&quot;</span>)</span><br><span class="line">log.warn(<span class="string">&quot;This is log warn!&quot;</span>)</span><br><span class="line">log.error(<span class="string">&quot;This is log error!&quot;</span>)</span><br><span class="line">log.debug(<span class="string">&quot;This is log debug!&quot;</span>)</span><br><span class="line"></span><br><span class="line">people_info = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">20</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    gender = people_info[<span class="string">&quot;gender&quot;</span>]</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> error:</span><br><span class="line">    log.exception(error)</span><br><span class="line">日志输出：</span><br><span class="line"></span><br><span class="line"><span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> 09:<span class="number">50</span>:<span class="number">58</span> - INFO - This <span class="keyword">is</span> log info!</span><br><span class="line"><span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> 09:<span class="number">50</span>:<span class="number">58</span> - WARN - This <span class="keyword">is</span> log warn!</span><br><span class="line"><span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> 09:<span class="number">50</span>:<span class="number">58</span> - ERROR - This <span class="keyword">is</span> log error!</span><br><span class="line"><span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> 09:<span class="number">50</span>:<span class="number">58</span> - DEBUG - This <span class="keyword">is</span> log debug!</span><br><span class="line"><span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> 09:<span class="number">50</span>:<span class="number">58</span> - <span class="string">&#x27;gender&#x27;</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;D:/python3Project/test.py&quot;</span>, line <span class="number">18</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    gender = people_info[<span class="string">&quot;gender&quot;</span>]</span><br><span class="line">KeyError: <span class="string">&#x27;gender&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="三、Logging-1"><a href="#三、Logging-1" class="headerlink" title="三、Logging"></a>三、Logging</h4><p>在一个完整的项目中，大多数人都会引入专门的日志记录库，而 Python 自带的标准库 logging 就是专门为日志记录而生的，logging 模块定义的函数和类为应用程序和库的开发实现了一个灵活的事件日志系统。由标准库模块提供日志记录 API 的关键好处是所有 Python 模块都可以使用这个日志记录功能。所以，你的应用日志可以将你自己的日志信息与来自第三方模块的信息整合起来。</p><p>logging 模块虽然强大，但是其配置也是比较繁琐的，在大型项目中通常需要单独初始化日志、配置日志格式等等，我在日常使用中通常都会对 logging 做如下的封装写法，使日志可以按天保存，保留15天的日志，可以配置是否输出到控制台和文件，如下所示：</p><h1 id="实现按天分割保留日志"><a href="#实现按天分割保留日志" class="headerlink" title="实现按天分割保留日志"></a>实现按天分割保留日志</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> logging <span class="keyword">import</span> handlers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">PARENT_DIR = os.path.split(os.path.realpath(__file__))[<span class="number">0</span>]  <span class="comment"># 父目录</span></span><br><span class="line">LOGGING_DIR = os.path.join(PARENT_DIR, <span class="string">&quot;log&quot;</span>)              <span class="comment"># 日志目录</span></span><br><span class="line">LOGGING_NAME = <span class="string">&quot;test&quot;</span>                                      <span class="comment"># 日志文件名</span></span><br><span class="line"></span><br><span class="line">LOGGING_TO_FILE = <span class="literal">True</span>                                     <span class="comment"># 日志输出文件</span></span><br><span class="line">LOGGING_TO_CONSOLE = <span class="literal">True</span>                                  <span class="comment"># 日志输出到控制台</span></span><br><span class="line"></span><br><span class="line">LOGGING_WHEN = <span class="string">&#x27;D&#x27;</span>                                         <span class="comment"># 日志文件切分维度</span></span><br><span class="line">LOGGING_INTERVAL = <span class="number">1</span>                                       <span class="comment"># 间隔少个 when 后，自动重建文件</span></span><br><span class="line">LOGGING_BACKUP_COUNT = <span class="number">15</span>                                  <span class="comment"># 日志保留个数，0 保留所有日志</span></span><br><span class="line">LOGGING_LEVEL = logging.DEBUG                              <span class="comment"># 日志等级</span></span><br><span class="line">LOGGING_suffix = <span class="string">&quot;%Y.%m.%d.log&quot;</span>                            <span class="comment"># 旧日志文件名</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 日志输出格式</span></span><br><span class="line">LOGGING_FORMATTER = <span class="string">&quot;%(levelname)s - %(asctime)s - process:%(process)d - %(filename)s - %(name)s - line:%(lineno)d - %(module)s - %(message)s&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">logging_init</span>():</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(LOGGING_DIR):</span><br><span class="line">        os.makedirs(LOGGING_DIR)</span><br><span class="line">    logger = logging.getLogger()</span><br><span class="line">    logger.setLevel(LOGGING_LEVEL)</span><br><span class="line">    formatter = logging.Formatter(LOGGING_FORMATTER)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> LOGGING_TO_FILE:</span><br><span class="line">        file_handler = handlers.TimedRotatingFileHandler(filename=os.path.join(LOGGING_DIR, LOGGING_NAME), when=LOGGING_WHEN, interval=LOGGING_INTERVAL, backupCount=LOGGING_BACKUP_COUNT)</span><br><span class="line">        file_handler.suffix = LOGGING_suffix</span><br><span class="line">        file_handler.setFormatter(formatter)</span><br><span class="line">        logger.addHandler(file_handler)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> LOGGING_TO_CONSOLE:</span><br><span class="line">        stream_handler = logging.StreamHandler(sys.stderr)</span><br><span class="line">        stream_handler.setFormatter(formatter)</span><br><span class="line">        logger.addHandler(stream_handler)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">logging_test</span>():</span><br><span class="line">    logging.info(<span class="string">&quot;This is log info!&quot;</span>)</span><br><span class="line">    logging.warning(<span class="string">&quot;This is log warn!&quot;</span>)</span><br><span class="line">    logging.error(<span class="string">&quot;This is log error!&quot;</span>)</span><br><span class="line">    logging.debug(<span class="string">&quot;This is log debug!&quot;</span>)</span><br><span class="line">    people_info = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">20</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        gender = people_info[<span class="string">&quot;gender&quot;</span>]</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> error:</span><br><span class="line">        logging.exception(error)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    logging_init()</span><br><span class="line">    logging_test()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出日志：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">INFO - <span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> <span class="number">11</span>:<span class="number">28</span>:<span class="number">10</span>,<span class="number">103</span> - process:<span class="number">15144</span> - test.py - root - line:<span class="number">52</span> - test - This <span class="keyword">is</span> log info!</span><br><span class="line">WARNING - <span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> <span class="number">11</span>:<span class="number">28</span>:<span class="number">10</span>,<span class="number">105</span> - process:<span class="number">15144</span> - test.py - root - line:<span class="number">53</span> - test - This <span class="keyword">is</span> log warn!</span><br><span class="line">ERROR - <span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> <span class="number">11</span>:<span class="number">28</span>:<span class="number">10</span>,<span class="number">105</span> - process:<span class="number">15144</span> - test.py - root - line:<span class="number">54</span> - test - This <span class="keyword">is</span> log error!</span><br><span class="line">DEBUG - <span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> <span class="number">11</span>:<span class="number">28</span>:<span class="number">10</span>,<span class="number">105</span> - process:<span class="number">15144</span> - test.py - root - line:<span class="number">55</span> - test - This <span class="keyword">is</span> log debug!</span><br><span class="line">ERROR - <span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> <span class="number">11</span>:<span class="number">28</span>:<span class="number">10</span>,<span class="number">105</span> - process:<span class="number">15144</span> - test.py - root - line:<span class="number">61</span> - test - <span class="string">&#x27;gender&#x27;</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;D:/python3Project/test.py&quot;</span>, line <span class="number">59</span>, <span class="keyword">in</span> logging_test</span><br><span class="line">    gender = people_info[<span class="string">&quot;gender&quot;</span>]</span><br><span class="line">KeyError: <span class="string">&#x27;gender&#x27;</span></span><br></pre></td></tr></table></figure><p>当然，如果你不需要很复杂的功能，希望简洁一点，仅仅需要在控制台输出一下日志的话，也可以只进行简单的配置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(level=logging.DEBUG, <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;</span>)</span><br><span class="line">logging.getLogger()</span><br></pre></td></tr></table></figure><p>更优雅的解决方案：Loguru<br>对于 logging 模块，即便是简单的使用，也需要自己定义格式，这里介绍一个更加优雅、高效、简洁的第三方模块：loguru，官方的介绍是：Loguru is a library which aims to bring enjoyable logging in Python. Loguru 旨在为 Python 带来愉快的日志记录。这里引用官方的一个 GIF 来快速演示其功能：</p><h5 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h5><p>Loguru 仅支持 Python 3.5 及以上的版本，使用 pip 安装即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install loguru</span><br></pre></td></tr></table></figure><p>开箱即用<br>Loguru 的主要概念是只有一个：logger</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> loguru <span class="keyword">import</span> logger</span><br><span class="line"></span><br><span class="line">logger.info(<span class="string">&quot;This is log info!&quot;</span>)</span><br><span class="line">logger.warning(<span class="string">&quot;This is log warn!&quot;</span>)</span><br><span class="line">logger.error(<span class="string">&quot;This is log error!&quot;</span>)</span><br><span class="line">logger.debug(<span class="string">&quot;This is log debug!&quot;</span>)</span><br></pre></td></tr></table></figure><p>控制台输出：</p><p>03.png</p><p>可以看到不需要手动设置，Loguru 会提前配置一些基础信息，自动输出时间、日志级别、模块名、行号等信息，而且根据等级的不同，还自动设置了不同的颜色，方便观察，真正做到了开箱即用！</p><p>add() &#x2F; remove()<br>如果想自定义日志级别，自定义日志格式，保存日志到文件该怎么办？与 logging 模块不同，不需要 Handler，不需要 Formatter，只需要一个 add() 函数就可以了，例如我们想把日志储存到文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> loguru <span class="keyword">import</span> logger</span><br><span class="line"></span><br><span class="line">logger.add(<span class="string">&#x27;test.log&#x27;</span>)</span><br><span class="line">logger.debug(<span class="string">&#x27;this is a debug&#x27;</span>)</span><br></pre></td></tr></table></figure><p>我们不需要像 logging 模块一样再声明一个 FileHandler 了，就一行 add() 语句搞定，运行之后会发现目录下 test.log 里面同样出现了刚刚控制台输出的 debug 信息。</p><p>与 add() 语句相反，remove() 语句可以删除我们添加的配置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> loguru <span class="keyword">import</span> logger</span><br><span class="line"></span><br><span class="line">log_file = logger.add(<span class="string">&#x27;test.log&#x27;</span>)</span><br><span class="line">logger.debug(<span class="string">&#x27;This is log debug!&#x27;</span>)</span><br><span class="line">logger.remove(log_file)</span><br><span class="line">logger.debug(<span class="string">&#x27;This is another log debug!&#x27;</span>)</span><br></pre></td></tr></table></figure><p>此时控制台会输出两条 debug 信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> <span class="number">13</span>:<span class="number">53</span>:<span class="number">36.610</span> | DEBUG    | __main__:&lt;module&gt;:<span class="number">86</span> - This <span class="keyword">is</span> log debug!</span><br><span class="line"><span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> <span class="number">13</span>:<span class="number">53</span>:<span class="number">36.611</span> | DEBUG    | __main__:&lt;module&gt;:<span class="number">88</span> - This <span class="keyword">is</span> another log debug!</span><br></pre></td></tr></table></figure><p>而 test.log 日志文件里面只有一条 debug 信息，原因就在于我们在第二条 debug 语句之前使用了 remove() 语句。</p><p>完整参数<br>Loguru 对输出到文件的配置有非常强大的支持，比如支持输出到多个文件，分级别分别输出，过大创建新文件，过久自动删除等等。 下面我们来详细看一下 add() 语句的详细参数：</p><p>基本语法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add(sink, *, level=<span class="string">&#x27;DEBUG&#x27;</span>, <span class="built_in">format</span>=<span class="string">&#x27;&lt;green&gt;&#123;time:YYYY-MM-DD HH:mm:ss.SSS&#125;&lt;/green&gt; | &lt;level&gt;&#123;level: &lt;8&#125;&lt;/level&gt; | &lt;cyan&gt;&#123;name&#125;&lt;/cyan&gt;:&lt;cyan&gt;&#123;function&#125;&lt;/cyan&gt;:&lt;cyan&gt;&#123;line&#125;&lt;/cyan&gt; - &lt;level&gt;&#123;message&#125;&lt;/level&gt;&#x27;</span>, <span class="built_in">filter</span>=<span class="literal">None</span>, colorize=<span class="literal">None</span>, serialize=<span class="literal">False</span>, backtrace=<span class="literal">True</span>, diagnose=<span class="literal">True</span>, enqueue=<span class="literal">False</span>, catch=<span class="literal">True</span>, **kwargs)</span><br></pre></td></tr></table></figure><h5 id="基本参数释义："><a href="#基本参数释义：" class="headerlink" title="基本参数释义："></a>基本参数释义：</h5><p>sink：可以是一个 file 对象，例如 sys.stderr 或 open(‘file.log’, ‘w’)，也可以是 str 字符串或者 pathlib.Path 对象，即文件路径，也可以是一个方法，可以自行定义输出实现，也可以是一个 logging 模块的 Handler，比如 FileHandler、StreamHandler 等，还可以是 coroutine function，即一个返回协程对象的函数等。<br>level：日志输出和保存级别。<br>format：日志格式模板。<br>filter：一个可选的指令，用于决定每个记录的消息是否应该发送到 sink。<br>colorize：格式化消息中包含的颜色标记是否应转换为用于终端着色的 ansi 代码，或以其他方式剥离。 如果没有，则根据 sink 是否为 tty（电传打字机缩写） 自动做出选择。<br>serialize：在发送到 sink 之前，是否应首先将记录的消息转换为 JSON 字符串。<br>backtrace：格式化的异常跟踪是否应该向上扩展，超出捕获点，以显示生成错误的完整堆栈跟踪。<br>diagnose：异常跟踪是否应显示变量值以简化调试。建议在生产环境中设置 False，避免泄露敏感数据。<br>enqueue：要记录的消息是否应在到达 sink 之前首先通过多进程安全队列，这在通过多个进程记录到文件时很有用，这样做的好处还在于使日志记录调用是非阻塞的。<br>catch：是否应自动捕获 sink 处理日志消息时发生的错误，如果为 True，则会在 sys.stderr 上显示异常消息，但该异常不会传播到 sink，从而防止应用程序崩溃。<br>**kwargs：仅对配置协程或文件接收器有效的附加参数（见下文）。<br>当且仅当 sink 是协程函数时，以下参数适用：</p><p>loop：将在其中调度和执行异步日志记录任务的事件循环。如果为 None，将使用 asyncio.get_event_loop() 返回的循环。<br>当且仅当 sink 是文件路径时，以下参数适用：</p><p>rotation：一种条件，指示何时应关闭当前记录的文件并开始新的文件。<br>**retention **：过滤旧文件的指令，在循环或程序结束期间会删除旧文件。<br>compression：日志文件在关闭时应转换为的压缩或存档格式。<br>delay：是在配置 sink 后立即创建文件，还是延迟到第一条记录的消息时再创建。默认为 False。<br>mode：内置 open() 函数的打开模式，默认为 a（以追加模式打开文件）。<br>buffering：内置 open() 函数的缓冲策略，默认为1（行缓冲文件）。<br>encoding：内置 open() 函数的文件编码，如果 None，则默认为 locale.getpreferredencoding()。<br>**kwargs：其他传递给内置 open() 函数的参数。<br>这么多参数可以见识到 add() 函数的强大之处，仅仅一个函数就能实现 logging 模块的诸多功能，接下来介绍几个比较常用的方法。</p><p>rotation 日志文件分隔</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">add() 函数的 rotation 参数，可以实现按照固定时间创建新的日志文件，比如设置每天 <span class="number">0</span> 点新创建一个 log 文件：</span><br><span class="line"></span><br><span class="line">logger.add(<span class="string">&#x27;runtime_&#123;time&#125;.log&#x27;</span>, rotation=<span class="string">&#x27;00:00&#x27;</span>)</span><br><span class="line">设置超过 <span class="number">500</span> MB 新创建一个 log 文件：</span><br><span class="line"></span><br><span class="line">logger.add(<span class="string">&#x27;runtime_&#123;time&#125;.log&#x27;</span>, rotation=<span class="string">&quot;500 MB&quot;</span>)</span><br><span class="line">设置每隔一个周新创建一个 log 文件：</span><br><span class="line"></span><br><span class="line">logger.add(<span class="string">&#x27;runtime_&#123;time&#125;.log&#x27;</span>, rotation=<span class="string">&#x27;1 week&#x27;</span>)</span><br><span class="line">retention 日志保留时间</span><br><span class="line">add() 函数的 retention 参数，可以设置日志的最长保留时间，比如设置日志文件最长保留 <span class="number">15</span> 天：</span><br><span class="line"></span><br><span class="line">logger.add(<span class="string">&#x27;runtime_&#123;time&#125;.log&#x27;</span>, retention=<span class="string">&#x27;15 days&#x27;</span>)</span><br><span class="line">设置日志文件最多保留 <span class="number">10</span> 个：</span><br><span class="line"></span><br><span class="line">logger.add(<span class="string">&#x27;runtime_&#123;time&#125;.log&#x27;</span>, retention=<span class="number">10</span>)</span><br><span class="line">也可以是一个 datetime.timedelta 对象，比如设置日志文件最多保留 <span class="number">5</span> 个小时：</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> loguru <span class="keyword">import</span> logger</span><br><span class="line"></span><br><span class="line">logger.add(<span class="string">&#x27;runtime_&#123;time&#125;.log&#x27;</span>, retention=datetime.timedelta(hours=<span class="number">5</span>))</span><br></pre></td></tr></table></figure><p>compression 日志压缩格式<br>add() 函数的 compression 参数，可以配置日志文件的压缩格式，这样可以更加节省存储空间，比如设置使用 zip 文件格式保存：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logger.add(<span class="string">&#x27;runtime_&#123;time&#125;.log&#x27;</span>, compression=<span class="string">&#x27;zip&#x27;</span>)</span><br></pre></td></tr></table></figure><p>其格式支持：gz、bz2、xz、lzma、tar、tar.gz、tar.bz2、tar.xz</p><p>字符串格式化<br>Loguru 在输出 log 的时候还提供了非常友好的字符串格式化功能，相当于 str.format()：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logger.info(<span class="string">&#x27;If you are using Python &#123;&#125;, prefer &#123;feature&#125; of course!&#x27;</span>, <span class="number">3.6</span>, feature=<span class="string">&#x27;f-strings&#x27;</span>)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> <span class="number">14</span>:<span class="number">59</span>:<span class="number">06.412</span> | INFO     | __main__:&lt;module&gt;:<span class="number">3</span> - If you are using Python <span class="number">3.6</span>, prefer f-strings of course!</span><br></pre></td></tr></table></figure><p>异常追溯<br>在 Loguru 里可以直接使用它提供的装饰器就可以直接进行异常捕获，而且得到的日志是无比详细的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> loguru <span class="keyword">import</span> logger</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@logger.catch</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">x, y, z</span>):</span><br><span class="line">    <span class="comment"># An error? It&#x27;s caught anyway!</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (x + y + z)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">my_function(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>日志输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2021</span>-<span class="number">10</span>-<span class="number">19</span> <span class="number">15</span>:04:<span class="number">51.675</span> | ERROR    | __main__:&lt;module&gt;:<span class="number">10</span> - An error has been caught <span class="keyword">in</span> function <span class="string">&#x27;&lt;module&gt;&#x27;</span>, process <span class="string">&#x27;MainProcess&#x27;</span> (<span class="number">30456</span>), thread <span class="string">&#x27;MainThread&#x27;</span> (<span class="number">26268</span>):</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line"></span><br><span class="line">&gt; File <span class="string">&quot;D:/python3Project\test.py&quot;</span>, line <span class="number">10</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    my_function(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">    └ &lt;function my_function at <span class="number">0x014CDFA8</span>&gt;</span><br><span class="line"></span><br><span class="line">  File <span class="string">&quot;D:/python3Project\test.py&quot;</span>, line <span class="number">7</span>, <span class="keyword">in</span> my_function</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (x + y + z)</span><br><span class="line">                │   │   └ <span class="number">0</span></span><br><span class="line">                │   └ <span class="number">0</span></span><br><span class="line">                └ <span class="number">0</span></span><br><span class="line"></span><br><span class="line">ZeroDivisionError: division by zero</span><br></pre></td></tr></table></figure><p>在控制台的输出是这样的：</p><p>相比 Logging，Loguru 无论是在配置方面、日志输出样式还是异常追踪，都远优于 Logging，使用 Loguru 无疑能提升开发人员效率。本文仅介绍了一些常用的方法，想要详细了解可参考 Loguru 官方文档或关注 Loguru GitHub。</p>]]></content>
      
      
      
        <tags>
            
            <tag> server </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>ceph安装以及测试</title>
      <link href="/ceph%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95/index.html"/>
      <url>/ceph%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95/index.html</url>
      
        <content type="html"><![CDATA[<p>1.环境配置<br>#在所有节点配置YUM：<br>#清空原来自带配置文件：<br>cd &#x2F;etc&#x2F;yum.repos.d&#x2F;<br>mkdir &#x2F;tmp&#x2F;bak<br>mv * &#x2F;tmp&#x2F;bak&#x2F;<br>#配置系统源码，epel源：</p><p>curl -o &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo <a href="https://mirrors.aliyun.com/repo/Centos-7.repo">https://mirrors.aliyun.com/repo/Centos-7.repo</a><br>yum install wget -y<br>wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;epel.repo <a href="http://mirrors.aliyun.com/repo/epel-7.repo">http://mirrors.aliyun.com/repo/epel-7.repo</a><br>#YUM优先级别：<br>yum -y install yum-plugin-priorities.noarch</p><p>#配置ceph源：<br>cat &lt;&lt; EOF | tee &#x2F;etc&#x2F;yum.repos.d&#x2F;ceph.repo<br>[Ceph]<br>name&#x3D;Ceph packages for $basearch<br>baseurl&#x3D;<a href="http://mirrors.163.com/ceph/rpm-nautilus/el7//$basearch">http://mirrors.163.com/ceph/rpm-nautilus/el7/\$basearch</a><br>enabled&#x3D;1<br>gpgcheck&#x3D;1<br>type&#x3D;rpm-md<br>gpgkey&#x3D;<a href="https://download.ceph.com/keys/release.asc">https://download.ceph.com/keys/release.asc</a><br>priority&#x3D;1<br>[Ceph-noarch]<br>name&#x3D;Ceph noarch packages<br>baseurl&#x3D;<a href="http://mirrors.163.com/ceph/rpm-nautilus/el7/noarch">http://mirrors.163.com/ceph/rpm-nautilus/el7/noarch</a><br>enabled&#x3D;1<br>gpgcheck&#x3D;1<br>type&#x3D;rpm-md<br>gpgkey&#x3D;<a href="https://download.ceph.com/keys/release.asc">https://download.ceph.com/keys/release.asc</a><br>priority&#x3D;1<br>[ceph-source]<br>name&#x3D;Ceph source packages<br>baseurl&#x3D;<a href="http://mirrors.163.com/ceph/rpm-nautilus/el7/SRPMS">http://mirrors.163.com/ceph/rpm-nautilus/el7/SRPMS</a><br>enabled&#x3D;1<br>gpgcheck&#x3D;1<br>type&#x3D;rpm-md<br>gpgkey&#x3D;<a href="https://download.ceph.com/keys/release.asc">https://download.ceph.com/keys/release.asc</a><br>EOF</p><p>#关闭防火墙：<br>systemctl stop firewalld<br>systemctl disable firewalld<br>systemctl status firewalld</p><p>#配置主机名称：<br>ceph1节点：<br>hostnamectl –static set-hostname ceph1<br>ceph2节点：<br>hostnamectl –static set-hostname ceph2<br>ceph3节点：<br>hostnamectl –static set-hostname ceph3</p><p>#所有节点配置hosts文件：<br>&#x2F;etc&#x2F;hosts<br>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4<br>::1         localhost localhost.localdomain localhost6 localhost6.localdomain6<br>192.168.0.231    ceph1<br>192.168.0.232    ceph2<br>192.168.0.233    ceph3</p><p>#所有节点NTP配置：<br>在所有集群和客户端节点安装NTP，修改配置。<br>yum -y install ntp ntpdate<br>以ceph1为NTP服务端节点，在ceph1新建NTP文件。<br>vi &#x2F;etc&#x2F;ntp.conf<br>并新增如下内容作为NTP服务端：<br>restrict 127.0.0.1<br>restrict ::1<br>restrict 192.168.3.0 mask 255.255.255.0 &#x2F;&#x2F;ceph1的网段与掩码<br>server 127.127.1.0<br>fudge 127.127.1.0 stratum 8</p><p>在ceph2、ceph3及所有客户机节点新建NTP文件。<br>vi &#x2F;etc&#x2F;ntp.conf<br>并新增如下内容作为客户端：<br>server 192.168.3.166</p><p>systemctl start ntpd<br>systemctl enable ntpd<br>systemctl status ntpd</p><p>#ssh配置，在ceph1节点生成公钥，并发放到各个主机&#x2F;客户机节点。：<br>ssh-keygen -t rsa #回车采取默认配置<br>for i in {1..3}; do ssh-copy-id ceph$i; done #根据提示输入yes及节点密码<br>for i in {1..3}; do ssh-copy-id client$i; done</p><p>#在所有节点，关闭SELinux<br>sed -i ‘s&#x2F;enforcing&#x2F;disabled&#x2F;‘ &#x2F;etc&#x2F;selinux&#x2F;config<br>setenforce 0</p><ol><li>安装Ceph软件<br>使用yum install安装ceph的时候会默认安装当前已有的最新版，如果不想安装最新版本，可以在&#x2F;etc&#x2F;yum.conf文件中加以限制。<br>2.1 在所有集群和客户端节点安装Ceph<br>yum -y install ceph<br>ceph -v命令查看版本:<br>[root@ceph1 ~]# ceph -v<br>ceph version 14.2.9 (581f22da52345dba46ee232b73b990f06029a2a0) nautilus (stable)<br>[root@ceph2 ~]# ceph -v<br>ceph version 14.2.9 (581f22da52345dba46ee232b73b990f06029a2a0) nautilus (stable)<br>[root@ceph3 ~]# ceph -v<br>ceph version 14.2.9 (581f22da52345dba46ee232b73b990f06029a2a0) nautilus (stable)<br>2.2 在ceph1节点额外安装ceph-deploy。<br>yum -y install ceph-deploy<br>3.部署MON节点<br>3.1 创建目录生成配置文件<br>mkdir cluster<br>cd cluster<br>ceph-deploy new ceph1 ceph2 ceph3<br>[root@ceph1 ~]# cd cluster&#x2F;<br>[root@ceph1 cluster]# ceph-deploy new ceph1 ceph2 ceph3<br>[ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf<br>[ceph_deploy.cli][INFO  ] Invoked (2.0.1): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy new ceph1 ceph2 ceph3<br>[ceph_deploy.cli][INFO  ] ceph-deploy options:<br>[ceph_deploy.cli][INFO  ]  username                      : None<br>[ceph_deploy.cli][INFO  ]  func                          : &lt;function new at 0x7ffb7dc07de8&gt;<br>[ceph_deploy.cli][INFO  ]  verbose                       : False<br>[ceph_deploy.cli][INFO  ]  overwrite_conf                : False<br>[ceph_deploy.cli][INFO  ]  quiet                         : False<br>[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7ffb7d58c6c8&gt;<br>[ceph_deploy.cli][INFO  ]  cluster                       : ceph<br>[ceph_deploy.cli][INFO  ]  ssh_copykey                   : True<br>[ceph_deploy.cli][INFO  ]  mon                           : [‘ceph1’, ‘ceph2’, ‘ceph3’]<br>[ceph_deploy.cli][INFO  ]  public_network                : None<br>[ceph_deploy.cli][INFO  ]  ceph_conf                     : None<br>[ceph_deploy.cli][INFO  ]  cluster_network               : None<br>[ceph_deploy.cli][INFO  ]  default_release               : False<br>[ceph_deploy.cli][INFO  ]  fsid                          : None<br>[ceph_deploy.new][DEBUG ] Creating new cluster named ceph<br>[ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds<br>[ceph1][DEBUG ] connected to host: ceph1<br>[ceph1][DEBUG ] detect platform information from remote host<br>[ceph1][DEBUG ] detect machine type<br>[ceph1][DEBUG ] find the location of an executable<br>[ceph1][INFO  ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ip link show<br>[ceph1][INFO  ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ip addr show<br>[ceph1][DEBUG ] IP addresses found: [u’192.168.0.231’]<br>[ceph_deploy.new][DEBUG ] Resolving host ceph1<br>[ceph_deploy.new][DEBUG ] Monitor ceph1 at 192.168.0.231<br>[ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds<br>[ceph2][DEBUG ] connected to host: ceph1<br>[ceph2][INFO  ] Running command: ssh -CT -o BatchMode&#x3D;yes ceph2<br>[ceph2][DEBUG ] connected to host: ceph2<br>[ceph2][DEBUG ] detect platform information from remote host<br>[ceph2][DEBUG ] detect machine type<br>[ceph2][DEBUG ] find the location of an executable<br>[ceph2][INFO  ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ip link show<br>[ceph2][INFO  ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ip addr show<br>[ceph2][DEBUG ] IP addresses found: [u’192.168.0.232’]<br>[ceph_deploy.new][DEBUG ] Resolving host ceph2<br>[ceph_deploy.new][DEBUG ] Monitor ceph2 at 192.168.0.232<br>[ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds<br>[ceph3][DEBUG ] connected to host: ceph1<br>[ceph3][INFO  ] Running command: ssh -CT -o BatchMode&#x3D;yes ceph3<br>[ceph3][DEBUG ] connected to host: ceph3<br>[ceph3][DEBUG ] detect platform information from remote host<br>[ceph3][DEBUG ] detect machine type<br>[ceph3][DEBUG ] find the location of an executable<br>[ceph3][INFO  ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ip link show<br>[ceph3][INFO  ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ip addr show<br>[ceph3][DEBUG ] IP addresses found: [u’192.168.0.233’]<br>[ceph_deploy.new][DEBUG ] Resolving host ceph3<br>[ceph_deploy.new][DEBUG ] Monitor ceph3 at 192.168.0.233<br>[ceph_deploy.new][DEBUG ] Monitor initial members are [‘ceph1’, ‘ceph2’, ‘ceph3’]<br>[ceph_deploy.new][DEBUG ] Monitor addrs are [‘192.168.0.231’, ‘192.168.0.232’, ‘192.168.0.233’]<br>[ceph_deploy.new][DEBUG ] Creating a random mon key…<br>[ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring…<br>[ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf…<br>3.2 初始化密钥<br>ceph-deploy mon create-initial<br>3.3 将ceph.client.admin.keyring拷贝到各个节点上<br>ceph-deploy –overwrite-conf admin ceph1 ceph2 ceph3<br>3.4 查看是否配置成功。<br>[root@ceph1 cluster]# ceph -scluster:id:     ea192428-05d2-437a-8cce-9d187de82dd5health: HEALTH_OKservices:mon: 3 daemons, quorum ceph1,ceph2,ceph3 (age 5m)mgr: no daemons activeosd: 0 osds: 0 up, 0 indata:pools:   0 pools, 0 pgsobjects: 0 objects, 0 Busage:   0 B used, 0 B &#x2F; 0 B availpgs:<br>4 部署MGR节点<br>ceph-deploy mgr create ceph1 ceph2 ceph3<br>查看MGR是否部署成功。<br>ceph -s<br>[root@ceph1 cluster]# ceph -scluster:id:     ea192428-05d2-437a-8cce-9d187de82dd5health: HEALTH_WARNOSD count 0 &lt; osd_pool_default_size 3services:mon: 3 daemons, quorum ceph1,ceph2,ceph3 (age 8m)mgr: ceph1(active, since 22s), standbys: ceph2, ceph3osd: 0 osds: 0 up, 0 indata:pools:   0 pools, 0 pgsobjects: 0 objects, 0 Busage:   0 B used, 0 B &#x2F; 0 B availpgs:<br>5 部署OSD节点<br>ceph-deploy osd create –data &#x2F;dev&#x2F;sdb ceph1<br>ceph-deploy osd create –data &#x2F;dev&#x2F;sdc ceph1<br>ceph-deploy osd create –data &#x2F;dev&#x2F;sdd ceph1<br>ceph-deploy osd create –data &#x2F;dev&#x2F;sdb ceph2<br>ceph-deploy osd create –data &#x2F;dev&#x2F;sdc ceph2<br>ceph-deploy osd create –data &#x2F;dev&#x2F;sdd ceph2<br>ceph-deploy osd create –data &#x2F;dev&#x2F;sdb ceph3<br>ceph-deploy osd create –data &#x2F;dev&#x2F;sdc ceph3<br>ceph-deploy osd create –data &#x2F;dev&#x2F;sdd ceph3<br>创建成功后，查看是否正常<br>[root@ceph1 cluster]# ceph -scluster:id:     ea192428-05d2-437a-8cce-9d187de82dd5health: HEALTH_OKservices:mon: 3 daemons, quorum ceph1,ceph2,ceph3 (age 14m)mgr: ceph1(active, since 6m), standbys: ceph2, ceph3osd: 9 osds: 9 up (since 2m), 9 in (since 2m)data:pools:   0 pools, 0 pgsobjects: 0 objects, 0 Busage:   9.0 GiB used, 135 GiB &#x2F; 144 GiB availpgs:<br>6 验证Ceph<br>创建存储池<br>ceph osd pool create vdbench 10 10<br>创建块设备<br>rbd create image01 –size 200–pool vdbench –image-format 2 –image-feature layering<br>rbd ls –pool vdbench<br>[root@ceph1 cluster]# rbd create image01 –size 200 –pool  vdbench –image-format 2 –image-feature layering<br>[root@ceph1 cluster]# rbd ls –pool vdbench<br>image01</li></ol><p>#PG 分 配 计 算<br>归置组(PG)的数量是由管理员在创建存储池的时候指定的，然后由 CRUSH 负责创建和使用，PG 的数量是 2 的 N 次方的倍数,每个 OSD 的 PG 不要超出 250 个 PG<br>Total PGs &#x3D; (Total_number_of_OSD * 100) &#x2F; max_replication_count<br>单个 pool 的 PG 计算如下：<br>有 100 个 osd，3 副本，5 个 pool<br>Total PGs &#x3D;100*100&#x2F;3&#x3D;3333<br>每个 pool 的 PG&#x3D;3333&#x2F;5&#x3D;512，那么创建 pool 的时候就指定 pg 为 512<br>客户端在读写对象时，需要提供的是对象标识和存储池名称<br>客户端需要在存储池中读写对象时，需要客户端将对象名称，对象名称的hash码，存储池中的PG数量和存储池名称作为输入信息提供给ceph，然后由CRUSH计算出PG的ID以及PG针对的主OSD即可读写OSD中的对象。<br>具体写操作如下：<br>1.APP向ceph客户端发送对某个对象的请求，此请求包含对象和存储池，然后ceph客户端对访问的对象做hash计算，并根据此hash值计算出对象所在的PG，完成对象从Pool至PG的映射。<br>APP 访问 pool ID 和 object ID （比如 pool &#x3D; pool1 and object-id &#x3D; “name1”）<br>ceph client 对 objectID 做哈希<br>ceph client 对该 hash 值取 PG 总数的模，得到 PG 编号(比如 32)<br>ceph client 对 pool ID 取 hash（比如 “pool1” &#x3D; 3）<br>ceph client 将 pool ID 和 PG ID 组合在一起(比如 3.23)得到 PG 的完整 ID。<br>2.然后客户端据 PG、CRUSH 运行图和归置组(placement rules)作为输入参数并再次进行计<br>算，并计算出对象所在的 PG 内的主 OSD ，从而完成对象从 PG 到 OSD 的映射。<br>3.客户端开始对主 OSD 进行读写请求(副本池 IO)，如果发生了写操作，会有 ceph 服务端完<br>成对象从主 OSD 到备份 OSD 的同步</p><p>二.熟练 ceph 的用户管理及授权<br>客户端使用 session key 向 mon 请求所需要的服务，mon 向客户端提供一个 tiket，用于向实际处理数据的 OSD 等服务验证客户端身份，MON 和 OSD 共享同一个 secret.<br>ceph 用户需要拥有存储池访问权限，才能读取和写入数据<br>ceph 用户必须拥有执行权限才能使用 ceph 的管理命令<br>ceph 支持多种类型的用户，但可管理的用户都属于 client 类型<br>通过点号来分割用户类型和用户名，格式为 TYPE.ID，例如 client.admin。<br>root@ceph-deploy:~# cat &#x2F;etc&#x2F;ceph&#x2F;ceph.client.admin.keyring<br>[client.admin]<br>        key &#x3D; AQBnFaNj1iyBMBAAd+9hKWXaNw3GYxT9PEXvrQ&#x3D;&#x3D;<br>        caps mds &#x3D; “allow *”<br>        caps mgr &#x3D; “allow *”<br>        caps mon &#x3D; “allow *”<br>        caps osd &#x3D; “allow *”</p><p>#列 出 指 定 用 户 信 息<br>root@ceph-deploy:~# ceph auth get osd.10<br>[osd.10]<br>        key &#x3D; AQB+I6Njk4KWNBAAL09FFayLKF44IgUQ1fjKYQ&#x3D;&#x3D;<br>        caps mgr &#x3D; “allow profile osd”<br>        caps mon &#x3D; “allow profile osd”<br>        caps osd &#x3D; “allow *”</p><p>exported keyring for osd.10</p><p>#: 列 出 用 户<br>cephadmin@ceph-deploy:~$ ceph auth list<br>mds.ceph-mgr1<br>        key: AQAdRbFjOwBXIRAAUTdwElBzYPHW+4uFicFC7Q&#x3D;&#x3D;<br>        caps: [mds] allow<br>        caps: [mon] allow profile mds<br>        caps: [osd] allow rwx<br>osd.0<br>        key: AQC0IqNjbcgKIxAA+BCNpQeZiMujR+r+69Miig&#x3D;&#x3D;<br>        caps: [mgr] allow profile osd<br>        caps: [mon] allow profile osd<br>        caps: [osd] allow *</p><p>#可以结合使用-o 文件名选项和 ceph auth list 将输出保存到某个文件。<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph auth list -o 123.key</p><p>#ceph auth add<br>此命令是添加用户的规范方法。它会创建用户、生成密钥，并添加所有指定的能力<br>添加认证 key：<br>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ ceph auth add client.tom mon ‘allow r’ osd ‘allow rwx pool&#x3D;testpool2’<br>added key for client.tom</p><p>##验证 key<br>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ ceph auth get client.tom<br>[client.tom]<br>        key &#x3D; AQD2vbJj8fIiDBAArtJBzQiuPy8nDWPSFVs0bw&#x3D;&#x3D;<br>        caps mon &#x3D; “allow r”<br>        caps osd &#x3D; “allow rwx pool&#x3D;testpool2”<br>exported keyring for client.tom</p><p>##创建用户<br>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ ceph auth get-or-create client.jack mon ‘allow r’ osd ‘allow rwx pool&#x3D;testpool2’<br>[client.jack]<br>        key &#x3D; AQC&#x2F;vrJj5kenHhAAGeRJpY64feS4Dn6DD&#x2F;R8VA&#x3D;&#x3D;</p><p>##再次创建用户<br>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ ceph auth get-or-create client.jack mon ‘allow r’ osd ‘allow rwx pool&#x3D;testpool2’<br>[client.jack]<br>        key &#x3D; AQC&#x2F;vrJj5kenHhAAGeRJpY64feS4Dn6DD&#x2F;R8VA&#x3D;&#x3D;</p><p>#ceph auth get-or-create-key:<br>此命令是创建用户并返回用户密钥，对于只需要密钥的客户端(例如 libvrirt),此命令非常有用。<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph auth get-or-create-key client.jack<br>mon ‘allow r’ osd ‘allow rwx pool&#x3D;mypool’<br>AQAtr8dfi37XMhAADbHWEZ0shY1QZ5A8eBpeoQ&#x3D;&#x3D;</p><p>用户有 key 就显示没有就创建<br>#修 改 用 户 能 力<br>cephadmin@ceph-deploy:<del>&#x2F;ceph-cluster$ ceph auth get client.jack<br>[client.jack]<br>        key &#x3D; AQC&#x2F;vrJj5kenHhAAGeRJpY64feS4Dn6DD&#x2F;R8VA&#x3D;&#x3D;<br>        caps mon &#x3D; “allow r”<br>        caps osd &#x3D; “allow rwx pool&#x3D;testpool2”<br>exported keyring for client.jack<br>cephadmin@ceph-deploy:</del>&#x2F;ceph-cluster$ ceph auth caps client.jack mon ‘allow r’ osd ‘allow rw pool&#x3D;testpool2’<br>updated caps for client.jack<br>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ ceph auth get client.jack<br>[client.jack]<br>        key &#x3D; AQC&#x2F;vrJj5kenHhAAGeRJpY64feS4Dn6DD&#x2F;R8VA&#x3D;&#x3D;<br>        caps mon &#x3D; “allow r”<br>        caps osd &#x3D; “allow rw pool&#x3D;testpool2”<br>exported keyring for client.jack</p><p>#删 除 用 户<br>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ ceph auth del client.tom<br>updated<br>#导出 keyring 至指定文件<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph auth get client.user1 -o<br>ceph.client.user1.keyring<br>exported keyring for client.user1<br>#验证指定用户的 keyring 文件：<br>[cephadmin@ceph-deploy ceph-cluster]$ cat ceph.client.user1.keyring<br>[client.user1]<br>key &#x3D; AQAUUchfjpMqGRAARV6h0ofdDEneuaRnxuHjoQ&#x3D;&#x3D;<br>caps mon &#x3D; “allow r”<br>caps osd &#x3D; “allow * pool&#x3D;mypool”<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph auth del client.user1 #演示误删除用户<br>Updated<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph auth get client.user1 #确认用户被删除<br>Error ENOENT: failed to find client.user1 in keyring<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph auth import -i<br>ceph.client.user1.keyring #导入用户<br>imported keyring<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph auth get client.user1 #验证已恢复用户<br>exported keyring for client.user1<br>#将多 用 户 导 出 至 秘 钥 环 ：<br>#创建 keyring 文件：<br>$ ceph-authtool –create-keyring ceph.client.user.keyring #创建空的 keyring 文件<br>creating ceph.client.user.keyring<br>#把指定的 admin 用户的 keyring 文件内容导入到 user 用户的 keyring 文件：<br>$ceph-authtool .&#x2F;ceph.client.user.keyring<br>–import-keyring .&#x2F;ceph.client.admin.keyring<br>importing contents of .&#x2F;ceph.client.admin.keyring into .&#x2F;ceph.client.user.keyring<br>#验证 keyring 文件：<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph-authtool -l .&#x2F;ceph.client.user.keyring<br>[client.admin]<br>key &#x3D; AQAGDKJfQk&#x2F;dAxAA3Y+9xoE&#x2F;p8in6QjoHeXmeg&#x3D;&#x3D;<br>caps mds &#x3D; “allow *”<br>caps mgr &#x3D; “allow *”<br>caps mon &#x3D; “allow *”<br>caps osd &#x3D; “allow *”<br>#再导入一个其他用户的 keyring：<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph-authtool .&#x2F;ceph.client.user.keyring<br>–import-keyring .&#x2F;ceph.client.user1.keyring<br>importing contents of .&#x2F;ceph.client.user1.keyring into .&#x2F;ceph.client.user.keyring<br>#再次验证 keyring 文件是否包含多个用户的认证信息：<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph-authtool -l .&#x2F;ceph.client.user.keyring<br>[client.admin]<br>key &#x3D; AQAGDKJfQk&#x2F;dAxAA3Y+9xoE&#x2F;p8in6QjoHeXmeg&#x3D;&#x3D;<br>caps mds &#x3D; “allow *”<br>caps mgr &#x3D; “allow *”<br>caps mon &#x3D; “allow *”<br>caps osd &#x3D; “allow *”<br>[client.user1]<br>key &#x3D; AQAUUchfjpMqGRAARV6h0ofdDEneuaRnxuHjoQ&#x3D;&#x3D;<br>caps mon &#x3D; “allow r”<br>caps osd &#x3D; “allow * pool&#x3D;mypool”</p><p>三. 使用普通客户挂载块存储<br>#创建存储池：<br>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ceph osd pool create rbd-data1 32 32</p><p>#存储池启用 rbd<br>cephadmin@ceph-deploy:<del>&#x2F;ceph-cluster$ceph osd pool application enable rbd-data1 rbd<br>#初始化 rbd<br>cephadmin@ceph-deploy:</del>&#x2F;ceph-cluster$rbd pool init -p rbd-data1</p><p>#创建两个镜像：<br>cephadmin@ceph-deploy:<del>&#x2F;ceph-cluster$rbd create data-img1 –size 3G –pool rbd-data1 –image-format 2 –image-feature layering<br>cephadmin@ceph-deploy:</del>&#x2F;ceph-cluster$rbd create data-img2 –size 5G –pool rbd-data1 –image-format 2 –image-feature layering</p><p>#列出镜像信息<br>cephadmin@ceph-deploy:<del>&#x2F;ceph-cluster$rbd ls –pool rbd-data1<br>#以 json 格 式 显 示 镜 像 信 息<br>cephadmin@ceph-deploy:</del>&#x2F;ceph-cluster$rbd ls –pool rbd-data1 -l –format json –pretty-format</p><p>#创建普通账户<br>ceph auth add client.shijie mon ‘allow r’ osd ‘allow rwx pool&#x3D;rbd-data1’</p><p>#验证用户信息<br>ceph auth get client.shijie</p><p>#创建用 keyring 文件<br>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ ceph-authtool –create-keyring ceph.client.shijie.keyring</p><p>#导出用户 keyring<br>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ ceph auth get client.shijie -o ceph.client.shijie.keyring </p><p>#验证指定用户的 keyring 文件</p><p>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$cat ceph.client.shijie.keyring </p><p>#同 步 普 通 用 户 认 证 文 件</p><p>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ scp ceph.client.shijie.keyring <a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#x40;&#49;&#x37;&#50;&#46;&#x33;&#49;&#46;&#54;&#46;&#49;&#48;&#x39;">&#x72;&#x6f;&#x6f;&#x74;&#x40;&#49;&#x37;&#50;&#46;&#x33;&#49;&#46;&#54;&#46;&#49;&#48;&#x39;</a>:&#x2F;etc&#x2F;ceph&#x2F;</p><p>#管理端验证镜像状态</p><p>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$rbd ls -p rbd-data1 -l</p><p>#在client上操作<br>#映射 rbd</p><p>root@ceph-node4:&#x2F;# rbd -p rbd-data1 map data-img1<br>&#x2F;dev&#x2F;rbd0<br>root@ceph-node4:&#x2F;# lsblk<br>rbd0<br>root@ceph-node4:&#x2F;# mkfs.xfs &#x2F;dev&#x2F;rbd0<br>root@ceph-node4:&#x2F;# mount &#x2F;dev&#x2F;rbd0 &#x2F;data<br>root@ceph-node4:&#x2F;# docker run -it -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD&#x3D;”12345678” -v &#x2F;data:&#x2F;var&#x2F;lib&#x2F;mysql mysql:5.6.46<br>48374db8541a7fa375c00611373051ef21690e89adfd4c156b3f6ffb0dbe95a2<br>root@ceph-node4:&#x2F;data# ls<br>ibdata1  ib_logfile0  ib_logfile1  mysql  performance_schema  test</p><p>#在client上操作<br>#使用普通用户映射 rbd</p><p>root@ceph-node4:&#x2F;etc&#x2F;ceph# rbd –user shijie -p rbd-data1 map data-img2<br>&#x2F;dev&#x2F;rbd1<br>#格式化<br>root@ceph-node4:&#x2F;etc&#x2F;ceph#mkfs.ext4 &#x2F;dev&#x2F;rbd0<br>root@ceph-node4:&#x2F;etc&#x2F;ceph# mkdir &#x2F;data1<br>root@ceph-node4:&#x2F;etc&#x2F;ceph# mount &#x2F;dev&#x2F;rbd1 &#x2F;data1<br>root@ceph-node4:&#x2F;etc&#x2F;ceph# cp &#x2F;var&#x2F;log&#x2F;auth.log &#x2F;data1<br>root@ceph-node4:&#x2F;etc&#x2F;ceph# cd &#x2F;data1<br>root@ceph-node4:&#x2F;data1# ls<br>auth.log  lost+found<br>四. 使用普通用户挂载 cephfs（可以通过 secret 或者 secretfile 的形式多主机同时挂载）<br>Ceph FS 需要运行 Meta Data Services(MDS)服务，其守护进程为 ceph-mds，ceph-mds进程管理与 cephFS 上存储的文件相关的元数据，并协调对 ceph 存储集群的访问。</p><p>#部署MDS服务:<br>cephadmin@ceph-deploy:<del>&#x2F;ceph-cluster$ apt-cache madison ceph-mds<br>  ceph-mds | 16.2.10-1bionic | <a href="https://mirrors.tuna.tsinghua.edu.cn/ceph/debian-pacific">https://mirrors.tuna.tsinghua.edu.cn/ceph/debian-pacific</a> bionic&#x2F;main amd64 Packages<br>cephadmin@ceph-deploy:</del>&#x2F;ceph-cluster$ apt install ceph-mds&#x3D;16.2.10-1bionic</p><p>#创建CephFS meta data和data存储池<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph osd pool create cephfs-metadata 32 32<br>pool ‘cephfs-metadata’ created #保存 metadata 的 pool<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph osd pool create cephfs-data 64 64<br>pool ‘cephfs-data’ created #保存数据的 pool<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph fs new mycephfs cephfs-metadata<br>cephfs-data<br>new fs with metadata pool 7 and data pool 8<br>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ ceph fs ls<br>name: mycephfs, metadata pool: cephfs-metadata, data pools: [cephfs-data ]<br>#查看指定 cephFS 状态</p><p>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ ceph fs status mycephfs<br>mycephfs - 0 clients<br>RANK  STATE      MDS        ACTIVITY     DNS    INOS   DIRS   CAPS<br> 0    active  ceph-mgr1  Reqs:    0 &#x2F;s    10     13     12      0<br>      POOL         TYPE     USED  AVAIL<br>cephfs-metadata  metadata   146k  18.9T<br>  cephfs-data      data       0   18.9T<br>MDS version: ceph version 16.2.10 (45fa1a083152e41a408d15505f594ec5f1b4fe17) pacific (stable)<br>#验证cephFS服务状态</p><p>cephadmin@ceph-deploy:~$ ceph mds stat<br>mycephfs:1 {0&#x3D;ceph-mgr1&#x3D;up:active}</p><p>#创建客户端账户<br>cephadmin@ceph-deploy:~&#x2F;ceph-cluster$ceph auth add client.yanyan mon ‘allow r’ mds ‘allow rw’ osd ‘allow rwx pool&#x3D;cephfs-data’<br>#验证账户<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph auth get client.yanyan<br>exported keyring for client.yanyan<br>[client.yanyan]<br>key &#x3D; AQCxpdhfjQt1OxAAGe0mqTMveNu2ZMEem3tb0g&#x3D;&#x3D;<br>caps mds &#x3D; “allow rw”<br>caps mon &#x3D; “allow r”<br>caps osd &#x3D; “allow rwx pool&#x3D;cephfs-data”<br>#创建keyring 文件<br>[cephadmin@ceph-deploy ceph-cluster]$ ceph auth get client.yanyan -o<br>ceph.client.yanyan.keyring<br>exported keyring for client.yanyan<br>#创建 key 文件：</p><p>[cephadmin@ceph-deploy ceph-cluster]$ ceph auth print-key client.yanyan &gt; yanyan.key<br>#验证用户的 keyring 文件</p><p>[cephadmin@ceph-deploy ceph-cluster]$ cat ceph.client.yanyan.keyring<br>[client.yanyan]<br>key &#x3D; AQCxpdhfjQt1OxAAGe0mqTMveNu2ZMEem3tb0g&#x3D;&#x3D;<br>caps mds &#x3D; “allow rw”<br>caps mon &#x3D; “allow r”<br>caps osd &#x3D; “allow rwx pool&#x3D;cephfs-data”</p><p>#同步客户端认证文件 ：</p><p>[cephadmin@ceph-deploy ceph-cluster]$ scp ceph.conf ceph.client.yanyan.keyring<br>yanyan.key <a href="mailto:&#114;&#111;&#111;&#116;&#64;&#49;&#55;&#x32;&#x2e;&#51;&#x31;&#x2e;&#x36;&#46;&#49;&#48;&#x39;">&#114;&#111;&#111;&#116;&#64;&#49;&#55;&#x32;&#x2e;&#51;&#x31;&#x2e;&#x36;&#46;&#49;&#48;&#x39;</a>:&#x2F;etc&#x2F;ceph&#x2F;</p><p>#客户端验证权限</p><p>root@ceph-node4:~# ceph –user yanyan -s<br>  cluster:<br>    id:     7c088d6f-06b0-4584-b23f-c0f150af51d4<br>    health: HEALTH_OK<br>  services:<br>    mon: 3 daemons, quorum ceph-mon1,ceph-mon2,ceph-mon3 (age 24m)<br>    mgr: ceph-mgr1(active, since 65m)<br>    mds: 1&#x2F;1 daemons up<br>    osd: 16 osds: 16 up (since 24m), 16 in (since 13d)<br>    rgw: 1 daemon active (1 hosts, 1 zones)<br>  data:<br>    volumes: 1&#x2F;1 healthy<br>    pools:   10 pools, 329 pgs<br>    objects: 296 objects, 218 MiB<br>    usage:   948 MiB used, 60 TiB &#x2F; 60 TiB avail<br>    pgs:     329 active+clean</p><p>#客户端通过 key 文件挂载:</p><p> root@ceph-node4:~#mkdir &#x2F;data<br> root@ceph-node4:&#x2F;etc&#x2F;ceph# mount -t ceph 172.31.6.101:6789,172.31.6.102:6789,172.31.6.103:6789:&#x2F; &#x2F;data -o name&#x3D;yanyan,secretfile&#x3D;&#x2F;etc&#x2F;ceph&#x2F;yanyan.key<br>root@ceph-node4:&#x2F;etc&#x2F;ceph# df -h<br>Filesystem                                               Size  Used Avail Use% Mounted on<br>udev                                                     955M     0  955M   0% &#x2F;dev<br>172.31.6.101:6789,172.31.6.102:6789,172.31.6.103:6789:&#x2F;   19T     0   19T   0% &#x2F;data</p><p>#客户端通过key挂载</p><p>root@ceph-node3:<del># mkdir &#x2F;data<br>root@ceph-node3:</del># mount -t ceph 172.31.6.101:6789,172.31.6.102:6789,172.31.6.103:6789:&#x2F; &#x2F;data -o name&#x3D;yanyan,secret&#x3D;AQAfebVjaIPgABAAzkW4ChX2Qm2Sha&#x2F;5twdxPA&#x3D;&#x3D;<br>root@ceph-node3:<del># df -h<br>Filesystem                                               Size  Used Avail Use% Mounted on<br>udev                                                     955M     0  955M   0% &#x2F;dev<br>172.31.6.101:6789,172.31.6.102:6789,172.31.6.103:6789:&#x2F;   19T     0   19T   0% &#x2F;data<br>root@ceph-node3:</del># cp &#x2F;var&#x2F;log&#x2F;auth.log &#x2F;data<br>root@ceph-node3:~# cd &#x2F;data<br>root@ceph-node3:&#x2F;data# ls<br>auth.log<br>root@ceph-node3:&#x2F;data# vim auth.log<br>root@ceph-node3:&#x2F;data# echo “12345678” &gt;&gt; auth.log<br>root@ceph-node3:&#x2F;data# echo “testlog” &gt;&gt; auth.log<br>#在node4客户端上查看cephfs挂载点&#x2F;data 目录下内容，已经同步</p><p>root@ceph-node4:&#x2F;# tail -f &#x2F;data&#x2F;auth.log<br>Jan  4 22:25:01 ceph-node3 CRON[4365]: pam_unix(cron:session): session closed for user root<br>12345678<br>testlog<br>#客户端内核加载 ceph.ko 模块挂载 cephfs 文件系统</p><p>root@ceph-node4:&#x2F;# lsmod|grep ceph<br>ceph                  380928  1<br>libceph               315392  1 ceph<br>fscache                65536  1 ceph<br>libcrc32c              16384  5 nf_conntrack,nf_nat,xfs,raid456,libceph<br>root@ceph-node4:&#x2F;# modinfo ceph<br>filename:       &#x2F;lib&#x2F;modules&#x2F;4.15.0-130-generic&#x2F;kernel&#x2F;fs&#x2F;ceph&#x2F;ceph.ko<br>license:        GPL<br>description:    Ceph filesystem for Linux<br>author:         Patience Warnick <a href="mailto:&#x70;&#x61;&#116;&#105;&#x65;&#x6e;&#99;&#101;&#64;&#110;&#x65;&#x77;&#100;&#x72;&#101;&#97;&#x6d;&#46;&#110;&#101;&#116;">&#x70;&#x61;&#116;&#105;&#x65;&#x6e;&#99;&#101;&#64;&#110;&#x65;&#x77;&#100;&#x72;&#101;&#97;&#x6d;&#46;&#110;&#101;&#116;</a><br>author:         Yehuda Sadeh <a href="mailto:&#x79;&#101;&#104;&#117;&#100;&#x61;&#x40;&#x68;&#x71;&#46;&#x6e;&#101;&#x77;&#100;&#114;&#x65;&#97;&#x6d;&#x2e;&#x6e;&#101;&#x74;">&#x79;&#101;&#104;&#117;&#100;&#x61;&#x40;&#x68;&#x71;&#46;&#x6e;&#101;&#x77;&#100;&#114;&#x65;&#97;&#x6d;&#x2e;&#x6e;&#101;&#x74;</a><br>author:         Sage Weil <a href="mailto:&#x73;&#x61;&#x67;&#101;&#64;&#110;&#x65;&#x77;&#x64;&#114;&#101;&#x61;&#109;&#46;&#x6e;&#x65;&#116;">&#x73;&#x61;&#x67;&#101;&#64;&#110;&#x65;&#x77;&#x64;&#114;&#101;&#x61;&#109;&#46;&#x6e;&#x65;&#116;</a><br>alias:          fs-ceph<br>srcversion:     CB79D9E4790452C6A392A1C<br>depends:        libceph,fscache<br>retpoline:      Y<br>intree:         Y<br>name:           ceph<br>vermagic:       4.15.0-130-generic SMP mod_unload<br>signat:         PKCS#7<br>signer:<br>sig_key:<br>sig_hashalgo:   md4</p>]]></content>
      
    </entry>
    
    
  
</search>
